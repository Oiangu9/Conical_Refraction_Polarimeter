{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Law Estimator: \n",
    "## with highest peak width get $w_0$ and using Gradient algorithm and that, obtain $R_0$\n",
    "This is a notebook to obtain the empirical law that follows the parameter $R_0$ given the estimation by the gravicenter algorithm and the theoretically known $w_0$ and an empirical Law to obtain the $w_0$ parameter if we know the width of the highest peak along the main axis of the CR ring.\n",
    "\n",
    "The idea is the following:\n",
    " - **(1)**: Simulate many many CR rings with different $R_0$ and $w_0$ combinations, fixing the angle at, say, $\\phi_{CR}=0$ and $nx=540$ so we get something similar in resolution to the Basler camera.\n",
    " \n",
    " \n",
    " - **(2)**: For each of the images compute the iX image and run the Gradient Algorithm to estimate the masked gravicenter (which shall be aligned with the gravicenter and the maximum of the ring and spoted in the Pogendorf dark ring). Record in a list the tuples ($D:=$dist(masked_grav,grav), w_0, R_0).\n",
    " \n",
    " \n",
    " - **(3)**: For each image, estimate the width of the highest peak above a certain tolerance of intensity to account for possible backgrounds (which in reality should not be present since they are simulated images, but ok). For this, look for the first pixel that is above the tolerance in the outside part of the big peak and then look for the pixel where there is a second trend change from there, by computing the difference for instance (the differential).\n",
    " \n",
    " \n",
    " - **(4)**: Run two fully connected and two simple regressors to fit each a model for our two objectives. Train the fully connecteds with gradient descent, while the simple multidimensional regressors (1 layer) using the normal equations if possible. Use the L1 norm to avoid unnecessary terms to have weight and get the simplest of the expressions (use also the L2 norm, in case we get a considerably better model).\n",
    "    \n",
    "    In order to compute the $w_0$ from the width of the highest peak, we could introduce also the data of the $D$ in order to give more flexibility to the model (try both things). For obtaining $R_0$ then use both the estimated $w_0$ and the $D$.\n",
    " \n",
    " \n",
    " - **(5)**: Save the trained models, and make a section where we can input experimental images and obtain automatically (or manually, since maybe the noise now gives us strange things) the width of the highest peak and with it $w_0$ and then $R_0$ with the gradient algorithm estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from GPU_Classes import *\n",
    "from Image_Manager import *\n",
    "from Polarization_Obtention_Algorithms import Gradient_Algorithm\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "experiment_name=\"540_Basler_like_phiCR_0\" # \"NOT_USING_INTERPOLATION_IN_iX\" # \"RECENTERING_AVERAGE_IMAGE_TO_iX_USING_INTERPOLATION\" # \"RECENTERING_AVERAGE_IMAGE_TO_iX_NOT_USING_INTERPOLATION\" # los 4 con 540 y los 4 con el doble de resolucion y ver que sacamos de los resultados - note that this means only two simulation rounds are necessary\n",
    "vig_path=f\"./OUTPUT/EMPIRICAL_LAWS/{experiment_name}/VIGILANT_{experiment_name}.json\"\n",
    "os.chdir(f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run simulations for theoretical samples with ground-truths +\n",
    "## Step 2: Compute the iX image and run the gradient algorithm, saving the results, ground-truths and Profiles along the main axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the PARAMETERS ############################################\n",
    "##################################################################\n",
    "randomization_seed=666\n",
    "image_depth=8 # or 16 bit per pixel\n",
    "pol_or_CR=\"pol\"\n",
    "image_shortest_side=540\n",
    "saturation=1\n",
    "\n",
    "# 1. SIMULATION ####################################################\n",
    "# Ring parameters to test (each will be a different simulation)\n",
    "phiCR_s=[0]\n",
    "R0_s=np.linspace(70,180,40) # in pxels\n",
    "#rho_0s=np.array([2,3,4,5,6,7,9,11,14,20])\n",
    "w0_s=np.linspace(8,50,40)\n",
    "rho_0s=R0_s/w0_s\n",
    "\n",
    "\n",
    "resolution_side_nx=image_shortest_side # generated images will be resolution_side x resolution_side\n",
    "# Other parameters\n",
    "max_k=50\n",
    "num_k=1200\n",
    "sim_chunk_ax=image_shortest_side\n",
    "\n",
    "# PROFILES\n",
    "pix_spacing=3\n",
    "\n",
    "# 4. GRAVICENTER iX and PROFILES ######################################\n",
    "X=int(resolution_side_nx*1.4/2)\n",
    "interpolation_flag= cv2.INTER_CUBIC #{\"CUBIC\":cv2.INTER_CUBIC, \"LANCZOS\":cv2.INTER_LANCZOS4}# \"LINEAR\":cv2.INTER_LINEAR, \"AREA\":cv2.INTER_AREA, \"NEAREST\":cv2.INTER_NEAREST}\n",
    "\n",
    "# 5. GRADIENT ALGORITHM ###################################\n",
    "# Each using both Fibonacci and Quadratic Fit Search\n",
    "\n",
    "rad_min_Grav=3\n",
    "rad_max_Grav=image_shortest_side/2-2\n",
    "initial_guess_delta_pix=10\n",
    "\n",
    "use_exact_gravicenter=True\n",
    "precision_quadratic=1e-10\n",
    "max_it_quadratic=100\n",
    "cost_tolerance_quadratic=1e-14\n",
    "precision_fibonacci=1e-10\n",
    "max_points_fibonacci=100\n",
    "cost_tolerance_fibonacci=1e-14\n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "# General considerations\n",
    "im_type=np.uint16 if image_depth==16 else np.uint8\n",
    "max_intensity=65535 if image_depth==16 else 255\n",
    "np.random.seed(randomization_seed)\n",
    "polCR=1 if pol_or_CR=='CR' else 0.5\n",
    "\n",
    "vig_path=f\"./OUTPUT/EMPIRICAL_LAWS/{experiment_name}/VIGILANT_{experiment_name}.json\"\n",
    "os.makedirs(f\"./OUTPUT/EMPIRICAL_LAWS/{experiment_name}/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL ROUTINES #################################\n",
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    return centered_image\n",
    "    '''\n",
    "    else:\n",
    "        # We compute the center of gravity of the cropped images, if everything was made allright\n",
    "        # they should get just centered in the central pixels number X+1 (index X)\n",
    "        g_centered = compute_intensity_gravity_center(centered_image)\n",
    "\n",
    "        # We now compute a floating translation of the image so that the gravicenter is exactly\n",
    "        # centered at pixel (607.5, 607.5) (exact center of the image in pixel coordinates staring\n",
    "        # form (0,0) and having size (607*2+1)x2), instead of being centered at the beginning of\n",
    "        # around pixel (607,607) as is now\n",
    "        translate_vectors = X+0.5-g_centered #[ 2(h,w)]\n",
    "        T = np.float64([[1,0, translate_vectors[1]], [0,1, translate_vectors[0]]])\n",
    "        return cv2.warpAffine( centered_image, T, (X*2+1, X*2+1),\n",
    "                    flags=interpolation_flag) # interpolation method\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Simulated\n",
      "2-th Simulated\n",
      "3-th Simulated\n",
      "4-th Simulated\n",
      "5-th Simulated\n",
      "6-th Simulated\n",
      "7-th Simulated\n",
      "8-th Simulated\n",
      "9-th Simulated\n",
      "10-th Simulated\n",
      "11-th Simulated\n",
      "12-th Simulated\n",
      "13-th Simulated\n",
      "14-th Simulated\n",
      "15-th Simulated\n",
      "16-th Simulated\n",
      "17-th Simulated\n",
      "18-th Simulated\n",
      "19-th Simulated\n",
      "20-th Simulated\n",
      "21-th Simulated\n",
      "22-th Simulated\n",
      "23-th Simulated\n",
      "24-th Simulated\n",
      "25-th Simulated\n",
      "26-th Simulated\n",
      "27-th Simulated\n",
      "28-th Simulated\n",
      "29-th Simulated\n",
      "30-th Simulated\n",
      "31-th Simulated\n",
      "32-th Simulated\n",
      "33-th Simulated\n",
      "34-th Simulated\n",
      "35-th Simulated\n",
      "36-th Simulated\n",
      "37-th Simulated\n",
      "38-th Simulated\n",
      "39-th Simulated\n",
      "40-th Simulated\n",
      "41-th Simulated\n",
      "42-th Simulated\n",
      "43-th Simulated\n",
      "44-th Simulated\n",
      "45-th Simulated\n",
      "46-th Simulated\n",
      "47-th Simulated\n",
      "48-th Simulated\n",
      "49-th Simulated\n",
      "50-th Simulated\n",
      "51-th Simulated\n",
      "52-th Simulated\n",
      "53-th Simulated\n",
      "54-th Simulated\n",
      "55-th Simulated\n",
      "56-th Simulated\n",
      "57-th Simulated\n",
      "58-th Simulated\n",
      "59-th Simulated\n",
      "60-th Simulated\n",
      "61-th Simulated\n",
      "62-th Simulated\n",
      "63-th Simulated\n",
      "64-th Simulated\n",
      "65-th Simulated\n",
      "66-th Simulated\n",
      "67-th Simulated\n",
      "68-th Simulated\n",
      "69-th Simulated\n",
      "70-th Simulated\n",
      "71-th Simulated\n",
      "72-th Simulated\n",
      "73-th Simulated\n",
      "74-th Simulated\n",
      "75-th Simulated\n",
      "76-th Simulated\n",
      "77-th Simulated\n",
      "78-th Simulated\n",
      "79-th Simulated\n",
      "80-th Simulated\n",
      "81-th Simulated\n",
      "82-th Simulated\n",
      "83-th Simulated\n",
      "84-th Simulated\n",
      "85-th Simulated\n",
      "86-th Simulated\n",
      "87-th Simulated\n",
      "88-th Simulated\n",
      "89-th Simulated\n",
      "90-th Simulated\n",
      "91-th Simulated\n",
      "92-th Simulated\n",
      "93-th Simulated\n",
      "94-th Simulated\n",
      "95-th Simulated\n",
      "96-th Simulated\n",
      "97-th Simulated\n",
      "98-th Simulated\n",
      "99-th Simulated\n",
      "100-th Simulated\n",
      "101-th Simulated\n",
      "102-th Simulated\n",
      "103-th Simulated\n",
      "104-th Simulated\n",
      "105-th Simulated\n",
      "106-th Simulated\n",
      "107-th Simulated\n",
      "108-th Simulated\n",
      "109-th Simulated\n",
      "110-th Simulated\n",
      "111-th Simulated\n",
      "112-th Simulated\n",
      "113-th Simulated\n",
      "114-th Simulated\n",
      "115-th Simulated\n",
      "116-th Simulated\n",
      "117-th Simulated\n",
      "118-th Simulated\n",
      "119-th Simulated\n",
      "120-th Simulated\n",
      "121-th Simulated\n",
      "122-th Simulated\n",
      "123-th Simulated\n",
      "124-th Simulated\n",
      "125-th Simulated\n",
      "126-th Simulated\n",
      "127-th Simulated\n",
      "128-th Simulated\n",
      "129-th Simulated\n",
      "130-th Simulated\n",
      "131-th Simulated\n",
      "132-th Simulated\n",
      "133-th Simulated\n",
      "134-th Simulated\n",
      "135-th Simulated\n",
      "136-th Simulated\n",
      "137-th Simulated\n",
      "138-th Simulated\n",
      "139-th Simulated\n",
      "140-th Simulated\n",
      "141-th Simulated\n",
      "142-th Simulated\n",
      "143-th Simulated\n",
      "144-th Simulated\n",
      "145-th Simulated\n",
      "146-th Simulated\n",
      "147-th Simulated\n",
      "148-th Simulated\n",
      "149-th Simulated\n",
      "150-th Simulated\n",
      "151-th Simulated\n",
      "152-th Simulated\n",
      "153-th Simulated\n",
      "154-th Simulated\n",
      "155-th Simulated\n",
      "156-th Simulated\n",
      "157-th Simulated\n",
      "158-th Simulated\n",
      "159-th Simulated\n",
      "160-th Simulated\n",
      "161-th Simulated\n",
      "162-th Simulated\n",
      "163-th Simulated\n",
      "164-th Simulated\n",
      "165-th Simulated\n",
      "166-th Simulated\n",
      "167-th Simulated\n",
      "168-th Simulated\n",
      "169-th Simulated\n",
      "170-th Simulated\n",
      "171-th Simulated\n",
      "172-th Simulated\n",
      "173-th Simulated\n",
      "174-th Simulated\n",
      "175-th Simulated\n",
      "176-th Simulated\n",
      "177-th Simulated\n",
      "178-th Simulated\n",
      "179-th Simulated\n",
      "180-th Simulated\n",
      "181-th Simulated\n",
      "182-th Simulated\n",
      "183-th Simulated\n",
      "184-th Simulated\n",
      "185-th Simulated\n",
      "186-th Simulated\n",
      "187-th Simulated\n",
      "188-th Simulated\n",
      "189-th Simulated\n",
      "190-th Simulated\n",
      "191-th Simulated\n",
      "192-th Simulated\n",
      "193-th Simulated\n",
      "194-th Simulated\n",
      "195-th Simulated\n",
      "196-th Simulated\n",
      "197-th Simulated\n",
      "198-th Simulated\n",
      "199-th Simulated\n",
      "200-th Simulated\n",
      "201-th Simulated\n",
      "202-th Simulated\n",
      "203-th Simulated\n",
      "204-th Simulated\n",
      "205-th Simulated\n",
      "206-th Simulated\n",
      "207-th Simulated\n",
      "208-th Simulated\n",
      "209-th Simulated\n",
      "210-th Simulated\n",
      "211-th Simulated\n",
      "212-th Simulated\n",
      "213-th Simulated\n",
      "214-th Simulated\n",
      "215-th Simulated\n",
      "216-th Simulated\n",
      "217-th Simulated\n",
      "218-th Simulated\n",
      "219-th Simulated\n",
      "220-th Simulated\n",
      "221-th Simulated\n",
      "222-th Simulated\n",
      "223-th Simulated\n",
      "224-th Simulated\n",
      "225-th Simulated\n",
      "226-th Simulated\n",
      "227-th Simulated\n",
      "228-th Simulated\n",
      "229-th Simulated\n",
      "230-th Simulated\n",
      "231-th Simulated\n",
      "232-th Simulated\n",
      "233-th Simulated\n",
      "234-th Simulated\n",
      "235-th Simulated\n",
      "236-th Simulated\n",
      "237-th Simulated\n",
      "238-th Simulated\n",
      "239-th Simulated\n",
      "240-th Simulated\n",
      "241-th Simulated\n",
      "242-th Simulated\n",
      "243-th Simulated\n",
      "244-th Simulated\n",
      "245-th Simulated\n",
      "246-th Simulated\n",
      "247-th Simulated\n",
      "248-th Simulated\n",
      "249-th Simulated\n",
      "250-th Simulated\n",
      "251-th Simulated\n",
      "252-th Simulated\n",
      "253-th Simulated\n",
      "254-th Simulated\n",
      "255-th Simulated\n",
      "256-th Simulated\n",
      "257-th Simulated\n",
      "258-th Simulated\n",
      "259-th Simulated\n",
      "260-th Simulated\n",
      "261-th Simulated\n",
      "262-th Simulated\n",
      "263-th Simulated\n",
      "264-th Simulated\n",
      "265-th Simulated\n",
      "266-th Simulated\n",
      "267-th Simulated\n",
      "268-th Simulated\n",
      "269-th Simulated\n",
      "270-th Simulated\n",
      "271-th Simulated\n",
      "272-th Simulated\n",
      "273-th Simulated\n",
      "274-th Simulated\n",
      "275-th Simulated\n",
      "276-th Simulated\n",
      "277-th Simulated\n",
      "278-th Simulated\n",
      "279-th Simulated\n",
      "280-th Simulated\n",
      "281-th Simulated\n",
      "282-th Simulated\n",
      "283-th Simulated\n",
      "284-th Simulated\n",
      "285-th Simulated\n",
      "286-th Simulated\n",
      "287-th Simulated\n",
      "288-th Simulated\n",
      "289-th Simulated\n",
      "290-th Simulated\n",
      "291-th Simulated\n",
      "292-th Simulated\n",
      "293-th Simulated\n",
      "294-th Simulated\n",
      "295-th Simulated\n",
      "296-th Simulated\n",
      "297-th Simulated\n",
      "298-th Simulated\n",
      "299-th Simulated\n",
      "300-th Simulated\n",
      "301-th Simulated\n",
      "302-th Simulated\n",
      "303-th Simulated\n",
      "304-th Simulated\n",
      "305-th Simulated\n",
      "306-th Simulated\n",
      "307-th Simulated\n",
      "308-th Simulated\n",
      "309-th Simulated\n",
      "310-th Simulated\n",
      "311-th Simulated\n",
      "312-th Simulated\n",
      "313-th Simulated\n",
      "314-th Simulated\n",
      "315-th Simulated\n",
      "316-th Simulated\n",
      "317-th Simulated\n",
      "318-th Simulated\n",
      "319-th Simulated\n",
      "320-th Simulated\n",
      "321-th Simulated\n",
      "322-th Simulated\n",
      "323-th Simulated\n",
      "324-th Simulated\n",
      "325-th Simulated\n",
      "326-th Simulated\n",
      "327-th Simulated\n",
      "328-th Simulated\n",
      "329-th Simulated\n",
      "330-th Simulated\n",
      "331-th Simulated\n",
      "332-th Simulated\n",
      "333-th Simulated\n",
      "334-th Simulated\n",
      "335-th Simulated\n",
      "336-th Simulated\n",
      "337-th Simulated\n",
      "338-th Simulated\n",
      "339-th Simulated\n",
      "340-th Simulated\n",
      "341-th Simulated\n",
      "342-th Simulated\n",
      "343-th Simulated\n",
      "344-th Simulated\n",
      "345-th Simulated\n",
      "346-th Simulated\n",
      "347-th Simulated\n",
      "348-th Simulated\n",
      "349-th Simulated\n",
      "350-th Simulated\n",
      "351-th Simulated\n",
      "352-th Simulated\n",
      "353-th Simulated\n",
      "354-th Simulated\n",
      "355-th Simulated\n",
      "356-th Simulated\n",
      "357-th Simulated\n",
      "358-th Simulated\n",
      "359-th Simulated\n",
      "360-th Simulated\n",
      "361-th Simulated\n",
      "362-th Simulated\n",
      "363-th Simulated\n",
      "364-th Simulated\n",
      "365-th Simulated\n",
      "366-th Simulated\n",
      "367-th Simulated\n",
      "368-th Simulated\n",
      "369-th Simulated\n",
      "370-th Simulated\n",
      "371-th Simulated\n",
      "372-th Simulated\n",
      "373-th Simulated\n"
     ]
    }
   ],
   "source": [
    "# Initialize the vigilant\n",
    "try:\n",
    "    phase_vigilant = json.load(open(vig_path))\n",
    "except:\n",
    "    phase_vigilant = {'stage':0, 'simulation_IDs':[], 'GT_R0s':[], 'GT_w0s':[], 'profiles':[], 'Ds':[], 'grav':[], 'masked_grav':[], 'angle_error':[], 'slope':[]}\n",
    "\n",
    "# Set the objects ready ##################\n",
    "# The image manager\n",
    "image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "# Define the Gradient algorithm\n",
    "gradient_algorithm = Gradient_Algorithm(image_loader,\n",
    "        rad_min_Grav, rad_max_Grav,\n",
    "        initial_guess_delta_pix,\n",
    "        use_exact_gravicenter)\n",
    "image_container=np.zeros( (1, 2*X+1, 2*X+1), dtype=np.float64)\n",
    "image_names=['a']\n",
    "# The simulator object\n",
    "simulator=RingSimulator_Optimizer_GPU( n=1.5, a0=1.0, max_k=max_k, num_k=num_k, nx=resolution_side_nx, sim_chunk_x=sim_chunk_ax, sim_chunk_y=sim_chunk_ax)\n",
    "\n",
    "cols = np.broadcast_to( np.arange(X*2+1), (X*2+1,X*2+1)) #[h,w]\n",
    "rows = cols.swapaxes(0,1) #[h,w]\n",
    "\n",
    "# Execute the stuff #####################\n",
    "i=1\n",
    "for phi_CR in phiCR_s:\n",
    "    for R0 in R0_s:\n",
    "        for w0 in w0_s:\n",
    "            ID=f\"phiCR_{phi_CR}_R0_{R0}_w0_{w0}\"\n",
    "            if ID not in phase_vigilant['simulation_IDs']:\n",
    "                # simulate image\n",
    "                image=simulator.compute_CR_ring( CR_ring_angle=phi_CR, R0_pixels=R0, Z=0, w0_pixels=w0)\n",
    "                # normalize the image to output datatype\n",
    "                image = max_intensity*(image.astype(np.float64)/image.max())\n",
    "                phase_vigilant['simulation_IDs'].append(ID)\n",
    "                phase_vigilant['GT_R0s'].append(R0)\n",
    "                phase_vigilant['GT_w0s'].append(w0)\n",
    "                \n",
    "                # get iX image\n",
    "                image = np.where( image<=(max_intensity*saturation), image, max_intensity*saturation)\n",
    "                image = compute_raw_to_centered_iX(image, X)\n",
    "                \n",
    "                # run gradient algorithm\n",
    "                # charge the image\n",
    "                image_container[0]=image.astype(np.float64)\n",
    "                image_names[0]=ID\n",
    "                # charge the image loader:\n",
    "                image_loader.import_converted_images_as_array(image_container, image_names)\n",
    "                \n",
    "                optimal_masked_gravs={}\n",
    "                optimal_radii={}\n",
    "                optimal_angle={}\n",
    "                grav=compute_intensity_gravity_center(image)\n",
    "                # run both fibonacci and quadratic and then compute the average as the desired optimal\n",
    "                gradient_algorithm.reInitialize(image_loader)\n",
    "                gradient_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "                optimal_masked_gravs['quad'] = gradient_algorithm.masked_gravs[f\"Quadratic_Search_{ID}\"]\n",
    "                optimal_radii['quad'] = gradient_algorithm.optimals[f\"Quadratic_Search_{ID}\"]\n",
    "                optimal_angle['quad'] = gradient_algorithm.angles[f\"Quadratic_Search_{ID}\"]\n",
    "                gradient_algorithm.reInitialize(image_loader)\n",
    "                gradient_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "                optimal_masked_gravs['fibo'] = gradient_algorithm.masked_gravs[f\"Fibonacci_Search_{ID}\"]\n",
    "                optimal_radii['fibo'] = gradient_algorithm.optimals[f\"Fibonacci_Search_{ID}\"]\n",
    "                optimal_angle['fibo'] = gradient_algorithm.angles[f\"Fibonacci_Search_{ID}\"]\n",
    "\n",
    "                masked_grav=(optimal_masked_gravs['quad']+optimal_masked_gravs['fibo'])/2.0\n",
    "                \n",
    "                phase_vigilant['Ds'].append((optimal_radii['quad']+optimal_radii['fibo'])/2)\n",
    "                phase_vigilant['grav'].append(grav.tolist())\n",
    "                phase_vigilant['masked_grav'].append(masked_grav.tolist())\n",
    "                # since we know that phiCR=0 we could input the exact profile of the main axis...but maybe for \n",
    "                # generality afterwards it will be nice to do it as there\n",
    "                slope=(masked_grav[0]-grav[0])/(masked_grav[1]-grav[1])\n",
    "                mask=(rows<( slope*(cols-masked_grav[1]) +masked_grav[0]+pix_spacing )) & (rows>( slope*(cols-masked_grav[1]) +masked_grav[0]-pix_spacing ))\n",
    "\n",
    "                filtered_image=np.where(mask, image, 0)\n",
    "                phase_vigilant['profiles'].append((np.sum(filtered_image,axis=0)).tolist())\n",
    "                phase_vigilant['slope'].append(slope)\n",
    "                \n",
    "                # it is good to record the error performed in the angle as a measure of how accurate the gradient algorithm was detecting the main axis\n",
    "                phase_vigilant['angle_error'].append(max(abs(optimal_angle['fibo']-phi_CR), abs(optimal_angle['quad']-phi_CR)))\n",
    "                # we save the progess (in order to be able to quit and resume)\n",
    "                json.dump(phase_vigilant, open( vig_path, \"w\"))\n",
    "                print(f\"{i}-th Simulated\")\n",
    "                i+=1\n",
    "\n",
    "# We print the maximum error that happened in the angle detection, as a sanity check\n",
    "print(f\"Maximum error made in angle detection is {max(phase_vigilant['angle_error'])}\")\n",
    "\n",
    "# We pass to the next stage\n",
    "if phase_vigilant['stage']==0:\n",
    "    phase_vigilant['stage']=2\n",
    "    json.dump(phase_vigilant, open( vig_path, \"w\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Estimate the width of the highest peak for each image's profile\n",
    "For this, we could actually use the masked gravicenter, since the optimal is supposed to be exactly in the Pogendorf dark ring, but well, we will use a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sanity_check_of_result(profile, first_increment_index, valley_min_index, slope):\n",
    "    plt.rc('font', size=8) \n",
    "    fig = plt.figure(figsize=(2*4.5, 2*4.5))\n",
    "    axes=fig.subplots(1,1)\n",
    "    axes.plot(np.arange(len(profile))*np.sqrt(1+slope**2) , profile , markersize=1, label=f'Intensity profile along main axis')\n",
    "    axes.plot([first_increment_index, valley_min_index], [0,0], 'or')\n",
    "    axes.grid()\n",
    "    axes.set_ylabel(f'Reduced Intensity profile along main axis')\n",
    "    axes.set_xlabel(\"Pixels along the main axis\") \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tolerance=0.001\n",
    "phase_vigilant['Ws']=[]\n",
    "\n",
    "for k, profile in enumerate(phase_vigilant['profiles']):\n",
    "    profile=np.array(profile)\n",
    "    grav_x=round(phase_vigilant['grav'][k][1])\n",
    "    if np.sum(profile[:grav_x])<np.sum(profile[grav_x:]): # then the bump is on the right\n",
    "        profile=np.flip(profile)\n",
    "    # At this point any profile has the bump in the left\n",
    "    first_increment_index=np.argmax(profile>=tolerance) # it will stop in the first True it finds\n",
    "    diff_prof=profile[1:]-profile[:-1]\n",
    "    is_increasing=(diff_prof>tolerance) # we select the points whose next point is higher than them\n",
    "    first_increment_index=np.argmax(is_increasing)\n",
    "    peak_of_high_bump_index=first_increment_index+np.argmin(is_increasing[first_increment_index:])\n",
    "    valley_min_index=peak_of_high_bump_index+np.argmax(is_increasing[peak_of_high_bump_index:])\n",
    "    \n",
    "    W = (valley_min_index-first_increment_index)*np.sqrt(1+phase_vigilant['slope'][k]**2) \n",
    "    phase_vigilant['Ws'].append(W)\n",
    "    print(f\"{k}-th W found: {W} with w0 {phase_vigilant['GT_w0s'][k]} and R0 {phase_vigilant['GT_R0s'][k]}\")\n",
    "    #plot_sanity_check_of_result(profile, first_increment_index, valley_min_index, phase_vigilant['slope'][k])\n",
    "\n",
    "\n",
    "# We print the maximum difference between the R0 and the W, as a sanity check\n",
    "print(f\"Maximum R0 to W absolute difference found is {np.max(np.abs((2.4*np.array(phase_vigilant['GT_w0s'])-np.array(phase_vigilant['Ws']))))}\")\n",
    "\n",
    "# We pass to the next stage\n",
    "if phase_vigilant['stage']==2:\n",
    "    phase_vigilant['stage']=3\n",
    "    #phase_vigilant['W']=[]\n",
    "    json.dump(phase_vigilant, open( vig_path, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run the Machine Learning to estimate the empirical laws. Save the fitted models.\n",
    "\n",
    "We are going to train several models.\n",
    "\n",
    "### a) Models to obtain $w_0$ from the $W$ and the $D$\n",
    "\n",
    "### b) Models to obtain $R_0$ from the $W$ and the $D$ or the estimated $w_0$ and the $D$ - in the end it should be roughly the same -\n",
    "\n",
    "### (c) Obtain $w_0, R_0$ from $D$, $slope$ and $Profile$ as a ten layer fc model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORMAL EQUATIONS\n",
    "### (a) Obtain $w_0$ from $W$ and $D$ as a Linear Model (the rule of thumb)\n",
    "First define the design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_vigilant = json.load(open(vig_path))\n",
    "\n",
    "# If we only include the W\n",
    "y = np.array(phase_vigilant['GT_w0s'])\n",
    "X = np.array(np.array([  phase_vigilant['Ws']])\n",
    "                ).T # the potential arguments to the empirical function we are looking for\n",
    "LS_w_1 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"Least square solution is w_0=W*{LS_w_1[0]:5.5}, or W=w_0*{(1/LS_w_1[0]):5.5}, with average abs error {np.mean(np.abs(y-X@LS_w_1)):5.5} pix\")\n",
    "\n",
    "# If we have bias as well\n",
    "X = np.array(np.array([ [1 for i in range(len(phase_vigilant['Ws']))], phase_vigilant['Ws']])\n",
    "                ).T\n",
    "LS_w_2 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is w_0={LS_w_2[0]:5.5}+W*{LS_w_2[1]:5.5}, or W=(w_0-{LS_w_2[0]:5.5})*{1/LS_w_2[1]:5.5}, with average abs error {np.mean(np.abs(y-X@LS_w_2)):5.5} pix\")\n",
    "\n",
    "# If we allow D to enter the equation\n",
    "X = np.array(np.array([ [1 for i in range(len(phase_vigilant['Ws']))], phase_vigilant['Ws'],\n",
    "                    phase_vigilant['Ds']])\n",
    "                ).T\n",
    "LS_w_3 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is w_0={LS_w_3[0]:5.5}+W*{LS_w_3[1]:5.5}+D*{LS_w_3[2]:5.5} with average abs error {np.mean(np.abs(y-X@LS_w_3)):5.5} pix\")\n",
    "\n",
    "# Id we allow to have crossed terms and bias\n",
    "X = np.array(np.array([ [1 for i in range(len(phase_vigilant['Ws']))], phase_vigilant['Ws'],\n",
    "                    phase_vigilant['Ds'],np.array(phase_vigilant['Ws'])*np.array(phase_vigilant['Ds'] )])\n",
    "                ).T\n",
    "LS_w_4 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is w_0={LS_w_4[0]:5.5}+W*{LS_w_4[1]:5.5}+D*{LS_w_4[2]:5.5}+{LS_w_4[3]:5.5}*WD with average abs error {np.mean(np.abs(y-X@LS_w_4)):5.5} pix\")\n",
    "\n",
    "# Last combination\n",
    "X = np.array(np.array([  phase_vigilant['Ws'],\n",
    "                    phase_vigilant['Ds']])\n",
    "                ).T\n",
    "LS_w_5 = np.linalg.solve(X.T@X,X.T@y)\n",
    "print(f\"\\nLeast square solution is w_0=W*{LS_w_5[0]:5.5}+D*{LS_w_5[1]:5.5} with average abs error {np.mean(np.abs(y-X@LS_w_5)):5.5} pix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the best rule of thumb is given by the simple relation with W. We could then check if regularization would say the same we will compute GD with an L1+L2 regularization appart from the MSE objective function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_w0=np.array(np.array([  phase_vigilant['Ws']])).T@LS_w_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b.1) Obtain $R_0$ from $D$ and estimated $w_0$ with the other rule of thumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_vigilant = json.load(open(vig_path))\n",
    "\n",
    "# If we only include the W\n",
    "y = np.array(phase_vigilant['GT_R0s'])\n",
    "X = np.array(np.array([  estimated_w0 ])\n",
    "                ).T # the potential arguments to the empirical function we are looking for\n",
    "LS_w_1 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"Least square solution is R_0=hat_w0*{LS_w_1[0]:5.5}, or hat_w0=R_0*{(1/LS_w_1[0]):5.5}, with average abs error {np.mean(np.abs(y-X@LS_w_1)):5.5} pix\")\n",
    "\n",
    "# If we have bias as well\n",
    "X = np.array(np.array([ [1 for i in range(len(estimated_w0))], estimated_w0])\n",
    "                ).T\n",
    "LS_w_2 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is R_0={LS_w_2[0]:5.5}+hat_w0*{LS_w_2[1]:5.5}, or hat_w0=(R_0-{LS_w_2[0]:5.5})*{1/LS_w_2[1]:5.5}, with average abs error {np.mean(np.abs(y-X@LS_w_2)):5.5} pix\")\n",
    "\n",
    "# If we allow D to enter the equation\n",
    "X = np.array(np.array([ [1 for i in range(len(estimated_w0))], estimated_w0,\n",
    "                    phase_vigilant['Ds']])\n",
    "                ).T\n",
    "LS_w_3 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is R_0={LS_w_3[0]:5.5}+hat_w0*{LS_w_3[1]:5.5}+D*{LS_w_3[2]:5.5} with average abs error {np.mean(np.abs(y-X@LS_w_3)):5.5} pix\")\n",
    "\n",
    "# Id we allow to have crossed terms and bias\n",
    "X = np.array(np.array([ [1 for i in range(len(estimated_w0))], estimated_w0,\n",
    "                    phase_vigilant['Ds'],estimated_w0*np.array(phase_vigilant['Ds'] )])\n",
    "                ).T\n",
    "LS_w_4 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is R_0={LS_w_4[0]:5.5}+hat_w0*{LS_w_4[1]:5.5}+D*{LS_w_4[2]:5.5}+{LS_w_4[3]:5.5}*WD with average abs error {np.mean(np.abs(y-X@LS_w_4)):5.5} pix\")\n",
    "\n",
    "# Last combination\n",
    "X = np.array(np.array([  estimated_w0,\n",
    "                    phase_vigilant['Ds']])\n",
    "                ).T\n",
    "LS_w_5 = np.linalg.solve(X.T@X,X.T@y)\n",
    "print(f\"\\nLeast square solution is R_0=hat_w0*{LS_w_5[0]:5.5}+D*{LS_w_5[1]:5.5} with average abs error {np.mean(np.abs(y-X@LS_w_5)):5.5} pix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b.2) Obtain $R_0$ from $D$ and $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_vigilant = json.load(open(vig_path))\n",
    "\n",
    "# If we only include the W\n",
    "y = np.array(phase_vigilant['GT_R0s'])\n",
    "X = np.array(np.array([  phase_vigilant['Ws']])\n",
    "                ).T # the potential arguments to the empirical function we are looking for\n",
    "LS_w_1 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"Least square solution is R_0=W*{LS_w_1[0]:5.5}, or W=R_0*{(1/LS_w_1[0]):5.5}, with average abs error {np.mean(np.abs(y-X@LS_w_1)):5.5} pix\")\n",
    "\n",
    "# If we have bias as well\n",
    "X = np.array(np.array([ [1 for i in range(len(phase_vigilant['Ws']))], phase_vigilant['Ws']])\n",
    "                ).T\n",
    "LS_w_2 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is R_0={LS_w_2[0]:5.5}+W*{LS_w_2[1]:5.5}, or W=(R_0-{LS_w_2[0]:5.5})*{1/LS_w_2[1]:5.5}, with average abs error {np.mean(np.abs(y-X@LS_w_2)):5.5} pix\")\n",
    "\n",
    "# If we allow D to enter the equation\n",
    "X = np.array(np.array([ [1 for i in range(len(phase_vigilant['Ws']))], phase_vigilant['Ws'],\n",
    "                    phase_vigilant['Ds']])\n",
    "                ).T\n",
    "LS_w_3 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is R_0={LS_w_3[0]:5.5}+W*{LS_w_3[1]:5.5}+D*{LS_w_3[2]:5.5} with average abs error {np.mean(np.abs(y-X@LS_w_3)):5.5} pix\")\n",
    "\n",
    "# Id we allow to have crossed terms and bias\n",
    "X = np.array(np.array([ [1 for i in range(len(phase_vigilant['Ws']))], phase_vigilant['Ws'],\n",
    "                    phase_vigilant['Ds'],np.array(phase_vigilant['Ws'])*np.array(phase_vigilant['Ds'] )])\n",
    "                ).T\n",
    "LS_w_4 = np.linalg.solve(X.T@X,X.T@y)\n",
    "\n",
    "print(f\"\\nLeast square solution is R_0={LS_w_4[0]:5.5}+W*{LS_w_4[1]:5.5}+D*{LS_w_4[2]:5.5}+{LS_w_4[3]:5.5}*WD with average abs error {np.mean(np.abs(y-X@LS_w_4)):5.5} pix\")\n",
    "\n",
    "# Last combination\n",
    "X = np.array(np.array([  phase_vigilant['Ws'],\n",
    "                    phase_vigilant['Ds']])\n",
    "                ).T\n",
    "LS_w_5 = np.linalg.solve(X.T@X,X.T@y)\n",
    "print(f\"\\nLeast square solution is R_0=W*{LS_w_5[0]:5.5}+D*{LS_w_5[1]:5.5} with average abs error {np.mean(np.abs(y-X@LS_w_5)):5.5} pix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEURAL NETWORKS -Gradient Descent using L1 and MSE cost fct-\n",
    "#### Define the  FC model classes#### Define the dataset and the FC model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FCModel(nn.Module):\n",
    "    def __init__(self, input_size, n_layers, neurons_per_layer, use_relu_in_last=False): \n",
    "        # last layer number of neurons will be equal to the output size!\n",
    "        super(FCModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        sequence=[(f'Linear0', nn.Linear(input_size, neurons_per_layer[0])), (f'ReLU0', nn.ReLU())]\n",
    "        for i in range(1,n_layers):\n",
    "            sequence.append((f'Linear{i}', nn.Linear(neurons_per_layer[i-1], neurons_per_layer[i])))\n",
    "            sequence.append((f'ReLU{i}', nn.ReLU()))\n",
    "            \n",
    "        if use_relu_in_last==False:\n",
    "            sequence=sequence[:-1]\n",
    "        self.network = nn.Sequential(OrderedDict( sequence ))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)\n",
    "    \n",
    "def createModel(input_size  = 28*28, \n",
    "                output_size = 10, n_layers=128, neurons_per_layer = 128*[30], use_relu_in_last=False,\n",
    "                parameter_initialiser=None):\n",
    "\n",
    "    torch.manual_seed(0) # seed for reproductibility\n",
    "\n",
    "    model = FCModel(input_size, n_layers, neurons_per_layer, use_relu_in_last)\n",
    "\n",
    "    # subroutine to count number of parameters in the model\n",
    "    def get_n_params(model):\n",
    "        np=0\n",
    "        for p in list(model.parameters()):\n",
    "            np += p.numel()\n",
    "        return np\n",
    "\n",
    "    print(f\"Number of parameters in model {get_n_params(model)}\")\n",
    "\n",
    "    # move model to gpu if available\n",
    "    model.to(device)\n",
    "    if not parameter_initialiser==None:\n",
    "        initialize_parameters(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The routines to validate and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # prevent this function from computing gradients \n",
    "def validate(criterion, model, loader): #show_confusion_matrix = False):\n",
    "\n",
    "    val_loss = 0\n",
    "    max_abs_error = torch.Tensor([0]).to(device)\n",
    "    mean_abs_error = 0\n",
    "    preds = torch.Tensor().to(device)\n",
    "    targets = torch.Tensor().to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in loader:\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.input_size)\n",
    "        output = model(data)\n",
    "        target = target.view(output.shape)\n",
    "        loss = criterion(output, target, model)\n",
    "        val_loss += loss.item()                                                              \n",
    "        #pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        #preds = torch.cat((preds, pred.view_as(target)))\n",
    "        #targets= torch.cat((targets, target))                                                                 \n",
    "        #correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        max_abs_error = torch.maximum(torch.max(torch.abs(output-target), 0).values, max_abs_error)\n",
    "        mean_abs_error += torch.sum(torch.abs(output-target), 0)\n",
    "\n",
    "    val_loss /= len(loader.dataset)\n",
    "    mean_abs_error /= len(loader.dataset)\n",
    "    #accuracy = 100. * correct / len(loader.dataset)\n",
    "    print(f'\\nValidation set: Average loss: {val_loss:.4f}, Average Abs Error: {np.array(mean_abs_error.cpu())}, Maximum Abs Error: {np.array(max_abs_error.cpu())} \\n')\n",
    "\n",
    "    #if show_confusion_matrix:\n",
    "    #    visualize_confusion_matrix(preds.to(torch.device('cpu')), targets.to(torch.device('cpu')))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def train(epoch, criterion, model, optimizer, loader, print_loss_every_batches=100):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data = data.view(-1, model.input_size)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target, model)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss every N batches\n",
    "        if batch_idx % print_loss_every_batches == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loader.dataset),\n",
    "                print_loss_every_batches * batch_idx / len(loader), loss.item()))\n",
    "\n",
    "\n",
    "        total_loss += loss.item()  #.item() is very important here\n",
    "        # Why?-> In order to avoid having total_loss as a tensor in the gpu\n",
    "\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_training_loop(model, criterion, optimizer, train_loader, val_loader, epochs=10, print_loss_every_batches=100):\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss = train(epoch, criterion, model, optimizer, train_loader, print_loss_every_batches=print_loss_every_batches)\n",
    "        val_loss = validate(criterion, model, val_loader)\n",
    "        losses[\"train\"].append(train_loss)\n",
    "        losses[\"val\"].append(val_loss)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        plt.plot(losses[\"train\"], label=\"training loss\")\n",
    "        plt.plot(losses[\"val\"], label=\"validation loss\")\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.pause(0.01)\n",
    "        plt.show()   \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Obtain $w_0$ from $W$ and $D$ as a Linear One Layer Model (the rule of thumb)\n",
    "First define the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "phase_vigilant = json.load(open(vig_path))\n",
    "targets = torch.tensor(phase_vigilant['GT_w0s']).float()\n",
    "data = torch.tensor(np.array([phase_vigilant['Ws'], phase_vigilant['Ds'], \n",
    "                     np.array(phase_vigilant['Ds'])*np.array(phase_vigilant['Ws'])])).transpose(0,1).float() # the potential arguments\n",
    "                                                                # to the empirical function we are looking for\n",
    "\n",
    "full_dataset = CustomDataset(data, targets)\n",
    "train_size = int(0.95 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom loss for having L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_L1_loss(estimation, target, model, decay=1e-4):\n",
    "    losser = nn.MSELoss()\n",
    "    loss = losser(estimation, target) # mse computation\n",
    "    #L1_reg = torch.tensor(0., requires_grad=True)\n",
    "    #for name, param in model.named_parameters():\n",
    "    #    if 'weight' in name:\n",
    "    #        L1_reg = L1_reg + torch.norm(param, 1)\n",
    "    #loss = loss + decay * L1_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate a model\n",
    "thumb_model_w0 = createModel( input_size  = 3, n_layers=1, \n",
    "                    neurons_per_layer = [1],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None) # que triste jajajajaja\n",
    "\n",
    "# nn package also has different loss functions.\n",
    "# we use mean square error for the regression task\n",
    "criterion = lambda est,targ,model : MSE_L1_loss(est,targ, model) \n",
    "\n",
    "# we use the optim package to apply\n",
    "# stochastic gradient descent for our parameter updates\n",
    "#optimizer = torch.optim.SGD(thumb_model_w0.parameters(), lr=1e-8, momentum=0.9, weight_decay=0) # built-in L2 weight decay\n",
    "optimizer = torch.optim.Adagrad(thumb_model_w0.parameters(), lr=0.1,lr_decay=0.01, weight_decay=0.3, initial_accumulator_value=0, eps=1e-10)\n",
    "\n",
    "# Execute the training and validation\n",
    "losses = full_training_loop(thumb_model_w0, criterion, optimizer, train_loader, val_loader, epochs=100, print_loss_every_batches=200)\n",
    "\n",
    "print(\"\\n\\n\\nFINAL VALIDATION! ####################################################\\n\\n\")\n",
    "validate(criterion, thumb_model_w0, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thumb_model_w0)\n",
    "\n",
    "print(thumb_model_w0.parameters())\n",
    "# Print model's state_dict\n",
    "print(\"\\n\\nModel's state_dict:\")\n",
    "for param_tensor in thumb_model_w0.state_dict():\n",
    "    print(param_tensor, \"\\t\", thumb_model_w0.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b.1) Obtain $R_0$ from $D$ and estimated $w_0$ with the other rule of thumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.cat([estimated_w0, torch.Tensor(phase_vigilant['Ds']).unsqueeze(1), \n",
    "                     torch.Tensor(phase_vigilant['Ds']).unsqueeze(1)*(estimated_w0)], 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_vigilant = json.load(open(vig_path))\n",
    "targets = torch.tensor(phase_vigilant['GT_R0s']).float()\n",
    "estimated_w0=thumb_model_w0(data.to(device)).cpu().detach().clone()\n",
    "data = torch.cat([estimated_w0, torch.Tensor(phase_vigilant['Ds']).unsqueeze(1), \n",
    "                     torch.Tensor(phase_vigilant['Ds']).unsqueeze(1)*(estimated_w0)], 1).float() # the potential arguments\n",
    "                                                                # to the empirical function we are looking for\n",
    "\n",
    "full_dataset = CustomDataset(data, targets)\n",
    "train_size = int(0.95 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate a model\n",
    "thumb_model_R0_1 = createModel( input_size  = 3, n_layers=1, \n",
    "                    neurons_per_layer = [1],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None) # que triste jajajajaja\n",
    "\n",
    "# nn package also has different loss functions.\n",
    "# we use mean square error for the regression task\n",
    "criterion = lambda est,targ,model : MSE_L1_loss(est,targ, model) \n",
    "\n",
    "# we use the optim package to apply\n",
    "# stochastic gradient descent for our parameter updates\n",
    "#optimizer = torch.optim.SGD(thumb_model_R0_1.parameters(), lr=1e-9, momentum=0.2, weight_decay=0) # built-in L2 weight decay\n",
    "optimizer = torch.optim.Adagrad(thumb_model_R0_1.parameters(), lr=0.1, lr_decay=0.01, weight_decay=0.3, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = torch.optim.Adam(thumb_model_R0_1.parameters(), lr=0.05, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.7, amsgrad=True) \n",
    "#optimizer = torch.optim.RMSprop(thumb_model_R0_1.parameters(), lr=0.01, alpha=0.7, eps=1e-08, weight_decay=0.2, momentum=0.1, centered=False)\n",
    "\n",
    "# Execute the training and validation\n",
    "losses = full_training_loop(thumb_model_R0_1, criterion, optimizer, train_loader, val_loader, epochs=70, print_loss_every_batches=400)\n",
    "\n",
    "print(\"\\n\\n\\nFINAL VALIDATION! ####################################################\\n\\n\")\n",
    "validate(criterion, thumb_model_R0_1, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thumb_model_R0_1)\n",
    "\n",
    "print(thumb_model_R0_1.parameters())\n",
    "# Print model's state_dict\n",
    "print(\"\\n\\nModel's state_dict:\")\n",
    "for param_tensor in thumb_model_R0_1.state_dict():\n",
    "    print(param_tensor, \"\\t\", thumb_model_R0_1.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b.2) Obtain $R_0$ from $D$ and $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_vigilant = json.load(open(vig_path))\n",
    "targets = torch.tensor(phase_vigilant['GT_R0s']).float()\n",
    "data = torch.tensor(np.array([phase_vigilant['Ws'], phase_vigilant['Ds'], \n",
    "                     np.array(phase_vigilant['Ds'])*np.array(phase_vigilant['Ws'])])).transpose(0,1).float() # the potential arguments\n",
    "                                                                # to the empirical function we are looking for\n",
    "\n",
    "full_dataset = CustomDataset(data, targets)\n",
    "train_size = int(0.95 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate a model\n",
    "thumb_model_R0_2 = createModel( input_size  = 3, n_layers=1, \n",
    "                    neurons_per_layer = [1],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None) # que triste jajajajaja\n",
    "\n",
    "# nn package also has different loss functions.\n",
    "# we use mean square error for the regression task\n",
    "criterion = lambda est,targ,model : MSE_L1_loss(est,targ, model) \n",
    "\n",
    "# we use the optim package to apply\n",
    "# stochastic gradient descent for our parameter updates\n",
    "#optimizer = torch.optim.SGD(thumb_model_R0_2.parameters(), lr=1e-9, momentum=0.2, weight_decay=0) # built-in L2 weight decay\n",
    "#optimizer = torch.optim.Adagrad(thumb_model_R0_2.parameters(), lr=0.1, lr_decay=0.01, weight_decay=0.3, initial_accumulator_value=0, eps=1e-10)\n",
    "optimizer = torch.optim.RMSprop(thumb_model_R0_2.parameters(), lr=0.01, alpha=0.8, eps=1e-08, weight_decay=0.1, momentum=0.2, centered=False)\n",
    "\n",
    "# Execute the training and validation\n",
    "losses = full_training_loop(thumb_model_R0_2, criterion, optimizer, train_loader, val_loader, epochs=70, print_loss_every_batches=100)\n",
    "\n",
    "print(\"\\n\\n\\nFINAL VALIDATION! ####################################################\\n\\n\")\n",
    "validate(criterion, thumb_model_R0_2, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thumb_model_R0_2)\n",
    "\n",
    "print(thumb_model_R0_2.parameters())\n",
    "# Print model's state_dict\n",
    "print(\"\\n\\nModel's state_dict:\")\n",
    "for param_tensor in thumb_model_R0_2.state_dict():\n",
    "    print(param_tensor, \"\\t\", thumb_model_R0_2.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Obtain $w_0, R_0$ from $D$, $slope$ and $Profile$ as a ten layer fc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_vigilant = json.load(open(vig_path))\n",
    "targets = torch.tensor([phase_vigilant['GT_w0s'], phase_vigilant['GT_R0s']]).transpose(0,1).float()\n",
    "data = torch.cat([torch.Tensor(phase_vigilant['slope']).unsqueeze(1), torch.Tensor(phase_vigilant['Ds']).unsqueeze(1), torch.Tensor(phase_vigilant['profiles'])],1).float()\n",
    "\n",
    "full_dataset = CustomDataset(data, targets)\n",
    "train_size = int(0.95 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate a model\n",
    "fc_model_w0_R0 = createModel( input_size  = 2+len(phase_vigilant['profiles'][0]), n_layers =10, \n",
    "                    neurons_per_layer = [10,10,5,5,4,4,3,3,2,2],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None) \n",
    "\n",
    "# nn package also has different loss functions.\n",
    "# we use mean square error for the regression task\n",
    "criterion = lambda est,targ,model : MSE_L1_loss(est,targ, model) \n",
    "\n",
    "# we use the optim package to apply\n",
    "# stochastic gradient descent for our parameter updates\n",
    "#optimizer = torch.optim.SGD(fc_model_w0_R0.parameters(), lr=1e-3, momentum=0.9, weight_decay=0) # built-in L2 weight decay\n",
    "optimizer = torch.optim.Adagrad(fc_model_w0_R0.parameters(), lr=0.1, lr_decay=0.001, weight_decay=0.3, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optimizer = torch.optim.RMSprop(fc_model_w0_R0.parameters(), lr=0.02, alpha=0.8, eps=1e-08, weight_decay=0.1, momentum=0.1, centered=False)\n",
    "\n",
    "# Execute the training and validation\n",
    "losses = full_training_loop(fc_model_w0_R0, criterion, optimizer, train_loader, val_loader, epochs=100, print_loss_every_batches=300)\n",
    "\n",
    "print(\"\\n\\n\\nFINAL VALIDATION! ####################################################\\n\\n\")\n",
    "validate(criterion, fc_model_w0_R0, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fc_model_w0_R0)\n",
    "print(fc_model_w0_R0.parameters())\n",
    "# Print model's state_dict\n",
    "print(\"\\n\\nModel's state_dict:\")\n",
    "for param_tensor in fc_model_w0_R0.state_dict():\n",
    "    print(param_tensor, \"\\t\", fc_model_w0_R0.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'thumb_model_w0': thumb_model_w0.state_dict(),\n",
    "            'thumb_model_R0_1': thumb_model_R0_1.state_dict(),\n",
    "            'thumb_model_R0_2': thumb_model_R0_2.state_dict(),\n",
    "            'fc_model_w0_R0': fc_model_w0_R0.state_dict()\n",
    "            }, f\"./OUTPUT/EMPIRICAL_LAWS/{experiment_name}/ML_Models.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use the computed models to get estimates in experimental images\n",
    "We first reload the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumb_model_w0 = createModel( input_size  = 3, n_layers=1, \n",
    "                    neurons_per_layer = [1],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None)\n",
    "thumb_model_R0_1 = createModel( input_size  = 3, n_layers=1, \n",
    "                    neurons_per_layer = [1],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None)\n",
    "thumb_model_R0_2 = createModel( input_size  = 3, n_layers=1, \n",
    "                    neurons_per_layer = [1],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None)\n",
    "fc_model_w0_R0 = createModel( input_size  = 2+len(phase_vigilant['profile'][0]), n_layers =10, \n",
    "                    neurons_per_layer = [5,5,5,4,4,3,3,2,2,2],  use_relu_in_last=False,\n",
    "                    parameter_initialiser=None) \n",
    "\n",
    "checkpoint = torch.load(f\"./OUTPUT/EMPIRICAL_LAWS/{experiment_name}/ML_Models.pt\")\n",
    "thumb_model_w0.load_state_dict(checkpoint['thumb_model_w0'])\n",
    "thumb_model_R0_1.load_state_dict(checkpoint['thumb_model_R0_1'])\n",
    "thumb_model_R0_2.load_state_dict(checkpoint['thumb_model_R0_2'])\n",
    "fc_model_w0_R0.load_state_dict(checkpoint['fc_model_w0_R0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "# Create and display a FileChooser widget\n",
    "fc = FileChooser('/home/oiangu/Desktop/Conical_Refraction_Polarimeter')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_full_path=fc.selected\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "if im is None:\n",
    "    print(f\" Unable to import image {image_full_path}\")\n",
    "    raise ValueError\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Gradient algorithm (also Mirror and Rotation ya que estamos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from GPU_Classes import *\n",
    "from Image_Manager import *\n",
    "from Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm, Gradient_Algorithm\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image=im.copy()\n",
    "saturation=1\n",
    "pol_or_CR=\"pol\" \n",
    "deg_or_rad=\"deg\" # for the final output\n",
    "image_depth=8 # or 16 bit per pixel\n",
    "image_shortest_side=540\n",
    "randomization_seed=666\n",
    "recenter_average_image=False\n",
    "\n",
    "\n",
    "# 4. GRAVICENTER iX and PROFILES ######################################\n",
    "X=int(image_shortest_side*1.4/2)\n",
    "plot_3d_finnes=0.3 # value that should go in (0,1]. 1 means all the pixels will be ploted in the 3d plot, 0.5 only half of them\n",
    "\n",
    "\n",
    "\n",
    "# 5. POLARIZATION RELATIVE ANGLES ###################################\n",
    "# Mirror with affine interpolation & Rotation Algorithms will be employed\n",
    "# Each using both Fibonacci and Quadratic Fit Search\n",
    "# Also a gradient algorithm\n",
    "theta_min_Rot=-np.pi\n",
    "theta_max_Rot=np.pi\n",
    "rad_min_Grav=3\n",
    "rad_max_Grav=image_shortest_side\n",
    "theta_min_Mir=0\n",
    "theta_max_Mir=np.pi\n",
    "initial_guess_delta_rad=0.1\n",
    "initial_guess_delta_pix=10\n",
    "use_exact_gravicenter=True\n",
    "precision_quadratic=1e-10\n",
    "max_it_quadratic=100\n",
    "cost_tolerance_quadratic=1e-14\n",
    "precision_fibonacci=1e-10\n",
    "max_points_fibonacci=100\n",
    "cost_tolerance_fibonacci=1e-14\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "im_type=np.uint16 if image_depth==16 else np.uint8\n",
    "max_intensity=65535 if image_depth==16 else 255\n",
    "np.random.seed(randomization_seed)\n",
    "polCR=1 if pol_or_CR=='CR' else 0.5\n",
    "\n",
    "# 4. GRAVICENTER iX ###############################\n",
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X, interpolation_flag=None):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    if interpolation_flag==None:\n",
    "        return centered_image\n",
    "    else:\n",
    "        # We compute the center of gravity of the cropped images, if everything was made allright\n",
    "        # they should get just centered in the central pixels number X+1 (index X)\n",
    "        g_centered = compute_intensity_gravity_center(centered_image)\n",
    "\n",
    "        # We now compute a floating translation of the image so that the gravicenter is exactly\n",
    "        # centered at pixel (607.5, 607.5) (exact center of the image in pixel coordinates staring\n",
    "        # form (0,0) and having size (607*2+1)x2), instead of being centered at the beginning of\n",
    "        # around pixel (607,607) as is now\n",
    "        translate_vectors = X+0.5-g_centered #[ 2(h,w)]\n",
    "        T = np.float64([[1,0, translate_vectors[1]], [0,1, translate_vectors[0]]])\n",
    "        return cv2.warpAffine( centered_image, T, (X*2+1, X*2+1),\n",
    "                    flags=interpolation_flag) # interpolation method\n",
    "\n",
    "image = np.where( image<=(max_intensity*saturation), image, max_intensity*saturation)\n",
    "image = compute_raw_to_centered_iX(image, X)\n",
    "# saturated and iX\n",
    "\n",
    "# 6. POLARIZATION RELATIVE ANGLES ###################################\n",
    "# Mirror with affine interpolation & Rotation Algorithms will be employed\n",
    "# Each using both Fibonacci and Quadratic Fit Search\n",
    "# Results will be gathered in a table and outputed as an excel csv\n",
    "# Mock Image Loader\n",
    "# Computar el angulo de cada uno en un dataframe donde una de las entradas sea results y haya un result per fibo qfs y per rotation y mirror affine. Y luego procesar en un 7º paso estos angulos para obtener los angulos relativos etc y perhaps hacer tablucha con ground truth menos el resulting delta angle medido por el algoritmo\n",
    "image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "# Define the ROTATION ALGORITHM\n",
    "rotation_algorithm = Rotation_Algorithm(image_loader,\n",
    "    theta_min_Rot, theta_max_Rot, None,\n",
    "    initial_guess_delta_rad, use_exact_gravicenter, initialize_it=False)\n",
    "\n",
    "# Define the Affine Mirror algorithm\n",
    "mirror_algorithm = Mirror_Flip_Algorithm(image_loader,\n",
    "    theta_min_Mir, theta_max_Mir, None,\n",
    "    initial_guess_delta_rad, method=\"aff\", left_vs_right=True, use_exact_gravicenter=use_exact_gravicenter, initialize_it=False)\n",
    "\n",
    "# Define the Gradient algorithm\n",
    "gradient_algorithm = Gradient_Algorithm(image_loader,\n",
    "        rad_min_Grav, rad_max_Grav,\n",
    "        initial_guess_delta_pix,\n",
    "        use_exact_gravicenter)\n",
    "\n",
    "# A dictionary to gather all the resulting angles for each image\n",
    "\n",
    "individual_image_results = { 'polarization_method':[], 'optimization_1d':[], 'found_phiCR':[], 'predicted_opt_precision':[] }\n",
    "\n",
    "def to_result_dict(result_dict, alg, alg_name, opt_name, im_names):\n",
    "    for key, name in zip(alg.times.keys(), im_names):\n",
    "        result_dict['polarization_method'].append(alg_name)\n",
    "        result_dict['optimization_1d'].append(opt_name)\n",
    "        result_dict['found_phiCR'].append(alg.angles[key])\n",
    "        result_dict['predicted_opt_precision'].append(alg.precisions[key])\n",
    "image_container=np.zeros( (1, 2*X+1, 2*X+1), dtype=np.float64)\n",
    "image_names=[]\n",
    "# charge the image\n",
    "image_container[0]=image.astype(np.float64)\n",
    "image_names.append(f\"{fc.selected_filename}\")\n",
    "\n",
    "# charge the image loader:\n",
    "image_loader.import_converted_images_as_array(image_container, image_names)\n",
    "# Execute the Rotation and Mirror Algorithms:\n",
    "# ROTATION ######\n",
    "interpolation_flag=None\n",
    "# the interpolation algorithm used in case we disbale its usage for the iX image obtention will be the Lanczos one\n",
    "rotation_algorithm.interpolation_flag=interpolation_flag if interpolation_flag is not None else cv2.INTER_CUBIC\n",
    "rotation_algorithm.reInitialize(image_loader)\n",
    "rotation_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Rotation\", \"Quadratic\", image_names)\n",
    "rotation_algorithm.reInitialize(image_loader)\n",
    "rotation_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Rotation\", \"Fibonacci\", image_names)\n",
    "\n",
    "# MIRROR #######\n",
    "mirror_algorithm.interpolation_flag=interpolation_flag if interpolation_flag is not None else cv2.INTER_CUBIC\n",
    "mirror_algorithm.reInitialize(image_loader)\n",
    "mirror_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Mirror\", \"Quadratic\", image_names)\n",
    "mirror_algorithm.reInitialize(image_loader)\n",
    "mirror_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Mirror\", \"Fibonacci\", image_names)\n",
    "\n",
    "# GRADIENT #######\n",
    "optimal_masked_gravs={}\n",
    "optimal_radii={}\n",
    "grav=compute_intensity_gravity_center(image)\n",
    "\n",
    "gradient_algorithm.interpolation_flag=interpolation_flag if interpolation_flag is not None else cv2.INTER_CUBIC\n",
    "gradient_algorithm.reInitialize(image_loader)\n",
    "gradient_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "to_result_dict( individual_image_results, gradient_algorithm, \"Gradient\", \"Quadratic\", image_names)\n",
    "optimal_masked_gravs['quad'] = gradient_algorithm.masked_gravs[f\"Quadratic_Search_{fc.selected_filename}\"]\n",
    "optimal_radii['quad'] = gradient_algorithm.optimals[f\"Quadratic_Search_{fc.selected_filename}\"]\n",
    "\n",
    "gradient_algorithm.reInitialize(image_loader)\n",
    "gradient_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "to_result_dict( individual_image_results, gradient_algorithm, \"Gradient\", \"Fibonacci\", image_names)\n",
    "\n",
    "optimal_masked_gravs['fibo'] = gradient_algorithm.masked_gravs[f\"Fibonacci_Search_{fc.selected_filename}\"]\n",
    "optimal_radii['fibo'] = gradient_algorithm.optimals[f\"Fibonacci_Search_{fc.selected_filename}\"]\n",
    "\n",
    "masked_grav=(optimal_masked_gravs['quad']+optimal_masked_gravs['fibo'])/2.0\n",
    "optimal_radi = (optimal_radii['quad']+optimal_radii['fibo'])/2\n",
    "print(f\"\\n\\nOptimal masked gravs: {optimal_masked_gravs}\\nOptimal radii: {optimal_radii}\\n\\n\\n\")\n",
    "print(pd.DataFrame.from_dict(individual_image_results))\n",
    "\n",
    "# 7. PROCESS FINAL RESULTS ##########################################\n",
    "def angle_to_pi_pi( angle): # convert any angle to range ()-pi,pi]\n",
    "    angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\n",
    "    return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle    \n",
    "\n",
    "average_found_phiCR=np.mean([angle_to_pi_pi(phi) for i,phi in enumerate(individual_image_results['found_phiCR']) if individual_image_results['polarization_method'][i]!='Gradient'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE PROFILES #################################################\n",
    "pix_spacing=10\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.rc('font', size=8) \n",
    "\n",
    "prof_x=image[int(grav[0])]\n",
    "prof_y=image[:,int(grav[1])]\n",
    "fig = plt.figure(figsize=(2*4.5, 2*4.5))\n",
    "axes=fig.subplots(2,2)\n",
    "cm=axes[0, 0].imshow(image, cmap='viridis')\n",
    "axes[0,0].plot([grav[1],masked_grav[1]], [grav[0], masked_grav[0]], '-w', markersize=1)\n",
    "axes[0,0].plot(grav[1], grav[0], 'or', markersize=4, label=\"Full image gravicenter\")\n",
    "axes[0,0].plot(masked_grav[1], masked_grav[0], 'ow', markersize=4, label=\"Masked circle gravicenter\")\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True)\n",
    "axes[0,1].scatter(prof_y, np.arange(len(prof_y)), s=1, label=f'Intensity profile in y')\n",
    "axes[0,1].set_ylim((0,len(prof_y)))\n",
    "axes[0,1].invert_yaxis()\n",
    "axes[1,0].scatter(np.arange(len(prof_x)), prof_x, s=1, label=f'Intensity profile in x')\n",
    "axes[1,0].set_xlim((0,len(prof_x)))\n",
    "axes[1,0].invert_yaxis()\n",
    "axes[0,0].set_xlabel(\"x (pixels)\")\n",
    "#axes[0,0].set_ylabel(\"y (pixels)\")\n",
    "axes[0,1].set_xlabel(\"Raw Intensity along Gravicenter\")\n",
    "axes[0,1].set_ylabel(\"y (pixels)\")\n",
    "axes[1,0].set_ylabel(\"Raw Intensity along Gravicenter\")\n",
    "axes[1,0].set_xlabel(\"x (pixels)\")\n",
    "axes[1,0].grid(True)\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "cols = np.broadcast_to( np.arange(X*2+1), (X*2+1,X*2+1)) #[h,w]\n",
    "rows = cols.swapaxes(0,1) #[h,w]\n",
    "slope=(masked_grav[0]-grav[0])/(masked_grav[1]-grav[1])\n",
    "mask=(rows<( slope*(cols-masked_grav[1]) +masked_grav[0]+pix_spacing )) & (rows>( slope*(cols-masked_grav[1]) +masked_grav[0]-pix_spacing ))\n",
    "\n",
    "filtered_image=np.where(mask, image, 0)\n",
    "filtered_line=np.where(mask, image, 200)\n",
    "axes[0,0].imshow(filtered_line, alpha=0.1, label=\"Optimal Radious Mask\")\n",
    "prof_filt=np.sum(filtered_image,axis=0)\n",
    "axes[1,1].scatter(np.arange(len(prof_filt))*np.sqrt(1+slope**2), prof_filt , s=1, label=f'Intensity profile along main axis')\n",
    "axes[1,1].grid()\n",
    "axes[1,1].set_ylabel(f'Reduced Intensity profile along main axis')\n",
    "axes[1,1].set_xlabel(\"Pixels along the main axis\") \n",
    "fig.suptitle(f\"Raw Intesity Profiles for Image{fc.selected_filename}\\nBest grav-masked_grav={optimal_radi:3.5} pix   Average found phiCR={average_found_phiCR:3.5} rad\\nEstimated radious={optimal_radi/0.689095:4.9} pix\")\n",
    "cbax=fig.add_axes([0.1,0.91,0.4,0.01])\n",
    "fig.colorbar(cm, ax=axes[0,0], cax=cbax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the ML models and the LS solutions on the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumb_model_w0\n",
    "thumb_model_R0_1 \n",
    "thumb_model_R0_2\n",
    "fc_model_w0_R0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
