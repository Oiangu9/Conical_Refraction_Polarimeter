{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Haz los push pop en el orden más adecuado y arregla los desastres.\n",
    "Kizas primero pull bixetan, ta gero push en Melanie, pull hemen. BAdezpada kopixe ta pege kanpoan jupyterrak\n",
    "- Ein mock example bat de cada cosa que he implementado hasta que no tenga errores.\n",
    "Dana, inkluso lo de el dump y tal del saving class instances.\n",
    "- Gero zuzendu beko gauza danak eta prepareu pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jarri bi aldiz (A) atala baten con non-noisy ta bestien con noisy data\n",
    "- Ikusi zelan eitzen dan kalse bat kustoma gordetako memorian eta berriro atarateko, si depende de más clases.\n",
    "- Ikusi hydran zelan zan gordetie clase bat hobeto\n",
    "- Ikusi gordetako imagenak usando matplotlib por ejemplo zelan eitzen genun hydran\n",
    "- Ikusi tripleten zelan zan exaktamente preprozesamentue!\n",
    "- Behin Dim egokixe aukeratute emaitzak ikusi ostien, jarri hurrengo seksiñoa errepikatute asakotan edo loop bat agian eta bata bestien atzetik embedder danak trainie eta gordetie!\n",
    "- Sólo los supervised embedding learners tiene sentido usarlos como métrica en lugar del L2 pa lo de la simulación...y quizás para lo del KNN tb. Lo ke pasa es que pra el FC ya tiene sentido usar un non-superivsed embedder.\n",
    "- Pa entrenar la KNN para el Triplet, haz lo mismo hasta lo de preprocess fct y luego ya salta a su sección.\n",
    "- Gero implemente noisy image pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart and Run All Function to do the whole pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "def restart_run_all():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                IPython.notebook.kernel.restart();\n",
    "                setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 10000)\n",
    "                \n",
    "            </script>\n",
    "        '''\n",
    "    ))\n",
    "#restart_run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) Determine Adequate Embedding Space Dimensionality\n",
    "Using MDA (to see when the manifolds torsion starts), using KNN to see when locality of same class can be preserved well, also UMAP for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 21:08:48.240011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28107/1248393840.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/umap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparametric_umap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParametricUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     warn(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/umap/parametric_umap.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     warn(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m   _current_module.__path__ = (\n\u001b[1;32m    686\u001b[0m       [_module_util.get_parent_dir(keras)] + _current_module.__path__)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/api/_v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_print_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/api/_v1/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/api/_v1/keras/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmobilenet_v3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnasnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.manifold as manifold\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import umap\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label\n",
    "    \n",
    "# Train set Input!\n",
    "GT_file_path_train = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/GROUND_TRUTHS.json\"\n",
    "images_dir_path_train =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/\" \n",
    "\n",
    "GT_file_path_test = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST\"\n",
    "\n",
    "num_images=700\n",
    "num_images_test = 200  # for the UMAP and NNE curve\n",
    "\n",
    "num_decimals = 2\n",
    "random_seed = 666\n",
    "n_jobs=11\n",
    "exp_name=\"Noisy_Dataset\"\n",
    "\n",
    "emb_dims= [1,4,9,16] #[1,2,3,4,5,7,10,13,16,20]\n",
    "\n",
    "save_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Finding_Dimensionality_of_Manifold\"\n",
    "os.makedirs( save_stuff_path, exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageDataset(GT_file_path_train, images_dir_path_train)\n",
    "test_data = ImageDataset(GT_file_path_test, images_dir_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "random_indices = np.random.choice(range(len(training_data)), num_images, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X21 = training_data[0][0].shape[1]\n",
    "X = np.zeros( (num_images, X21**2), dtype=np.float32)\n",
    "y = np.zeros((num_images), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices):\n",
    "    im, lab = training_data[idx]\n",
    "    X[j, :] = im[0].flatten()\n",
    "    y[j] = lab   \n",
    "\n",
    "y_categoric = (np.around(y+np.pi, num_decimals)*10**num_decimals).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data for KNN tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices_test = np.random.choice(range(len(test_data)), num_images_test, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X_test = np.zeros( (num_images_test, X21**2), dtype=np.float32)\n",
    "y_test= np.zeros((num_images_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_test):\n",
    "    im, lab = test_data[idx]\n",
    "    X_test[j, :] = im[0].flatten()\n",
    "    y_test[j] = lab   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS # y not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDS\n",
    "args = {'metric':True, 'n_init':4, 'max_iter':50, 'dissimilarity':'euclidean'}\n",
    "metrics['MDS']=[]\n",
    "\n",
    "for dim in emb_dims:\n",
    "    embedder = manifold.MDS(n_components=dim, metric=args['metric'], n_init=args['n_init'],\n",
    "                    max_iter=args['max_iter'], n_jobs=n_jobs, random_state=random_seed, dissimilarity=args['dissimilarity'])\n",
    "    \n",
    "    embedder.fit(X)\n",
    "    metrics['MDS'].append(embedder.stress_)\n",
    "    print(f\"Embedder of dim {dim} done!\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.plot(emb_dims, metrics['MDS'])\n",
    "ax.set_ylim((0, max(metrics['MDS'])))\n",
    "ax.set_title(\"MDS Stress by Embedding Space Dimension\\n\"+exp_name)\n",
    "ax.grid(True)\n",
    "plt.savefig(f\"{save_stuff_path}/MDS_stress_{exp_name}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLE # y not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLE\n",
    "args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 9,\"emb_dims\": emb_dims, 'max_iter':10}\n",
    "# Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "methods = [\"standard\", \"ltsa\", \"hessian\"]\n",
    "\n",
    "for method in methods:\n",
    "    args['method']=method\n",
    "    metrics[\"LLE_\"+method]=[]\n",
    "    for dim in emb_dims:\n",
    "        embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "              n_components=dim, max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs) \n",
    "        embedder = embedder.fit(X)\n",
    "        metrics[\"LLE_\"+method].append(embedder.reconstruction_error_)\n",
    "        print(f\"Done dim {dim}!\")\n",
    "    print(f\"Done method {method}\")\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    ax.plot(emb_dims, metrics[\"LLE_\"+method], 'o-')\n",
    "    ax.set_ylim((0, max(metrics[\"LLE_\"+method])))\n",
    "    ax.set_title(f\"LLE {method} Reconstruction Error\\n by Embedding Space Dimension\\n\"+exp_name)\n",
    "    ax.grid(True)\n",
    "    plt.savefig(f\"{save_stuff_path}/LLE_{method}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "for method in methods:\n",
    "    ax.plot(emb_dims, metrics[\"LLE_\"+method], 'o-',label=method)\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_title(f\"LLE Reconstruction Error\\n by Embedding Space Dimension\\n\"+exp_name)\n",
    "ax.grid(True)\n",
    "plt.savefig(f\"{save_stuff_path}/LLE_{exp_name}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP # y used in continous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_sk_KNN = {'n_neighbors':20, 'weights':'uniform', 'algorithm':'auto', 'leaf_size':8, 'p':2,\n",
    "               'metric':'minkowski', 'n_jobs':n_jobs}\n",
    "\n",
    "# UMAP\n",
    "args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':15, 'metric':'euclidean', 'n_epochs':None,\n",
    "       'target_metric':'l2'}\n",
    "# Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "metrics[\"UMAP\"]=[]\n",
    "for dim in emb_dims:\n",
    "    embedder = umap.UMAP(n_components=dim, min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "            n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "            target_metric=args['target_metric']) \n",
    "    embedder = embedder.fit(X,y)\n",
    "    print(f\"Dimension {dim} trained\")\n",
    "    KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "            weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "            leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "            metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "    KNN = KNN.fit(embedder.embedding_, y)\n",
    "    metrics[\"UMAP\"].append(1-KNN.score(embedder.transform(X_test),y_test))\n",
    "    print(f\"KNN ran\")\n",
    "    \n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.plot(emb_dims, metrics['UMAP'], 'o-')\n",
    "ax.set_ylim((0, max(metrics['UMAP'])))\n",
    "ax.set_title(\"UMAP Embedding 1-KNN Regression Score\\n\"+exp_name)\n",
    "ax.grid(True)\n",
    "plt.savefig(f\"{save_stuff_path}/UMAP_score_knn_{exp_name}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCA # y used in categorical version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_sk_KNN = {'n_neighbors':20, 'weights':'uniform', 'algorithm':'auto', 'leaf_size':8, 'p':2,\n",
    "               'metric':'minkowski', 'n_jobs':n_jobs}\n",
    "\n",
    "# NCA\n",
    "args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':50, }\n",
    "# init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "metrics[\"NCA\"]=[]\n",
    "for dim in emb_dims:\n",
    "    embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=dim, init=args['init'],\n",
    "                                max_iter=args['max_iter'], random_state=random_seed)\n",
    "    X_emb = embedder.fit_transform(X,y_categoric)\n",
    "    print(f\"Dimension {dim} done!\")\n",
    "    KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "            weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "            leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "            metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "    KNN = KNN.fit(X_emb, y)\n",
    "    metrics[\"NCA\"].append(1-KNN.score(embedder.transform(X_test), y_test))\n",
    "    print(\"KNN done!\")\n",
    "      \n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.plot(emb_dims, metrics['NCA'], 'o-')\n",
    "ax.set_ylim((0, max(metrics['NCA'])))\n",
    "ax.set_title(\"NCA Embedding 1-KNN Regression Score\\n\"+exp_name)\n",
    "ax.grid(True)\n",
    "plt.savefig(f\"{save_stuff_path}/NCA_score_knn_{exp_name}.png\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gathered metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# the json file where the output must be stored\n",
    "out_metrics = open(f\"{save_stuff_path}/Metrics_{exp_name}.json\", \"w\")\n",
    "  \n",
    "json.dump({'Emb_dims':emb_dims, 'Metrics':metrics}, out_metrics)\n",
    "  \n",
    "out_metrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa ver la variedad nooisy y non-noisy, porke los noisy pueden hacer de puente de einstein rosen sino entre partes del manifold\n",
    "# pa hacer embedding spaces para knn o fc o pa usarlo de simulated metric en plan euclidean ya no lo sé...\n",
    "# supongo que si es un embedding ke mira los GT entonces noisy, si no...sólo se fija en la topología digamos...mejor non-noisy pa evitar puentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) Class to Use Embedding Spaces for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_sk_KNN = {'n_neighbors':50, 'weights':'distance', 'algorithm':'auto', 'leaf_size':30, 'p':2,\n",
    "               'metric':'minkowski', 'n_jobs':11}\n",
    "\n",
    "class KNN_Regressor():\n",
    "    def __init__(self, embedder_func, args_sk_KNN):\n",
    "        # ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\n",
    "        # ‘uniform’, ‘distance’\n",
    "        self.embedder_func = embedder_func\n",
    "        self.KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "                    weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "                    leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "                    metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, X, y, already_embedded_X=False): # X [N_samples, dim_feats], y [N_samples] # y can be to regression floats!\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X) # [N_samples, dim_feats]\n",
    "        self.KNN = self.KNN.fit(X, y)\n",
    "        self.fitted = True\n",
    "    \n",
    "    def score(self, X, y, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.score(X,y)\n",
    "        \n",
    "    def predict(self, X, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.predict(X)\n",
    "    \n",
    "class Sklearn_embedder():\n",
    "    def __init__(self, embedder, preprocess_fct):\n",
    "        self.preprocess_fct = preprocess_fct\n",
    "        self.embedder = embedder\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.embedder.transform( self.preprocess_fct(X) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (C) Generate Embedding Space Transformers\n",
    "## Input Image Dataset to train the embedders and choose Embedder Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import umap\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Dataset and **training** hyperparameters for the Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_file_path_train = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/GROUND_TRUTHS.json\"\n",
    "images_dir_path_train =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/\" \n",
    "\n",
    "num_images=500\n",
    "num_decimals = 3\n",
    "random_seed = 666\n",
    "n_jobs=11\n",
    "\n",
    "emb_dims=10\n",
    "\n",
    "save_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/\"\n",
    "os.makedirs(save_stuff_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageDataset(GT_file_path_train, images_dir_path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Embedder to use and its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA -> Existe la incremental PCA por si es massa grande el dataset!\n",
    "args = {'exp':'PCA','emb_dims':emb_dims, \"whiten\":True}\n",
    "embedder = sk.decomposition.PCA(n_components=args['emb_dims'], whiten=args['whiten'], random_state=random_seed)\n",
    "\n",
    "# KPCA\n",
    "args = {'exp':'KPCA_rbf', 'emb_dims':emb_dims, 'kernel':'rbf', 'fit_inverse':True, 'max_iter':50}\n",
    "# kernels: linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘cosine’, ‘precomputed’\n",
    "embedder = sk.decomposition.KernelPCA(n_components=args['emb_dims'], kernel=args['kernel'], \n",
    "                fit_inverse_transform=args['fit_inverse'], max_iter=args['max_iter'], \n",
    "                        random_state=random_seed, n_jobs=n_jobs)\n",
    "\n",
    "# LLE \n",
    "args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 500,\"emb_dims\": emb_dims, 'max_iter':50}\n",
    "# Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "              n_components=args['emb_dims'], max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs)\n",
    "\n",
    "# UMAP -> uses y continous\n",
    "args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':500, 'metric':'hamming', 'n_epochs':None,\n",
    "       'target_metric':'l2'}\n",
    "# Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "            n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                    target_metric=args['target_metric']) \n",
    "\n",
    "# ISOMAP\n",
    "args = {'exp':'ISOMAP', 'n_neighbors':10, 'emb_dims':emb_dims, 'max_iter':50, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                    max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                    metric=args['metric'], p=2)\n",
    "\n",
    "# NCA -> uses y categorical\n",
    "args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':50 }\n",
    "# init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                max_iter=args['max_iter'], random_state=random_seed)\n",
    "\n",
    "# Triplet\n",
    "#args = {'exp':'TRIPLET_CNN', 'emb_dims':10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot example inputted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_array = plt.subplots(7, 7)\n",
    "axes = ax_array.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    im, lab = training_data[i]\n",
    "    ax.imshow(im[0])\n",
    "plt.setp(axes, xticks=[], yticks=[], frame_on=False)\n",
    "plt.tight_layout(h_pad=0.4, w_pad=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate proper finite dataset for Embedders! X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "random_indices = np.random.choice(range(len(training_data)), num_images, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X21 = training_data[0][0].shape[1]\n",
    "X = np.zeros( (num_images, X21**2), dtype=np.float32)\n",
    "y = np.zeros((num_images), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices):\n",
    "    im, lab = training_data[idx]\n",
    "    X[j, :] = im[0].flatten()\n",
    "    y[j] = lab   \n",
    "\n",
    "y_categoric = (np.around(y+np.pi, num_decimals)*10**num_decimals).astype(int)\n",
    "\n",
    "# for plotting purposes\n",
    "df = pd.DataFrame({'y':y})\n",
    "df['phiCR'] = df[\"y\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply pre-embedding pre-process function to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_name = \"normalize_to_max_and_iX\"\n",
    "\n",
    "import torch\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images\n",
    "\n",
    "def normalize_to_max_and_iX_input_output_flatten(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=302): # images expected to be [N_images, h, w]\n",
    "    images= images.reshape(-1, X*2+1, X*2+1).astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy().reshape(images.shape[0], -1)\n",
    "\n",
    "preprocess_fct = normalize_to_max_and_iX_input_output_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_fct(X) # apply preprocess funct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Embedding Training and KNN Training after it\n",
    "Note that the embedders alone can be also used as metric for the simulation coordinate descent or Nedler Mead.\n",
    "\n",
    "And note also that the embedder is still required for inference in KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%d_%m_%Y_%H-M-%S\")\n",
    "f_name_emb = f\"{args['exp']}_EMBEDDER_n_images_{num_images}_emb_dims_{emb_dims}_pre_process_{pre_process_name}_n_decimals_{num_decimals}_seed_{random_seed}_date_{date}.sav\"\n",
    "f_name_knn = f\"{args['exp']}_KNN_n_images_{num_images}_emb_dims_{emb_dims}_pre_process_{pre_process_name}_n_decimals_{num_decimals}_seed_{random_seed}_date_{date}.sav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['exp']=='NCA': # then y categorical\n",
    "    X_embedded = embedder.fit_transform(X, y=y_categoric)\n",
    "else: # in relaity only UMAP uses y from the rest, but it can handle y continous\n",
    "    X_embedded = embedder.fit_transform(X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor = KNN_Regressor( Sklearn_embedder( embedder, preprocess_fct), args_sk_KNN)\n",
    "knn_regressor.fit(X_embedded, y, already_embedded_X=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save trained embedder and knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_stuff_path+f_name_emb, 'wb') as f:\n",
    "    pickle.dump(embedder, f)\n",
    "with open(save_stuff_path+f_name_knn, 'wb') as f:\n",
    "    pickle.dump(knn_regressor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Trained Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder = pickle.load((open(save_stuff_path+\"NCA_EMBEDDER_n_images_500_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_3_seed_666_date_13_06_2022_18-M-28.sav\", 'rb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize resulting embedding in lower dimensions using PCA, first 2d PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded = embedder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(X_embedded)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "df['principal component 1'] = principalDf['principal component 1']\n",
    "df['principal component 2'] = principalDf['principal component 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bokeh and px see 2d PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig=px.scatter(df, x=\"principal component 1\", y=\"principal component 2\", color=\"y\")\n",
    "fig.update_traces(marker={\"size\":5})\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "fig.write_image(f\"{save_stuff_path}/{f_name_emb}_2d.png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, LinearColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "def embeddable_image(data):\n",
    "    img_data = data.values.reshape(X21,X21).astype(np.uint8)\n",
    "    image = Image.fromarray(img_data, mode='L').resize((64, 64), Image.BICUBIC)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='png')\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return 'data:image/png;base64,' + base64.b64encode(for_encoding).decode()\n",
    "\n",
    "df['image'] = pd.DataFrame(data=X, columns=list(range(X.shape[1]))).apply(embeddable_image, axis=1)\n",
    "\n",
    "datasource = ColumnDataSource(df)\n",
    "color_mapping = LinearColorMapper(\n",
    "    palette='Magma256',\n",
    "    low=y.min(),\n",
    "    high=y.max()\n",
    ")\n",
    "\n",
    "plot_figure = figure(\n",
    "    title='PCA projection of the CR dataset',\n",
    "    plot_width=800,\n",
    "    plot_height=800,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style='font-size: 16px; color: #224499'>phiCR:</span>\n",
    "        <span style='font-size: 18px'>@phiCR</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "plot_figure.circle(\n",
    "    'principal component 1',\n",
    "    'principal component 2',\n",
    "    source=datasource,\n",
    "    color=dict(field='phiCR', transform=color_mapping),\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=7\n",
    ")\n",
    "show(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now 3d PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "principalComponents = pca.fit_transform(X_embedded)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "df['principal component 1'] = principalDf['principal component 1']\n",
    "df['principal component 2'] = principalDf['principal component 2']\n",
    "df['principal component 3'] = principalDf['principal component 3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter_3d(df, x=\"principal component 1\", y=\"principal component 2\", z=\"principal component 3\", color=\"y\")\n",
    "fig.update_traces(marker={\"size\":3})\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "fig.write_image(f\"{save_stuff_path}/{f_name_emb}_3d.png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save just in case the generated embedding and the employed indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Initialize the hdf5 dataset saver\n",
    "h5f = h5py.File(f\"{save_stuff_path}/{args['exp_name']}_Training_Embedding_date_{datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}.h5\", 'a') # append if exists, create if not\n",
    "h5f.create_dataset(\"Embeddings\", data= embedded_training, compression=\"lzf\", shuffle=True)\n",
    "h5f.create_dataset(\"phiCRs\", data= y, compression=\"lzf\", shuffle=True)\n",
    "h5f.create_dataset(\"ImageIndexes\", data= random_indices, compression=\"lzf\", shuffle=True)\n",
    "\n",
    "h5f.flush()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (D) Design Embedder Functions for the KNN\n",
    "### (D.1) Using SK embedders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sklearn_embedder():\n",
    "    def __init__(self, embedder, preprocess_fct):\n",
    "        self.preprocess_fct = preprocess_fct\n",
    "        self.embedder = embedder\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.embedder.transform( self.preprocess_fct(X) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (D.2) Using Torch Embedder of Triplet Loss and train KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.manifold as manifold\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import umap\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label\n",
    "    \n",
    "# Train set Input!\n",
    "GT_file_path_train = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/GROUND_TRUTHS.json\"\n",
    "images_dir_path_train =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/\" \n",
    "\n",
    "GT_file_path_test = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST\"\n",
    "\n",
    "num_images=700\n",
    "num_images_test = 200  # for the UMAP and NNE curve\n",
    "\n",
    "num_decimals = 2\n",
    "random_seed = 666\n",
    "n_jobs=11\n",
    "exp_name=\"Noisy_Dataset\"\n",
    "\n",
    "emb_dims= [1,4,9,16] #[1,2,3,4,5,7,10,13,16,20]\n",
    "\n",
    "save_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Finding_Dimensionality_of_Manifold\"\n",
    "os.makedirs( save_stuff_path, exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageDataset(GT_file_path_train, images_dir_path_train)\n",
    "test_data = ImageDataset(GT_file_path_test, images_dir_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "random_indices = np.random.choice(range(len(training_data)), num_images, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X21 = training_data[0][0].shape[1]\n",
    "X = np.zeros( (num_images, X21**2), dtype=np.float32)\n",
    "y = np.zeros((num_images), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices):\n",
    "    im, lab = training_data[idx]\n",
    "    X[j, :] = im[0].flatten()\n",
    "    y[j] = lab   \n",
    "\n",
    "y_categoric = (np.around(y+np.pi, num_decimals)*10**num_decimals).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data for KNN tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices_test = np.random.choice(range(len(test_data)), num_images_test, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X_test = np.zeros( (num_images_test, X21**2), dtype=np.float32)\n",
    "y_test= np.zeros((num_images_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_test):\n",
    "    im, lab = test_data[idx]\n",
    "    X_test[j, :] = im[0].flatten()\n",
    "    y_test[j] = lab   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "class Proximity_Metric_Based_On_Simple_Encoder(nn.Module):\n",
    "    def __init__(self, X=302, feats_1=15, feats_2=20, feats_3=20, feats_4=20,\n",
    "                 prop1=3, prop2=2, prop3=1, av_pool1_div=4, conv4_feat_size=15, av_pool2_div=10, \n",
    "                 out_fc_1=10, out_fc_2=10,\n",
    "                 dropout_p1=0.2, dropout_p2=0.1\n",
    "                ): \n",
    "        # propj is such that the_ image getting out from stage j is propj/prop_{j-1}-ths of the previous (with j=0 being 5)\n",
    "        # clearly, prop_{j-1}>prop_{j}>...\n",
    "        # 2X+1 will be assumed to be divisible by 5\n",
    "        assert((2*X+1)%5==0)\n",
    "        assert(prop1>prop2)\n",
    "        assert(prop2>prop3)\n",
    "        assert((int((prop3*(2*X+1)/5)/av_pool1_div)-conv4_feat_size)>0)\n",
    "        \n",
    "        \n",
    "        super(Proximity_Metric_Based_On_Simple_Encoder, self).__init__()\n",
    "        # in is [epoch_size, 1, 2X+1, 2X+1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=feats_1, \n",
    "                               kernel_size = int((2*X+1)/5*(5-prop1)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        self.conv2 = nn.Conv2d(in_channels=feats_1, out_channels=feats_2, \n",
    "                               kernel_size = int((2*X+1)/5*(prop1-prop2)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_2, prop2*(prop1*(2X+1)/5)/prop1, prop2*(prop1*(2X+1)/5)/prop1]\n",
    "        # that is [epoch_size, feats_2, prop2*(2X+1)/5), prop2*(2X+1)/5)]\n",
    "        self.conv3 = nn.Conv2d(in_channels=feats_2, out_channels=feats_3, \n",
    "                               kernel_size = int((2*X+1)/5*(prop2-prop3)+1), bias=True)\n",
    "        # out conv3 is [epoch_size, feats_3, prop3*(2X+1)/5), prop3*(2X+1)/5)]\n",
    "\n",
    "        self.avPool1 = nn.AvgPool2d(kernel_size= int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=feats_3, out_channels=feats_4, \n",
    "                              kernel_size= int((prop3*(2*X+1)/5)/av_pool1_div+1)-conv4_feat_size+1, bias=True)\n",
    "        # [epoch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        \n",
    "        self.avPool2 = nn.AvgPool2d(kernel_size= int(conv4_feat_size*(1-1/av_pool2_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_4, conv4_feat_size/av_pool2_div+1, conv4_feat_size/av_pool2_div+1]\n",
    "        \n",
    "        #self.in_fc = int(feats_4*(conv4_feat_size/av_pool2_div+1)**2)\n",
    "        self.in_fc = feats_4*((((((2*X+1-int((2*X+1)/5*(5-prop1)+1)+1)\n",
    "                                  -int((2*X+1)/5*(prop1-prop2)+1)+1)\n",
    "                                 -int((2*X+1)/5*(prop2-prop3)+1)+1)\n",
    "                                -int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) -1+1)\n",
    "                               -int((prop3*(2*X+1)/5)/av_pool1_div+1)+conv4_feat_size-1+1)\n",
    "                              -int(conv4_feat_size*(1-1/av_pool2_div)) -1+1)**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc, out_features=out_fc_1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc_1, out_features=out_fc_2, bias=True)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1, inplace=False)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=feats_2)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=feats_4)\n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        \n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, out_fc_2]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Proximity_Metric_Based_On_Corrector(nn.Module):\n",
    "    def __init__(self, S0=2*302+1, S1=2*290+1, S2=2*250+1, S3=2*200+1, S4 = 2*10+1,\n",
    "                 S5 = 2*1+1, S6 =2,\n",
    "                 feats_S1=10, feats_S2=10, feats_S3=20, feats_S4=20, feats_S5 = 20,\n",
    "                 out_fc1=100, out_fc2=10,\n",
    "                 feats_S6 = 25,\n",
    "                 dropout_p=0.1\n",
    "                ): \n",
    "       \n",
    "        super(Proximity_Metric_Based_On_Corrector, self).__init__()\n",
    "        self.Ss = [S0, S1, S2, S3, S4, S5, S6]\n",
    "        self.feats = [1, feats_S1, feats_S2, feats_S3, feats_S4, feats_S5, feats_S6]\n",
    "        self.out_fc1 = out_fc1\n",
    "        self.out_fc2 = out_fc2\n",
    "        # in is [batch_size, 1, S0, S0]\n",
    "        self.conv_S01 = nn.Conv2d(in_channels=1, out_channels=feats_S1, \n",
    "                               kernel_size = S0-S1+1, bias=True) \n",
    "        # out conv_S01 [batch_size, feats_S1, S1, S1]\n",
    "        self.conv_S12 = nn.Conv2d(in_channels=feats_S1, out_channels=feats_S2, \n",
    "                               kernel_size = S1-S2+1, bias=True) \n",
    "        # out conv_S12 [batch_size, feats_S2, S2, S2]\n",
    "        self.conv_S23 = nn.Conv2d(in_channels=feats_S2, out_channels=feats_S3, \n",
    "                               kernel_size = S2-S3+1, bias=True) \n",
    "        # out conv_S23 [batch_size, feats_S3, S3, S3]\n",
    "        \n",
    "        self.conv_S33 = nn.Conv2d(in_channels=feats_S3, out_channels=feats_S3, \n",
    "                               kernel_size = 1, bias=True) \n",
    "        # out conv_S33 [batch_size, feats_S3, S3, S3]\n",
    "        \n",
    "        self.conv_S34 = nn.Conv2d(in_channels=feats_S3, out_channels=feats_S4, \n",
    "                               kernel_size = S3-S4+1, bias=True) \n",
    "        # out conv_S34 [batch_size, feats_S4, S4, S4]\n",
    "        \n",
    "        self.conv_S45 = nn.Conv2d(in_channels=feats_S4, out_channels=feats_S5, \n",
    "                               kernel_size = S4-S5+1, bias=True) \n",
    "        # out conv_S45 [batch_size, feats_S5, S5, S5]\n",
    "        self.conv_S56 = nn.Conv2d(in_channels=feats_S5, out_channels=feats_S6, \n",
    "                               kernel_size = S5-S6+1, bias=True) \n",
    "        # out conv_S56 [batch_size, feats_S6, S6, S6]\n",
    "        \n",
    "        self.in_fc1 = S6*S6*feats_S6\n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc1, out_features=out_fc1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc1, out_features=out_fc2, bias=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_p, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=feats_S3)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(num_features=out_fc1)\n",
    "        \n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        # Conv layers\n",
    "        x = self.relu(self.conv_S01(x)) # [batch_size, feats_S1, S1, S1]\n",
    "        x = self.dropout( self.relu(self.conv_S12(x)) ) # [batch_size, feats_S2, S2, S2]\n",
    "        x = self.relu(self.conv_S23(x)) # [batch_size, feats_S3, S3, S3]\n",
    "        x = self.batchNorm1(self.relu(self.conv_S33(x)))\n",
    "        x = self.relu(self.conv_S34(x))\n",
    "        x = self.relu(self.conv_S45(x))\n",
    "        x = self.relu(self.conv_S56(x))\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc1)\n",
    "        x = self.dropout( self.relu(self.batchNorm2(self.fc1(self.dropout(x)))) )\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                    'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                    'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "\n",
    "save_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "\n",
    "check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "checkpoint = torch.load(save_stuff_path+f\"/NNs/{check_file}\")\n",
    "\n",
    "class Triplet_NN_embedder(): # INPUT DATA IS ASSUMED TO BE NUMPY\n",
    "    def __init__(self, args_NN_embedder, checkpoint_path, device, batch_size=200,\n",
    "                 encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\"):\n",
    "        self.device = device\n",
    "        self.output_to = output_to\n",
    "        self.args_NN_embedder = args_NN_embedder\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.iX = args_NN_embedder['X']\n",
    "        self.out_dim = args_NN_embedder['out_fc2']\n",
    "        if encoder_or_denoiser_based==\"encoder\":\n",
    "            self.model = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_embedder['X'], \n",
    "                feats_1=args_NN_embedder['feats_1'], feats_2=args_NN_embedder['feats_2'], \n",
    "                feats_3=args_NN_embedder['feats_3'], feats_4=args_NN_embedder['feats_4'],\n",
    "                 prop1=args_NN_embedder['prop1'], prop2=args_NN_embedder['prop2'], prop3=args_NN_embedder['prop3'], \n",
    "                av_pool1_div=args_NN_embedder['av_pool1_div'], conv4_feat_size=args_NN_embedder['conv4_feat_size'], \n",
    "                av_pool2_div=args_NN_embedder['av_pool2_div'], \n",
    "                 out_fc_1=args_NN_embedder['out_fc_1'], out_fc_2=args_NN_embedder['out_fc2'],\n",
    "                 dropout_p1=args_NN_embedder['dropout_p1'], dropout_p2=args_NN_embedder['dropout_p2'] )\n",
    "        else:\n",
    "            self.model = Proximity_Metric_Based_On_Corrector(S0=S0, S1=S1, S2=S2, S3=S3, S4=S4, S5=S5, S6=S6,\n",
    "                 feats_S1=feats_S1, feats_S2=feats_S2, feats_S3=feats_S3, feats_S4=feats_S4,\n",
    "                 feats_S5=feats_S5, feats_S6=feats_S6,\n",
    "                 out_fc1=out_fc1, out_fc2=out_fc2,\n",
    "                 dropout_p=dropout_p ) \n",
    "        \n",
    "        self.preprocess = lambda X: (torch.tensor(X.reshape(X.shape[0],self.iX*2+1,self.iX*2+1)).to(device)) if len(X.shape)<3 else (torch.tensor(X).to(device))\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # move model to gpu if available\n",
    "        self.model.to(device)\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.model.eval()\n",
    "    \n",
    "    @torch.no_grad() \n",
    "    def __call__(self, X):\n",
    "        self.model.eval()\n",
    "        if self.output_to==\"numpy\":\n",
    "            Xout = np.zeros((X.shape[0], self.out_dim), dtype=np.float64)\n",
    "            for j in range(0, X.shape[0], self.batch_size):\n",
    "                Xout[j:(j+self.batch_size)] = self.model(self.preprocess(X[j:(j+self.batch_size)])).detach().to('cpu').numpy()\n",
    "            return Xout\n",
    "        else:\n",
    "            return self.model(self.preprocess(X))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_sk_KNN = {'n_neighbors':2, 'weights':'distance', 'algorithm':'auto', 'leaf_size':50, 'p':2,\n",
    "               'metric':'minkowski', 'n_jobs':11}\n",
    "\n",
    "class KNN_Regressor():\n",
    "    def __init__(self, embedder_func, args_sk_KNN):\n",
    "        # ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\n",
    "        # ‘uniform’, ‘distance’\n",
    "        self.embedder_func = embedder_func\n",
    "        self.KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "                    weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "                    leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "                    metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, X, y, already_embedded_X=False): # X [N_samples, dim_feats], y [N_samples] # y can be to regression floats!\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X) # [N_samples, dim_feats]\n",
    "        self.KNN = self.KNN.fit(X, y)\n",
    "        self.fitted = True\n",
    "    \n",
    "    def score(self, X, y, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.score(X,y)\n",
    "        \n",
    "    def predict(self, X, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.predict(X)\n",
    "    \n",
    "class Sklearn_embedder():\n",
    "    def __init__(self, embedder, preprocess_fct):\n",
    "        self.preprocess_fct = preprocess_fct\n",
    "        self.embedder = embedder\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.embedder.transform( self.preprocess_fct(X) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train KNN for CNN embedder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=save_stuff_path+check_file, \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor = KNN_Regressor( -1, args_sk_KNN) # se introduzca el embedder en el código final, porke sino pesaría gigas este objeto en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = triplet_embedder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor.fit(  X_emb, y, already_embedded_X=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emb = triplet_embedder(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor.score( X_test_emb, y_test, already_embedded_X=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_regressor.predict(X_test_emb, already_embedded_X=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(y_pred-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "f_name_knn = f'Triplet_CNN_KNN_n_images_{num_images}_emb_dims_{10}_seed_{random_seed}_date_{date}.sav'\n",
    "with open(save_stuff_path+f_name_knn, 'wb'):\n",
    "    pickle.dump(knn_regressor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see generated embedding space after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for plotting purposes\n",
    "df = pd.DataFrame({'y':y})\n",
    "df['phiCR'] = df[\"y\"].astype(str)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(X_emb)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "df['principal component 1'] = principalDf['principal component 1']\n",
    "df['principal component 2'] = principalDf['principal component 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bokeh and px see 2d PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig=px.scatter(df, x=\"principal component 1\", y=\"principal component 2\", color=\"y\")\n",
    "fig.update_traces(marker={\"size\":5})\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "#fig.write_image(f\"{save_stuff_path}/{f_name_emb}_2d.png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, LinearColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "import plotly.express as px\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "def embeddable_image(data):\n",
    "    img_data = data.values.reshape(X21,X21).astype(np.uint8)\n",
    "    image = Image.fromarray(img_data, mode='L').resize((64, 64), Image.BICUBIC)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='png')\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return 'data:image/png;base64,' + base64.b64encode(for_encoding).decode()\n",
    "\n",
    "df['image'] = pd.DataFrame(data=X, columns=list(range(X.shape[1]))).apply(embeddable_image, axis=1)\n",
    "\n",
    "datasource = ColumnDataSource(df)\n",
    "color_mapping = LinearColorMapper(\n",
    "    palette='Magma256',\n",
    "    low=y.min(),\n",
    "    high=y.max()\n",
    ")\n",
    "\n",
    "plot_figure = figure(\n",
    "    title='PCA projection of the CR dataset',\n",
    "    plot_width=800,\n",
    "    plot_height=800,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style='font-size: 16px; color: #224499'>phiCR:</span>\n",
    "        <span style='font-size: 18px'>@phiCR</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "plot_figure.circle(\n",
    "    'principal component 1',\n",
    "    'principal component 2',\n",
    "    source=datasource,\n",
    "    color=dict(field='phiCR', transform=color_mapping),\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=7\n",
    ")\n",
    "show(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now 3d PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "principalComponents = pca.fit_transform(X_emb)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "df['principal component 1'] = principalDf['principal component 1']\n",
    "df['principal component 2'] = principalDf['principal component 2']\n",
    "df['principal component 3'] = principalDf['principal component 3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter_3d(df, x=\"principal component 1\", y=\"principal component 2\", z=\"principal component 3\", color=\"y\")\n",
    "fig.update_traces(marker={\"size\":3})\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "#fig.write_image(f\"{save_stuff_path}/{f_name_emb}_3d.png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2+2)\n",
    "a=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.ipc_collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "def initialize():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                function restart_run_all(){\n",
    "                    IPython.notebook.kernel.restart();\n",
    "                    setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 10000)\n",
    "                }\n",
    "                function code_toggle() {\n",
    "                    if (code_show) {\n",
    "                        $('div.input').hide(200);\n",
    "                    } else {\n",
    "                        $('div.input').show(200);\n",
    "                    }\n",
    "                    code_show = !code_show\n",
    "                }\n",
    "            </script>\n",
    "            <button onclick=\"code_toggle()\">Click to toggle</button>\n",
    "            <button onclick=\"restart_run_all()\">Click to Restart and Run all Cells</button>\n",
    "        '''\n",
    "    ))\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ein fitxero baten gordetie estadoa de en cual iba, zenbaki bat, orduen bukaerara heltzeran ke se ejecute todo ke mire si esto pues embedder es este, si tal es este otro etc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart_run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pkill -f ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del triplet_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(points, points_color, title):\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(6, 6),\n",
    "        facecolor=\"white\",\n",
    "        tight_layout=True,\n",
    "        subplot_kw={\"projection\": \"3d\"},\n",
    "    )\n",
    "    fig.suptitle(title, size=16)\n",
    "    col = ax.scatter(x, y, z, c=points_color, s=50, alpha=0.8)\n",
    "    ax.view_init(azim=-60, elev=9)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.zaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    fig.colorbar(col, ax=ax, orientation=\"horizontal\", shrink=0.6, aspect=60, pad=0.01)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_2d(points, points_color, title):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3), facecolor=\"white\", constrained_layout=True)\n",
    "    fig.suptitle(title, size=16)\n",
    "    add_2d_scatter(ax, points, points_color)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_2d_scatter(ax, points, points_color, title=None):\n",
    "    x, y = points.T\n",
    "    ax.scatter(x, y, c=points_color, s=50, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 12  # neighborhood which is used to recover the locally linear structure\n",
    "n_components = 2  # number of embedding space dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as sk_datasets\n",
    "from matplotlib import ticker\n",
    "n_samples = 1500\n",
    "S_points, S_color = sk_datasets.make_s_curve(n_samples)\n",
    "print(S_points.shape, S_color.shape)\n",
    "plot_3d(S_points, S_color, \"Original S-curve samples\")\n",
    "\n",
    "S_points_gittered = S_points + np.random.randn(S_points.shape[0], S_points.shape[1])/10\n",
    "plot_3d(S_points_gittered, S_color, \"Gittered S-curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = sk_decomposition.PCA(n_components=2)\n",
    "S_PCA = PCA.fit_transform(S_points)\n",
    "\n",
    "plot_2d(S_PCA, S_color, title=\"PCA\")\n",
    "\n",
    "Sg_PCA = PCA.transform(S_points_gittered)\n",
    "plot_2d(Sg_PCA, S_color, title=\"Gittered with same PCA as GT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Locally Linear Embeddings\n",
    "Locally linear embedding (LLE) can be thought of as a series of local Principal Component Analyses which are globally compared to find the best non-linear embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_neighbors\": n_neighbors,\n",
    "    \"n_components\": n_components,\n",
    "    \"eigen_solver\": \"auto\"\n",
    "}\n",
    "\n",
    "lle_standard = sk_manifold.LocallyLinearEmbedding(method=\"standard\", **params)\n",
    "S_standard = lle_standard.fit_transform(S_points)\n",
    "Sg_standard = lle_standard.transform(S_points_gittered)\n",
    "\n",
    "\n",
    "lle_ltsa = sk_manifold.LocallyLinearEmbedding(method=\"ltsa\", **params)\n",
    "S_ltsa = lle_ltsa.fit_transform(S_points)\n",
    "Sg_ltsa = lle_ltsa.transform(S_points_gittered)\n",
    "\n",
    "\n",
    "lle_hessian = sk_manifold.LocallyLinearEmbedding(method=\"hessian\", **params)\n",
    "S_hessian = lle_hessian.fit_transform(S_points)\n",
    "Sg_hessian = lle_hessian.transform(S_points_gittered)\n",
    "\n",
    "\n",
    "lle_mod = sk_manifold.LocallyLinearEmbedding(method=\"modified\", modified_tol=0.8, **params)\n",
    "S_mod = lle_mod.fit_transform(S_points)\n",
    "Sg_mod = lle_mod.transform(S_points_gittered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=2, ncols=2, figsize=(7, 7), facecolor=\"white\", constrained_layout=True\n",
    ")\n",
    "fig.suptitle(\"Locally Linear Embeddings\", size=16)\n",
    "\n",
    "lle_methods = [\n",
    "    (\"Standard locally linear embedding\", S_standard),\n",
    "    (\"Local tangent space alignment\", S_ltsa),\n",
    "    (\"Hessian eigenmap\", S_hessian),\n",
    "    (\"Modified locally linear embedding\", S_mod),\n",
    "]\n",
    "for ax, method in zip(axs.flat, lle_methods):\n",
    "    name, points = method\n",
    "    add_2d_scatter(ax, points, S_color, name)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=2, ncols=2, figsize=(7, 7), facecolor=\"white\", constrained_layout=True\n",
    ")\n",
    "fig.suptitle(\"Locally Linear Embeddings On Gittered Versions\", size=16)\n",
    "\n",
    "lle_methods = [\n",
    "    (\"Standard locally linear embedding\", Sg_standard),\n",
    "    (\"Local tangent space alignment\", Sg_ltsa),\n",
    "    (\"Hessian eigenmap\", Sg_hessian),\n",
    "    (\"Modified locally linear embedding\", Sg_mod),\n",
    "]\n",
    "for ax, method in zip(axs.flat, lle_methods):\n",
    "    name, points = method\n",
    "    add_2d_scatter(ax, points, S_color, name)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Isomap Embedding\n",
    "Non-linear dimensionality reduction through Isometric Mapping. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap = sk_manifold.Isomap(n_neighbors=n_neighbors, n_components=n_components, p=1)\n",
    "S_isomap = isomap.fit_transform(S_points)\n",
    "\n",
    "plot_2d(S_isomap, S_color, \"Isomap Embedding\")\n",
    "\n",
    "S_isomap = isomap.transform(S_points_gittered)\n",
    "\n",
    "plot_2d(S_isomap, S_color, \"Isomap Embedding On Noisy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Multidimensional scaling (MDS) No tiene transform!\n",
    "\n",
    "Seeks a low-dimensional representation of the data in which the distances respect well the distances in the original high-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "md_scaling_Euclidean = sk_manifold.MDS(\n",
    "    n_components=n_components, max_iter=50, n_init=4, dissimilarity=\"euclidean\"\n",
    ")\n",
    "S_scaling_Euclidean = md_scaling_Euclidean.fit_transform(S_points)\n",
    "\n",
    "plot_2d(S_scaling_Euclidean, S_color, \"Multidimensional scaling Euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_scaling_GTy = sk_manifold.MDS(\n",
    "    n_components=n_components, max_iter=50, n_init=4, dissimilarity=\"precomputed\"\n",
    ")\n",
    "S_scaling_GTy = md_scaling_GTy.fit_transform(np.abs(S_color[np.newaxis,:]-S_color[:,np.newaxis]))\n",
    "\n",
    "plot_2d(S_scaling_GTy, S_color, \"Multidimensional scaling GT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.round(S_color, 2)*100\n",
    "a = a+np.abs(a.min())\n",
    "a = a.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "mapa = umap.UMAP(n_neighbors = 20, min_dist=0.9, n_components=2, metric=\"euclidean\")\n",
    "S_points_umapo = mapa.fit_transform(S_points, y=a)\n",
    "plot_2d(S_points_umapo, S_color, \"UMAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?umap.utils.check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_points_umapo = mapa.transform(S_points_gittered)\n",
    "plot_2d(S_points_umapo, S_color, \"UMAP gitt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCA = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=2, init='auto', warm_start=False, max_iter=50, tol=1e-05, random_state=999)\n",
    "S_points_NCA = NCA.fit_transform(S_points, y=a)\n",
    "plot_2d(S_points_NCA/np.mean(np.abs(S_points_NCA)), S_color, \"Prueba NCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = NCA.transform(S_points_gittered)\n",
    "plot_2d(s, S_color, \"Prueba glitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\n",
    "# ‘uniform’, ‘distance’\n",
    "\n",
    "\n",
    "KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=50, weights='uniform', algorithm='auto',\n",
    "                            leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=5)\n",
    "KNN = KNN.fit(S_points, S_color)\n",
    "print(KNN.score(S_points_gittered, S_color))\n",
    "preds = KNN.predict(S_points_gittered)\n",
    "plot_3d(S_points_gittered, S_color, title=\"GT\")\n",
    "plot_3d(S_points_gittered, preds, title=\"Preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
