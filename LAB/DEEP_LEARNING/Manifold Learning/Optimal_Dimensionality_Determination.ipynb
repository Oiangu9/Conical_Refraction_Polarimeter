{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart and Run All Function to do the whole pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "def restart_run_all():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                IPython.notebook.kernel.restart();\n",
    "                setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 1000)\n",
    "                \n",
    "            </script>\n",
    "        '''\n",
    "    ))\n",
    "#restart_run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) Determine Adequate Embedding Space Dimensionality\n",
    "Using MDA (to see when the manifolds torsion starts), using KNN to see when locality of same class can be preserved well, also UMAP for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.manifold as manifold\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import json\n",
    "import umap\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label\n",
    "    \n",
    "# Noisy Train set!\n",
    "GT_file_path_train_noisy = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/GROUND_TRUTHS.json\"\n",
    "images_dir_path_train_noisy =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN\"\n",
    "\n",
    "# Non-Noisy Train set!\n",
    "GT_file_path_train_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_train_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST\"\n",
    "\n",
    "# Test set\n",
    "GT_file_path_test_noisy = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_noisy =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST\"\n",
    "\n",
    "# Non-Noisy Train set!\n",
    "GT_file_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST\"\n",
    "\n",
    "use_noisy=False\n",
    "\n",
    "num_images=2000\n",
    "num_images_test = 700  # for the UMAP and NNE curve\n",
    "\n",
    "num_decimals = 2\n",
    "random_seed = 666\n",
    "n_jobs=10\n",
    "exp_name=\"Non_Noisy_Dataset\"\n",
    "\n",
    "emb_dims= [1,2,3,4,5,6,7,8,10,15,20] #[1,2,3,4,5,7,10,13,16,20]\n",
    "\n",
    "save_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Finding_Dimensionality_of_Manifold/{exp_name}/\"\n",
    "os.makedirs( save_stuff_path, exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_noisy:\n",
    "    training_data = ImageDataset(GT_file_path_train_noisy, images_dir_path_train_noisy)\n",
    "    test_data = ImageDataset(GT_file_path_test_noisy, images_dir_path_test_noisy)\n",
    "else:\n",
    "    training_data = ImageDataset(GT_file_path_train_non_noisy, images_dir_path_train_non_noisy)\n",
    "    test_data = ImageDataset(GT_file_path_test_non_noisy, images_dir_path_test_non_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "random_indices = np.random.choice(range(len(training_data)), num_images, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X21 = training_data[0][0].shape[1]\n",
    "X = np.zeros( (num_images, X21**2), dtype=np.float32)\n",
    "y = np.zeros((num_images), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices):\n",
    "    im, lab = training_data[idx]\n",
    "    X[j, :] = im[0].flatten()\n",
    "    y[j] = lab   \n",
    "\n",
    "y_categoric = (np.around(y+np.pi, num_decimals)*10**num_decimals).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data for KNN tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices_test = np.random.choice(range(len(test_data)), num_images_test, replace=False)\n",
    "#random_indices = np.random.choice(range(2850), num_images, replace=False)\n",
    "X_test = np.zeros( (num_images_test, X21**2), dtype=np.float32)\n",
    "y_test= np.zeros((num_images_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_test):\n",
    "    im, lab = test_data[idx]\n",
    "    X_test[j, :] = im[0].flatten()\n",
    "    y_test[j] = lab   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get state of pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(f\"state_{exp_name}.txt\", \"r\")\n",
    "    current_state = int(f.read())\n",
    "    f.close()\n",
    "    \n",
    "    current_state+=1\n",
    "except:\n",
    "    current_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start metric saver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    out_metrics = open(f\"{save_stuff_path}/Metrics_{exp_name}.json\", \"r\")\n",
    "  \n",
    "    metrics = json.load(out_metrics)\n",
    "    metrics = metrics['Metrics']\n",
    "    \n",
    "    out_metrics.close()\n",
    "    \n",
    "except: \n",
    "    metrics={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Dimensionality Determination:\n",
    "- If state 0-> do MDS # y not used\n",
    "- If state 1-> do LLE # y not used\n",
    "- If state 2 -> do UAMP # y used in continous version\n",
    "- If stte 3 -> do NCA # y used in categroical version for training of embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()  \n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if current_state == 0:\n",
    "    # MDS\n",
    "    args = {'metric':True, 'n_init':4, 'max_iter':40, 'dissimilarity':'euclidean'}\n",
    "    metrics['MDS']=[]\n",
    "\n",
    "    for dim in emb_dims:\n",
    "        embedder = manifold.MDS(n_components=dim, metric=args['metric'], n_init=args['n_init'],\n",
    "                        max_iter=args['max_iter'], n_jobs=n_jobs, random_state=random_seed, dissimilarity=args['dissimilarity'])\n",
    "\n",
    "        embedder.fit(X)\n",
    "        metrics['MDS'].append(embedder.stress_)\n",
    "        print(f\"Embedder of dim {dim} done!\")\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    ax.plot(emb_dims, metrics['MDS'], 'o-')\n",
    "    #ax.set_ylim((0, max(metrics['MDS'])))\n",
    "    ax.set_title(\"MDS Stress by Embedding Space Dimension\\n\"+exp_name)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"Embedding space dimensions\")\n",
    "    ax.set_ylabel(\"MDS Stress\")\n",
    "    plt.savefig(f\"{save_stuff_path}/MDS_stress_{exp_name}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "elif current_state == 1000:\n",
    "    # LLE\n",
    "    args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 50,\"emb_dims\": emb_dims, 'max_iter':50}\n",
    "    # Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "    methods = [\"standard\", \"ltsa\", \"hessian\"]\n",
    "\n",
    "    for method in methods:\n",
    "        args['method']=method\n",
    "        metrics[\"LLE_\"+method]=[]\n",
    "        if method=='hessian':\n",
    "            args['n_neighbors'] = dim * (dim + 3) //2 + 2\n",
    "        for dim in emb_dims:\n",
    "            embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "                  n_components=dim, max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs) \n",
    "            embedder = embedder.fit(X)\n",
    "            metrics[\"LLE_\"+method].append(embedder.reconstruction_error_)\n",
    "            print(f\"Done dim {dim}!\")\n",
    "        print(f\"Done method {method}\")\n",
    "        fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "        ax.plot(emb_dims, metrics[\"LLE_\"+method], 'o-')\n",
    "        #ax.set_ylim((0, max(metrics[\"LLE_\"+method])))\n",
    "        ax.set_title(f\"LLE {method} Reconstruction Error\\n by Embedding Space Dimension\\n\"+exp_name)\n",
    "        ax.set_xlabel(\"Embedding space dimensions\")\n",
    "        ax.set_ylabel(\"LLE reconstruction error\")\n",
    "        ax.grid(True)\n",
    "        plt.savefig(f\"{save_stuff_path}/LLE_{method}.png\")\n",
    "        plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    for method in methods:\n",
    "        ax.plot(emb_dims, metrics[\"LLE_\"+method], 'o-',label=method)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"LLE Reconstruction Error\\n by Embedding Space Dimension\\n\"+exp_name)\n",
    "    ax.set_xlabel(\"Embedding space dimensions\")\n",
    "    ax.set_ylabel(\"LLE reconstruction error\")\n",
    "    ax.grid(True)\n",
    "    plt.savefig(f\"{save_stuff_path}/LLE_{exp_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "elif current_state == 2:\n",
    "    args_sk_KNN = {'n_neighbors':5, 'weights':'uniform', 'algorithm':'auto', 'leaf_size':20, 'p':2,\n",
    "               'metric':'minkowski', 'n_jobs':n_jobs}\n",
    "\n",
    "    # UMAP\n",
    "    args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.2, 'n_neighbors':50, 'metric':'euclidean', 'n_epochs':40,\n",
    "           'target_metric':'l2'}\n",
    "    # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "    metrics[\"UMAP\"]=[]\n",
    "    for dim in emb_dims:\n",
    "        embedder = umap.UMAP(n_components=dim, min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                target_metric=args['target_metric']) \n",
    "        embedder = embedder.fit(X,y)\n",
    "        print(f\"Dimension {dim} trained\")\n",
    "        KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "                weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "                leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "                metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "        KNN = KNN.fit(embedder.embedding_, y)\n",
    "        metrics[\"UMAP\"].append(1-KNN.score(embedder.transform(X_test),y_test))\n",
    "        print(f\"KNN ran\")\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    ax.plot(emb_dims, metrics['UMAP'], 'o-')\n",
    "    #ax.set_ylim((0, max(metrics['UMAP'])))\n",
    "    ax.set_title(\"UMAP Embedding 1-KNN Regression Score\\n\"+exp_name)\n",
    "    ax.set_xlabel(\"Embedding space dimensions\")\n",
    "    ax.set_ylabel(\"1-KNN score on test set\")\n",
    "    ax.grid(True)\n",
    "    plt.savefig(f\"{save_stuff_path}/UMAP_score_knn_{exp_name}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "elif current_state == 3:\n",
    "    args_sk_KNN = {'n_neighbors':5, 'weights':'uniform', 'algorithm':'auto', 'leaf_size':30, 'p':2,\n",
    "               'metric':'minkowski', 'n_jobs':n_jobs}\n",
    "\n",
    "    # NCA\n",
    "    args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':40, }\n",
    "    # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "    metrics[\"NCA\"]=[]\n",
    "    for dim in emb_dims:\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=dim, init=args['init'],\n",
    "                                    max_iter=args['max_iter'], random_state=random_seed)\n",
    "        X_emb = embedder.fit_transform(X,y_categoric)\n",
    "        print(f\"Dimension {dim} done!\")\n",
    "        KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "                weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "                leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "                metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "        KNN = KNN.fit(X_emb, y)\n",
    "        metrics[\"NCA\"].append(1-KNN.score(embedder.transform(X_test), y_test))\n",
    "        print(\"KNN done!\")\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    ax.plot(emb_dims, metrics['NCA'], 'o-')\n",
    "    #ax.set_ylim((0, max(metrics['NCA'])))\n",
    "    ax.set_title(\"NCA Embedding 1-KNN Regression Score\\n\"+exp_name)\n",
    "    ax.set_xlabel(\"Embedding space dimensions\")\n",
    "    ax.set_ylabel(\"1-KNN score on test set\")\n",
    "    ax.grid(True)\n",
    "    plt.savefig(f\"{save_stuff_path}/NCA_score_knn_{exp_name}.png\")\n",
    "    plt.show()  \n",
    "\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gathered metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the json file where the output must be stored\n",
    "out_metrics = open(f\"{save_stuff_path}/Metrics_{exp_name}.json\", \"w\")\n",
    "\n",
    "json.dump({'Emb_dims':emb_dims, 'Metrics':metrics}, out_metrics)\n",
    "  \n",
    "out_metrics.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If everything fine until here then updte state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"state_{exp_name}.txt\", \"w\")\n",
    "f.write(str(current_state))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart kernel and re-run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart_run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa ver la variedad nooisy y non-noisy, porke los noisy pueden hacer de puente de einstein rosen sino entre partes del manifold\n",
    "# pa hacer embedding spaces para knn o fc o pa usarlo de simulated metric en plan euclidean ya no lo sé...\n",
    "# supongo que si es un embedding ke mira los GT entonces noisy, si no...sólo se fija en la topología digamos...mejor non-noisy pa evitar puentes?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
