{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"../../..\")\n",
    "from SOURCE.CLASS_CODE_GPU_Classes import *\n",
    "from SOURCE.CLASS_CODE_Image_Manager import *\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from time import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit//STRUCTURE_Grid.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4855/2170864860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/{experiment_name}/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimage_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{output_directory}/SIMULATIONS/\"\u001b[0m \u001b[0;31m#nx_{image_shortest_side}_depth_{image_depth}_sat_{saturation}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mphase_vigilant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{output_directory}/STRUCTURE_Grid.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit//STRUCTURE_Grid.json'"
     ]
    }
   ],
   "source": [
    "image_depth=8 # or 16 bit per pixel\n",
    "saturation=1\n",
    "image_shortest_side=540\n",
    "resolution_side_nx=image_shortest_side # generated images will be resolution_side x resolution_side\n",
    "\n",
    "experiment_name=\"Basler_like_R0_300x_w0_300x_Z_50x_64bit\"\n",
    "output_directory=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/{experiment_name}/\"\n",
    "image_directory=f\"{output_directory}/SIMULATIONS/\" #nx_{image_shortest_side}_depth_{image_depth}_sat_{saturation}\n",
    "phase_vigilant = json.load(open(f\"{output_directory}/STRUCTURE_Grid.json\"))\n",
    "\n",
    "\n",
    "X=int(resolution_side_nx*1.15/2) # 605\n",
    "im_type=np.uint16 if image_depth==16 else np.uint8\n",
    "max_intensity=65535 if image_depth==16 else 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL ROUTINES #################################\n",
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    return centered_image\n",
    "    '''\n",
    "    else:\n",
    "        # We compute the center of gravity of the cropped images, if everything was made allright\n",
    "        # they should get just centered in the central pixels number X+1 (index X)\n",
    "        g_centered = compute_intensity_gravity_center(centered_image)\n",
    "\n",
    "        # We now compute a floating translation of the image so that the gravicenter is exactly\n",
    "        # centered at pixel (607.5, 607.5) (exact center of the image in pixel coordinates staring\n",
    "        # form (0,0) and having size (607*2+1)x2), instead of being centered at the beginning of\n",
    "        # around pixel (607,607) as is now\n",
    "        translate_vectors = X+0.5-g_centered #[ 2(h,w)]\n",
    "        T = np.float64([[1,0, translate_vectors[1]], [0,1, translate_vectors[0]]])\n",
    "        return cv2.warpAffine( centered_image, T, (X*2+1, X*2+1),\n",
    "                    flags=interpolation_flag) # interpolation method\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time 0.59206223487854s -> per image: 0.00740077793598175 \n",
      "Note saving images will not be required, just that applying noise will\n",
      "Also, in reality one can apply iX and normalization to the whole batch at once in the GPU\n",
      "hf5 size 14109876-> per image 1763734.5\n"
     ]
    }
   ],
   "source": [
    "phiCRs = np.linspace(0,2*np.pi-0.01, 10)\n",
    "t00=time()\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset.h5\",'r')\n",
    "phis = h5f['phis'][:]\n",
    "\n",
    "for ID in h5f.keys(): # phase_vigilant['IDs']: \n",
    "    for phiCR in phiCRs:\n",
    "\n",
    "        D_mats = h5f[ID][:]\n",
    "        \n",
    "        image = D_mats[0]+D_mats[1]*np.cos(phiCR-phis)\n",
    "        # convert to selected uint format\n",
    "        image = (max_intensity*(image/image.max())).astype(im_type)\n",
    "\n",
    "        # get iX (saturated) image\n",
    "        #image = np.where( image<=(max_intensity*saturation), image, max_intensity*saturation) # saturation application if necessary\n",
    "        image = compute_raw_to_centered_iX(image, X)\n",
    "\n",
    "        # save the image\n",
    "        rel_path=f\"{image_directory}/{ID}_phiCR_{phiCR}.png\"\n",
    "        cv2.imwrite( rel_path, image)\n",
    "\n",
    "tff=time()\n",
    "print(f\"Total elapsed time {tff-t00}s -> per image: {(tff-t00)/(len(phase_vigilant['IDs'])*len(phiCRs))} \\nNote saving images will not be required, just that applying noise will\\nAlso, in reality one can apply iX and normalization to the whole batch at once in the GPU\")\n",
    "print(f\"hf5 size {os.path.getsize(image_directory+'/Dataset.h5')}-> per image {os.path.getsize(image_directory+'/Dataset.h5')/(len(phase_vigilant['IDs']))}\")   \n",
    "\n",
    "        \n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time 0.981055736541748s -> per image: 0.1226319670677185 \n",
      "Note saving images will not be required, just that applying noise will\n",
      "Also, in reality one can apply iX and normalization to the whole batch at once in the GPU\n",
      "hf5 size 13122984-> per image 1640373.0\n"
     ]
    }
   ],
   "source": [
    "phiCRs = np.linspace(0,2*np.pi-0.01, 10)\n",
    "t00=time()\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset.h5\",'r')\n",
    "phis = h5f['phis'][:]\n",
    "\n",
    "for ID in phase_vigilant['IDs']: #h5f.keys():\n",
    "    for phiCR in phiCRs:\n",
    "\n",
    "        D_mats = h5f[ID][:]\n",
    "        \n",
    "        image = D_mats[0]+D_mats[1]*np.cos(phiCR-phis)\n",
    "        # convert to selected uint format\n",
    "        image = (max_intensity*(image/image.max())).astype(im_type)\n",
    "\n",
    "        # get iX (saturated) image\n",
    "        #image = np.where( image<=(max_intensity*saturation), image, max_intensity*saturation) # saturation application if necessary\n",
    "        image = compute_raw_to_centered_iX(image, X)\n",
    "\n",
    "        # save the image\n",
    "        rel_path=f\"{image_directory}/{ID}.png\"\n",
    "        cv2.imwrite( rel_path, image)\n",
    "\n",
    "tff=time()\n",
    "print(f\"Total elapsed time {tff-t00}s -> per image: {(tff-t00)/(len(phase_vigilant['IDs']))} \\nNote saving images will not be required, just that applying noise will\\nAlso, in reality one can apply iX and normalization to the whole batch at once in the GPU\")\n",
    "print(f\"hf5 size {os.path.getsize(image_directory+'/Dataset.h5')}-> per image {os.path.getsize(image_directory+'/Dataset.h5')/(len(phase_vigilant['IDs']))}\")   \n",
    "\n",
    "        \n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "'''\n",
    "La idea es que cada 5 epochs, se cambie el dataset efectivo, que sera un subset de los R0,w0,Z posibles\n",
    "multiplicado por el batch size (phiCR posibles). En cada batch, las imagenes enviadas seran todas\n",
    "de un mismo D matrix (R0,w0,Z) con diferentes angulos elegidos aleatoriamente con una uniforme\n",
    "'''\n",
    "class R0_w0_Z_Sampler(Sampler):\n",
    "    def __init__(self, R0_weights, w0_weights, Z_weights, num_batches_per_epoch):\n",
    "        self.num_batches = num_batches_per_epoch\n",
    "        self.R0_weights = R0_weights\n",
    "        self.w0_weights = w0_weights\n",
    "        self.Z_weights = Z_weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.stack((\n",
    "            torch.multinomial(self.R0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.w0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.Z_weights, self.num_batches, replacement=True)),\n",
    "            dim=1).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class CR_Dataset(Dataset):\n",
    "    def __init__(self, D_matrix_file_path, ID_file_path, device, X=605, generate_images_w_depth=8, random_seed=666, \n",
    "                 batch_size=10, num_batches_per_epoch=100): #, change_grid_R0_w0_Z_every_epochs=5):\n",
    "        np.random.seed(random_seed) \n",
    "        torch.manual_seed(random_seed)\n",
    "        self.D_matrix_file_path=D_matrix_file_path\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(ID_file_path)))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "        self.epoch_size = batch_size*num_batches_per_epoch\n",
    "        self.device = device\n",
    "        self.im_type = torch.uint16 if generate_images_w_depth==16 else torch.uint8\n",
    "        self.max_intensity = 65535 if generate_images_w_depth==16 else 255\n",
    "        self.X=X\n",
    "        \n",
    "    #def update_dataset o set_epoch_number y que aqui se genere directamente el dataset entero para las epochs que vienen\n",
    "    # lo que permitiria es que cada X epochs, se ahorrase el tener que re-generar todas las imagenes\n",
    "    # Pero claro, la pregunta es, la RAM aguantaria?\n",
    "    # Si haces con update_dataset, entonces no haria falta hacer un sampler custom, con el normal ya bastaria\n",
    "    \n",
    "    # Bueno, por ahora, vamos a hacer que en cada minibatch, se haga todo el puroceso. La cosa es que asi se \n",
    "    # puede aprovechar el multiprocessing innato, si no habria que hacer el multiprocessing dentroe del update_dataset\n",
    "    # o simplemente prescindir de hacerlo supongo.\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'h5f_D_matrices'):\n",
    "            self.h5f_D_matrices.close()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "    \n",
    "    def open_hdf5(self):\n",
    "        self.h5f_D_matrices = h5py.File( self.D_matrix_file_path, 'r')\n",
    "        #self.dataset = self.img_hdf5['dataset'] # if you want dataset.\n",
    "        \n",
    "\n",
    "    def compute_intensity_gravity_centers(self, images):\n",
    "        \"\"\"\n",
    "            Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "            It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "            Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "        \"\"\"\n",
    "        # image wise total intensity and marginalized inensities for weighted sum\n",
    "        intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "        intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "        total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "        # Compute mass center for intensity\n",
    "        # [N_images, 2] (h_center,w_center)\n",
    "        return torch.nan_to_num( torch.stack(\n",
    "            (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity,\n",
    "             torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity),\n",
    "            dim=1\n",
    "            ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    def compute_raw_to_centered_iX(self, images):\n",
    "\n",
    "        g_raw = self.compute_intensity_gravity_centers(images) # [ N_images, 2]\n",
    "\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*self.X+1, 2*self.X+1),  dtype = images.dtype, \n",
    "                                      device=self.device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-self.X\n",
    "        unclipped_upper = g_index_raw+self.X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(g_raw.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images\n",
    "    \n",
    "\n",
    "    def __getitem__(self, R0_w0_Z_idxs):\n",
    "        # In order to allow multiprocessing data loading, each worker needs to initialize \n",
    "        # the h5f loader, which must be done in the first iteration of getitem and not in the init\n",
    "        # of the parent process\n",
    "        if not hasattr(self, 'h5f_D_matrices'):\n",
    "            self.open_hdf5()\n",
    "            self.phis = torch.from_numpy(self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(self.device) #[1,Nx,Ny]\n",
    "\n",
    "        try:\n",
    "            D_mats = torch.from_numpy(self.h5f_D_matrices[\n",
    "                f\"R0_{self.R0s[R0_w0_Z_idxs[0]]}_w0_{self.w0s[R0_w0_Z_idxs[1]]}_Z_{self.Zs[R0_w0_Z_idxs[2]]}\"][:]\n",
    "                                 ).unsqueeze(1).to(self.device) #[2, 1, Nx, Ny]\n",
    "        except:\n",
    "            D_mats = torch.from_numpy(self.h5f_D_matrices[\n",
    "                f\"R0_100.28985507246377_w0_10.318840579710145_Z_0.0\"][:]\n",
    "                                 ).unsqueeze(1).to(self.device) #[2, 1, Nx,Ny]\n",
    "            \n",
    "        \n",
    "        phiCRs = torch.FloatTensor(self.batch_size, 1, 1).uniform_(0, 2*np.pi).to(self.device) #[batch_size, 1, 1]\n",
    "        images = D_mats[0]+D_mats[1]*torch.cos(phiCRs-self.phis) #[batch_size, Nx,Ny]\n",
    "        \n",
    "        # Apply noise to images\n",
    "        #####################################################################\n",
    "        \n",
    "        # convert images to selected uint format\n",
    "        images = (self.max_intensity*(images/images.amax(dim=(1,2), keepdim=True)[0].unsqueeze(1))).type(self.im_type)\n",
    "        \n",
    "\n",
    "        # get iX images\n",
    "        images = self.compute_raw_to_centered_iX(images) #[batch_size, 2X+1, 2X+1]\n",
    "        labels = torch.Tensor([[float(self.R0s[R0_w0_Z_idxs[0]]), float(self.w0s[R0_w0_Z_idxs[1]]), \n",
    "                               float(self.Zs[R0_w0_Z_idxs[2]])]]).to(self.device) #[1,4]\n",
    "        labels = torch.hstack( ( labels.expand(self.batch_size, 3), phiCRs.squeeze(2) ) ) #[4, batch_size]\n",
    "        del D_mats, phiCRs\n",
    "        torch.cuda.empty_cache()\n",
    "        return images, labels #[ batch_size, 2X+1, 2X+1] and [batch_size, 4]\n",
    "        # The whole batch is already in the GPU, since to process it we wanted it to be there\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma, normalized_output=True):\n",
    "    p_s = (1/np.sqrt(2*np.pi)/sigma)*torch.exp(-(x-mu)**2/(2*sigma**2))\n",
    "    return p_s/p_s.sum() if normalized_output else p_s\n",
    "\n",
    "phase_vigilant = pd.DataFrame.from_dict(json.load(open(\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\")))\n",
    "R0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['R0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=158, sigma=35)\n",
    "w0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['w0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=25, sigma=10)\n",
    "Z_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['Zs'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=0, sigma=0.5)\n",
    "#print(R0_weights,  phase_vigilant['R0s'].drop_duplicates())\n",
    "#print(w0_weights, phase_vigilant['w0s'].drop_duplicates())\n",
    "#print(Z_weights, phase_vigilant['Zs'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches=3\n",
    "sampler = R0_w0_Z_Sampler( R0_weights, w0_weights, Z_weights, num_batches)\n",
    "dataset = CR_Dataset(D_matrix_file_path=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Dataset_R0_70_w0_70_Z_4.h5\",\n",
    "            ID_file_path =\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\", \n",
    "            device = device,\n",
    "            X=302, generate_images_w_depth=8, random_seed=666, \n",
    "            batch_size=5, num_batches_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches=3\n",
    "sampler = R0_w0_Z_Sampler( R0_weights, w0_weights, Z_weights, num_batches)\n",
    "dataset = CR_Dataset(D_matrix_file_path=\"/home/melanie/Desktop/Conical_Refraction_Polarimeter/OUTPUT/Dataset_R0_70_w0_70_Z_4.h5\",\n",
    "            ID_file_path =\"/home/melanie/Desktop/Conical_Refraction_Polarimeter/OUTPUT/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\", \n",
    "            device = device,\n",
    "            X=302, generate_images_w_depth=8, random_seed=666, \n",
    "            batch_size=5, num_batches_per_epoch=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing times -retrieval+image generation- where: [0.018270254135131836, 0.006209373474121094, 0.006011486053466797]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "times=[]\n",
    "for i in sampler: # outputea por cada batch un index\n",
    "    t=time()\n",
    "    ims, lab=dataset[i]\n",
    "    times.append(time()-t)\n",
    "    #print(ims.shape, lab.shape, ims.is_cuda, lab.is_cuda, ims.dtype, lab.dtype)\n",
    "    for j in range(ims.shape[0]):\n",
    "        #print(lab[j])\n",
    "        cv2.imwrite(f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/{str(lab[j])}.png\", np.array(ims[j].to('cpu')))\n",
    "        #print(dataset.compute_intensity_gravity_centers(ims))\n",
    "print(f\"Batch processing times -retrieval+image generation- where: {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader =DataLoader(\n",
    "    dataset=dataset, batch_size=1, sampler=sampler, num_workers=5, # each index yielded by the sampler is intended to be a full mini-batch already\n",
    "           # we can take advantage of the workers only if meta-batches are more than 1, so we can do it, just reducing the sub-batch\n",
    "           shuffle=False, \n",
    "           batch_sampler=None, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None,\n",
    "           multiprocessing_context=None, generator=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datas, targets in loader:\n",
    "    print(datas.shape, targets.shape)\n",
    "    print(datas.is_cuda, targets.is_cuda)\n",
    "# checkea tb que las matrices intermedias que mando al device se vayan olvidando cuando ya no se necesiten\n",
    "# Quizas hay que hacerlo explicitamente!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=torch.Tensor([[9.2], [10.2], [14.3]])\n",
    "a=torch.torch.FloatTensor(1,1, 10).uniform_(0, 2*np.pi)\n",
    "print(a.squeeze(0).shape)\n",
    "torch.vstack((l.expand(3, 10), a.squeeze(0))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0240, 0.0270, 0.0270],\n",
      "        [0.0240, 0.0270, 0.0270]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "g_raw=torch.stack((torch.matmul(torch.tensor([[21, 3,3,5],[2,3,3,6],[2,3,3,6]]).transpose(0,1).transpose(0,1), torch.arange(4))/1000,\n",
    "            torch.matmul(torch.tensor([[21, 3,3,5],[2,3,3,6],[2,3,3,6]]).transpose(0,1).transpose(0,1), torch.arange(4))/1000),\n",
    "                 )\n",
    "print(g_raw)\n",
    "print(g_raw.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[24, 27, 27],\n",
       "        [24, 27, 27]], dtype=torch.int32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_raw=torch.stack((torch.matmul(torch.tensor([[2.1, 3,3,5],[2,3,3,6],[2,3,3,6]]).transpose(0,1).transpose(0,1), torch.arange(4, dtype=torch.float32)),\n",
    "            torch.matmul(torch.tensor([[2.1, 3,3,5],[2,3,3,6],[2,3,3,6]]).transpose(0,1).transpose(0,1), torch.arange(4, dtype=torch.float32))),\n",
    "                 )\n",
    "print(g_raw.dtype)\n",
    "torch.round(g_raw).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 93, 255,   5],\n",
       "         [ 93, 254,   5],\n",
       "         [ 93, 254,   4],\n",
       "         ...,\n",
       "         [  1,  76,  49],\n",
       "         [  1,  76,  49],\n",
       "         [  1,  76,  49]],\n",
       "\n",
       "        [[ 93, 254,   5],\n",
       "         [ 93, 254,   5],\n",
       "         [ 93, 254,   5],\n",
       "         ...,\n",
       "         [  1,  76,  49],\n",
       "         [  1,  76,  49],\n",
       "         [  1,  75,  49]],\n",
       "\n",
       "        [[ 94, 254,   5],\n",
       "         [ 93, 254,   5],\n",
       "         [ 93, 254,   5],\n",
       "         ...,\n",
       "         [  1,  76,  49],\n",
       "         [  1,  76,  49],\n",
       "         [  1,  75,  49]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[254,  56, 236],\n",
       "         [254,  55, 236],\n",
       "         [254,  55, 236],\n",
       "         ...,\n",
       "         [ 55,   9, 126],\n",
       "         [ 55,   9, 126],\n",
       "         [ 55,   9, 125]],\n",
       "\n",
       "        [[254,  55, 236],\n",
       "         [254,  55, 236],\n",
       "         [254,  55, 236],\n",
       "         ...,\n",
       "         [ 55,   9, 126],\n",
       "         [ 55,   9, 126],\n",
       "         [ 55,   9, 126]],\n",
       "\n",
       "        [[255,  55, 236],\n",
       "         [254,  55, 236],\n",
       "         [254,  55, 237],\n",
       "         ...,\n",
       "         [ 55,   9, 126],\n",
       "         [ 55,   9, 126],\n",
       "         [ 55,   9, 126]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds=torch.from_numpy(D_mats).unsqueeze(2)\n",
    "phik=torch.from_numpy(phis).unsqueeze(2)\n",
    "phiCRs=torch.FloatTensor(1,1, 3).uniform_(0, 2*np.pi)\n",
    "images=Ds[0]+Ds[1]*torch.cos(phiCRs-phik)\n",
    "\n",
    "images = (255*(images/images.amax(dim=(0,1), keepdim=True)[0].unsqueeze(0))).type(torch.uint8)\n",
    "images = compute_raw_to_centered_iX(images, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([540, 540, 3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(phiCRs-phik.unsqueeze(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[2, 2]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in iter(torch.stack((torch.multinomial(torch.Tensor([0.3,0.5,0.2]), 5, replacement=True),torch.multinomial(torch.Tensor([0.3,0.5,0.2]), 5, replacement=True)),dim=1).tolist()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     70.0\n",
       "2    178.0\n",
       "Name: R0s, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(phase_vigilant)['R0s'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.0, 178.0]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a['R0s'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=70.020202020345678987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pito 70.02020202034568\n"
     ]
    }
   ],
   "source": [
    "print(f\"pito {str(b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame.from_dict(phase_vigilant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
