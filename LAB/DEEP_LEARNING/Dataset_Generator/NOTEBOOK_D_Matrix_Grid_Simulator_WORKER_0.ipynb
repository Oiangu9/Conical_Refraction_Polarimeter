{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"../../..\")\n",
    "from SOURCE.CLASS_CODE_GPU_Classes import *\n",
    "from SOURCE.CLASS_CODE_Image_Manager import *\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from time import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the PARAMETERS ############################################\n",
    "##################################################################\n",
    "experiment_name=\"Basler_like_R0_300x_w0_300x_Z_50x_64bit\"\n",
    "N_R0 = 70 #130\n",
    "N_w0 = 70 #130\n",
    "N_Z = 4 #8\n",
    "\n",
    "output_directory=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/{experiment_name}/\"\n",
    "#output_directory=f\"./OUTPUT/LIBRARIES_OF_THEORETICAL_D/{experiment_name}/\"\n",
    "#os.chdir(f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/\")\n",
    "\n",
    "randomization_seed=666\n",
    "image_shortest_side=540\n",
    "saturation=1\n",
    "\n",
    "# Ring parameters to test (each will be a different simulation)\n",
    "#phiCR_s=np.linspace(-180,180,360*10**significant_decimal+1)*np.pi/180\n",
    "R0_s=np.linspace(70, 180, N_R0) #np.linspace(70,180,40) # in pxels 153\n",
    "w0_s=np.linspace( 8, 40, N_w0) #np.linspace(8,50,40) 11\n",
    "Z_s=np.linspace(0, 0.9, N_Z)\n",
    "rho_0s=R0_s/w0_s\n",
    "\n",
    "\n",
    "resolution_side_nx=image_shortest_side # generated images will be resolution_side x resolution_side\n",
    "# Other parameters\n",
    "max_k=50\n",
    "num_k=1200\n",
    "sim_chunk_ax=image_shortest_side\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "# General considerations\n",
    "image_directory=f\"{output_directory}/SIMULATIONS/\" #nx_{image_shortest_side}_depth_{image_depth}_sat_{saturation}\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "np.random.seed(randomization_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this data generation in parallel, we will generate the data in parallel processes.\n",
    "Eventually, when all is finished, we will manually generate a single h5f from the individual parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 -> 0 to 12\n",
      "Worker 1 -> 12 to 23\n",
      "Worker 2 -> 23 to 34\n",
      "Worker 3 -> 34 to 45\n",
      "Worker 4 -> 45 to 56\n"
     ]
    }
   ],
   "source": [
    "K=5 # workers\n",
    "N=56 # tareas\n",
    "\n",
    "for j in range(K):\n",
    "    print(f\"Worker {j} -> {(N//K)*j + j*((N%K-j)>0) + (N%K)*(j>=N%K) } to {(N//K)*(j+1) + (j+1)*((N%K-j-1)>0)+ (N%K)*(j+1>=N%K)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_WORKERS = 2\n",
    "WORKER_ID = 0 # beginning from 0 till TOTAL_WORKERS-1\n",
    "\n",
    "def beg_index(N,j,K):\n",
    "    # N -> number of total elements in vector, j is worker id, K is total number of workers\n",
    "    return (N//K)*j + j*((N%K-j)>0) + (N%K)*(j>=N%K)\n",
    "def end_index(N,j,K):\n",
    "    return (N//K)*(j+1) + (j+1)*((N%K-j-1)>0)+ (N%K)*(j+1>=N%K)\n",
    "\n",
    "# we just need to partitionate one of the vectors! If you do it with all of them you do not get the whole!!!\n",
    "R0_s = R0_s[beg_index(N_R0, WORKER_ID, TOTAL_WORKERS):end_index(N_R0, WORKER_ID, TOTAL_WORKERS)] \n",
    "# w0_s = w0_s[beg_index(N_w0, WORKER_ID, TOTAL_WORKERS):end_index(N_w0, WORKER_ID, TOTAL_WORKERS)] \n",
    "# Z_s = Z_s[beg_index(N_Z, WORKER_ID, TOTAL_WORKERS):end_index(N_Z, WORKER_ID, TOTAL_WORKERS)]\n",
    "# rho_0s=R0_s/w0_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using h5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#####                                                                                               ] 5.357% \n",
      "\n",
      "Simulated: 525/9800\n",
      "Elapsed time: 1.0 h 49.0 min -58.67 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16354/2594667578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphase_vigilant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IDs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# simulate matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mD_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_pieces_for_I_LP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR0_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mD_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/SOURCE/CLASS_CODE_GPU_Classes.py\u001b[0m in \u001b[0;36mcompute_pieces_for_I_LP\u001b[0;34m(self, R0_pixels, Z, w0_pixels)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_D_matrix_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin_phis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos_phis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_pieces_for_I_LP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR0_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_B0_B1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR0_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpieces_for_I_LP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, self.phis[:,:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/SOURCE/CLASS_CODE_GPU_Classes.py\u001b[0m in \u001b[0;36m_compute_B0_B1\u001b[0;34m(self, Z, R0, w0)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mrs_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 self.B0=self.B0.at[ self.chunks_x[ix]:self.chunks_x[ix+1], self.chunks_y[iy]:self.chunks_y[iy+1]].set(\n\u001b[0;32m--> 188\u001b[0;31m                 compute_B0_block( self.n, self.a0, R0/w0, rs_block, self.ks, Z, self.dk, jax.device_put(j0(self.ks*rs_block))  ))#[ny, nx, 1]\n\u001b[0m\u001b[1;32m    189\u001b[0m                 self.B1=self.B1.at[ self.chunks_x[ix]:self.chunks_x[ix+1], self.chunks_y[iy]:self.chunks_y[iy+1]].set(\n\u001b[1;32m    190\u001b[0m                 compute_B1_block( self.n, self.a0, R0/w0, rs_block, self.ks, Z, self.dk, jax.device_put(j1(self.ks*rs_block))  ))  #[ny, nx, 1]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the vigilant\n",
    "try:\n",
    "    phase_vigilant = json.load(open(f\"{output_directory}/STRUCTURE_Grid_PART_{WORKER_ID}.json\"))\n",
    "except:\n",
    "    phase_vigilant = {'R0s':[], 'w0s':[], 'Zs':[], 'IDs':[]}\n",
    "\n",
    "# Set the objects ready ##################\n",
    "# The simulator object\n",
    "simulator =RingSimulator_Optimizer_GPU( n=1.5, a0=1.0, max_k=max_k, num_k=num_k, nx=resolution_side_nx, \n",
    "                                      sim_chunk_x=sim_chunk_ax, sim_chunk_y=sim_chunk_ax)\n",
    "\n",
    "# Initialize the hdf5 dataset saver\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset_PART_{WORKER_ID}.h5\", 'a') # append if exists, create if not\n",
    "\n",
    "# save phis\n",
    "try:\n",
    "    h5f.create_dataset('phis', data=simulator.phis[:,:,0], compression=\"lzf\", shuffle=True) #, compression_opts=9)\n",
    "except:\n",
    "    print(f\"phis was already in h5f but not in phase vigilant\")\n",
    "    h5f['phis'][:] = simulator.phis[:,:,0]\n",
    "\n",
    "# Execute the stuff #####################\n",
    "i=1\n",
    "total=Z_s.shape[0]*R0_s.shape[0]*w0_s.shape[0]\n",
    "elapsed=0\n",
    "beg=time()\n",
    "output_info_every=25\n",
    "dump_every=25\n",
    "\n",
    "for Z in Z_s:\n",
    "    for R0 in R0_s:\n",
    "        for w0 in w0_s:\n",
    "            ID=f\"R0_{str(R0)}_w0_{str(w0)}_Z_{str(Z)}\"\n",
    "            if ID not in phase_vigilant['IDs']:\n",
    "                # simulate matrix\n",
    "                D_matrix = simulator.compute_pieces_for_I_LP(R0_pixels=R0, Z=Z, w0_pixels=w0)\n",
    "                \n",
    "                if D_matrix is None:\n",
    "                    raise ValueError\n",
    "                    \n",
    "                # save the matrix\n",
    "                try:\n",
    "                    h5f.create_dataset(ID, data=D_matrix, compression=\"lzf\", shuffle=True) #, compression_opts=9)\n",
    "                except: # in case the phase_vigilant did not record it, but it was already in h5f\n",
    "                    print(f\"{ID} was already in h5f but not in phase vigilant\")\n",
    "                    h5f[ID][:] = D_matrix\n",
    "\n",
    "                #append the data\n",
    "                phase_vigilant['IDs'].append(ID)\n",
    "                phase_vigilant['R0s'].append(str(R0))\n",
    "                phase_vigilant['Zs'].append(str(Z))\n",
    "                phase_vigilant['w0s'].append(str(w0))\n",
    "                \n",
    "                \n",
    "                if i%output_info_every==0:\n",
    "                    display.clear_output(wait=True)\n",
    "                    elapsed=time()-beg\n",
    "                    print(f\"[\"+'#'*(int(100*i/total))+' '*(100-int(100*i/total))+f\"] {100*i/total:3.4}% \\n\\nSimulated: {i}/{total}\\nElapsed time: {elapsed//3600} h {elapsed//60-(elapsed//3600)*60} min {elapsed-(elapsed//60)*60-(elapsed//3600)*60:2.4} s\")\n",
    "                    if i%dump_every==0:\n",
    "                        h5f.flush()\n",
    "                        # we save the progess (in order to be able to quit and resume)\n",
    "                        json.dump(phase_vigilant, open( f\"{output_directory}/STRUCTURE_Grid_PART_{WORKER_ID}.json\", \"w\"))\n",
    "            i+=1\n",
    "            \n",
    "display.clear_output(wait=True)\n",
    "elapsed=time()-beg\n",
    "print(f\"[\"+'#'*(int(100*i/total))+' '*(100-int(100*i/total))+f\"] {100*i/total:3.4}% \\n\\nSimulated: {i}/{total}\\nElapsed time: {elapsed//3600} h {elapsed//60-(elapsed//3600)*60} min {elapsed-(elapsed//60)*60-(elapsed//3600)*60:2.4} s\")               \n",
    "h5f.flush()\n",
    "# we save the progess (in order to be able to quit and resume)\n",
    "json.dump(phase_vigilant, open( f\"{output_directory}/STRUCTURE_Grid_PART_{WORKER_ID}.json\", \"w\"))\n",
    "\n",
    "h5f.close()\n",
    "print(f\"\\n\\nWORKER {WORKER_ID} FINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.flush()\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code to join all the parts individually generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 done!\n",
      "Worker 1 done!\n"
     ]
    }
   ],
   "source": [
    "raise ValueError\n",
    "# Open the big h5f that will contain all of the parts\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset_R0_{N_R0}_w0_{N_w0}_Z_{N_Z}.h5\", 'w') # append if exists, create if not\n",
    "total_phase = {'R0s':[], 'w0s':[], 'Zs':[], 'IDs':[]}\n",
    "for j in range(TOTAL_WORKERS):\n",
    "    h5f_worker = h5py.File(f\"{image_directory}/Dataset_PART_{j}.h5\", 'r')\n",
    "    phase_worker = json.load(open(f\"{output_directory}/STRUCTURE_Grid_PART_{j}.json\"))\n",
    "    if j==0:\n",
    "        h5f.create_dataset('phis', data=h5f_worker['phis'][:], compression=\"lzf\", shuffle=True)\n",
    "    for ID in phase_worker['IDs']:\n",
    "        h5f.create_dataset(ID, data=h5f_worker[ID][:], compression=\"lzf\", shuffle=True)\n",
    "    total_phase['R0s'] = total_phase['R0s'] + phase_worker['R0s']\n",
    "    total_phase['w0s'] = total_phase['w0s'] + phase_worker['w0s']\n",
    "    total_phase['Zs'] = total_phase['Zs'] + phase_worker['Zs']\n",
    "    total_phase['IDs'] = total_phase['IDs'] + phase_worker['IDs']\n",
    "    h5f_worker.close()\n",
    "    print(f\"Worker {j} done!\")\n",
    "json.dump(total_phase, open( f\"{output_directory}/STRUCTURE_Grid_R0_{N_R0}_w0_{N_w0}_Z_{N_Z}.json\", \"w\"))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time()\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset.h5\",'r')\n",
    "D_mat = h5f[ID][:]\n",
    "phis = h5f['phis'][:]\n",
    "#print(list(h5f.keys()))\n",
    "h5f.close()\n",
    "print(f\"hf5:{time()-t}s size {os.path.getsize(image_directory+'/Dataset.h5')}\")   \n",
    "print(D_mat.dtype, D_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize(image_directory+'/Dataset.h5')/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3367/2901206933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m# save the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mrel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{image_directory}/{ID}.pkl.lzma\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;31m#np.save( rel_path, D_matrix, allow_pickle=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nDUMP {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_directory' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle, gzip, lzma, bz2\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Initialize the vigilant\n",
    "try:\n",
    "    phase_vigilant = json.load(open(f\"{output_directory}/STRUCTURE_Grid.json\"))\n",
    "except:\n",
    "    phase_vigilant = {'R0s':[], 'w0s':[], 'Zs':[], 'IDs':[], 'rel_path':[]}\n",
    "\n",
    "# Set the objects ready ##################\n",
    "# The simulator object\n",
    "simulator=RingSimulator_Optimizer_GPU( n=1.5, a0=1.0, max_k=max_k, num_k=num_k, nx=resolution_side_nx, sim_chunk_x=sim_chunk_ax, sim_chunk_y=sim_chunk_ax)\n",
    "\n",
    "# Execute the stuff #####################\n",
    "i=1\n",
    "total=Z_s.shape[0]*R0_s.shape[0]*w0_s.shape[0]\n",
    "elapsed=0\n",
    "beg=time()\n",
    "output_info_every=100\n",
    "dump_every=10000\n",
    "\n",
    "for Z in Z_s:\n",
    "    for R0 in R0_s:\n",
    "        for w0 in w0_s:\n",
    "            ID=f\"R0_{R0}_w0_{w0}_Z_{Z}\"\n",
    "            if ID not in phase_vigilant['IDs']:\n",
    "                # simulate matrix\n",
    "                #D_matrix = simulator.compute_D_matrix( R0_pixels=R0, Z=Z, w0_pixels=w0)\n",
    "                D_matrix = simulator.compute_pieces_for_I_LP(R0_pixels=R0, Z=Z, w0_pixels=w0)\n",
    "                \n",
    "                # save the matrix\n",
    "                rel_path=f\"{image_directory}/{ID}.pkl.lzma\"\n",
    "                #np.save( rel_path, D_matrix, allow_pickle=False)\n",
    "                print(f\"\\nDUMP {i}\")\n",
    "                t=time()\n",
    "                pickle.dump(D_matrix, lzma.open(rel_path, 'wb'))\n",
    "                print(f\"lzma:{time()-t}s size {os.path.getsize(rel_path)}\")\n",
    "                t=time()\n",
    "                pickle.dump(D_matrix, gzip.open(rel_path+\".gzip\", 'wb'))\n",
    "                print(f\"gzip:{time()-t}s size {os.path.getsize(rel_path+'.gzip')}\")\n",
    "                t=time()\n",
    "                pickle.dump(D_matrix, bz2.open(rel_path+\".bz2\", 'wb'))\n",
    "                print(f\"bz2:{time()-t}s size {os.path.getsize(rel_path+'.bz2')}\")\n",
    "                t=time()\n",
    "                fp = np.memmap(rel_path+\".p\", dtype='complex64', mode='w+', shape=(3,image_shortest_side,image_shortest_side))\n",
    "                fp=D_matrix\n",
    "                print(f\"memmap:{time()-t}s size {os.path.getsize(rel_path+'.p')}\")\n",
    "                t=time()\n",
    "                h5f = h5py.File(rel_path+'.h5', 'w')\n",
    "                h5f.create_dataset('dataset_1', data=D_matrix, compression=\"gzip\", shuffle=True) #, compression_opts=9)\n",
    "                h5f.close()\n",
    "                print(f\"hf5 lzf:{time()-t}s size {os.path.getsize(rel_path+'.h5')}\")     \n",
    "\n",
    "\n",
    "                \n",
    "                print(f\"\\nLOAD {i}\")\n",
    "                t=time()\n",
    "                D_mat=pickle.load(lzma.open(rel_path, 'rb'))\n",
    "                print(f\"lzma:{time()-t}s size {os.path.getsize(rel_path)}\")\n",
    "                t=time()\n",
    "                D_mat=pickle.load(gzip.open(rel_path+\".gzip\", 'rb'))\n",
    "                print(f\"gzip:{time()-t}s size {os.path.getsize(rel_path+'.gzip')}\")\n",
    "                t=time()\n",
    "                D_mat=pickle.load( bz2.open(rel_path+\".bz2\",'rb'))\n",
    "                #print(D_mat.dtype, D_mat.shape)\n",
    "                print(f\"bz2:{time()-t}s size {os.path.getsize(rel_path+'.bz2')}\")     \n",
    "                t=time()\n",
    "                D_mat= np.memmap(rel_path+\".p\", dtype='complex64', mode='r+', shape=(3,image_shortest_side,image_shortest_side))\n",
    "                print(f\"memmap:{time()-t}s size {os.path.getsize(rel_path+'.p')}\")     \n",
    "                t=time()\n",
    "                h5f = h5py.File(rel_path+'.h5','r')\n",
    "                D_mat = h5f['dataset_1'][:]\n",
    "                h5f.close()\n",
    "                print(f\"hf5:{time()-t}s size {os.path.getsize(rel_path+'.h5')}\")     \n",
    "                print(type(D_mat), D_mat.dtype, D_mat.shape)\n",
    "                print(np.allclose(D_mat, D_matrix))\n",
    "\n",
    "                \n",
    "\n",
    "                if D_matrix is None:\n",
    "                    raise ValueError\n",
    "\n",
    "                #append the data\n",
    "                phase_vigilant['IDs'].append(ID)\n",
    "                phase_vigilant['R0s'].append(float(R0))\n",
    "                phase_vigilant['Zs'].append(float(Z))\n",
    "                phase_vigilant['w0s'].append(float(w0))\n",
    "                phase_vigilant['rel_path'].append(rel_path)\n",
    "                \n",
    "                \n",
    "                if i%output_info_every==0:\n",
    "                    display.clear_output(wait=True)\n",
    "                    elapsed=time()-beg\n",
    "                    print(f\"[\"+'#'*(int(100*i/total))+' '*(100-int(100*i/total))+f\"] {100*i/total:3.4}% \\n\\nSimulated: {i}/{total}\\nElapsed time: {elapsed//3600} h {elapsed//60-(elapsed//3600)*60} min {elapsed-(elapsed//60)*60-(elapsed//3600)*60:2.4} s\")\n",
    "                    if i%dump_every==0:\n",
    "                        # we save the progess (in order to be able to quit and resume)\n",
    "                        json.dump(phase_vigilant, open( f\"{output_directory}/STRUCTURE_Grid.json\", \"w\"))\n",
    "            i+=1\n",
    "print(\"\\n\\nFINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=np.abs(D_mat)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=(D_mat*D_mat.conjugate()).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=D_mat.real**2+D_mat.imag**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=D_mat.real**2\n",
    "    a+=D_mat.imag**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose( (D_mat*D_mat.conjugate()).real, D_mat.real**2+D_mat.imag**2, rtol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
