{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_11320687227353328932() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_11320687227353328932()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just a function to allow toggleing code cells that are too long for good\n",
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) Generate the Basic Extensive .h5 Grid for $w_0,R_0,Z$\n",
    "## The intermediate D matrix is saved such that any $\\phi_{CR}$ may be generated from it\n",
    "### Useful for the Simulation fitting algorithms for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"../../..\")\n",
    "from SOURCE.CLASS_CODE_GPU_Classes import *\n",
    "from SOURCE.CLASS_CODE_Image_Manager import *\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from time import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the PARAMETERS ############################################\n",
    "##################################################################\n",
    "experiment_name=\"Basler_like_with_magnification\"\n",
    "N_R0 = 115 #70\n",
    "N_w0 = 115 #70\n",
    "N_Z = 4 #4\n",
    "\n",
    "output_directory = \"/media/melanie/D459-5113/CONICAL_REFRACTION_DATABASE\"\n",
    "#output_directory=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/{experiment_name}/\"\n",
    "#output_directory=f\"./OUTPUT/LIBRARIES_OF_THEORETICAL_D/{experiment_name}/\"\n",
    "#os.chdir(f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/\")\n",
    "\n",
    "randomization_seed=666\n",
    "image_shortest_side=520\n",
    "saturation=1\n",
    "\n",
    "# Ring parameters to test (each will be a different simulation)\n",
    "#phiCR_s=np.linspace(-180,180,360*10**significant_decimal+1)*np.pi/180\n",
    "R0_s= np.linspace(100, 180, N_R0)#np.linspace(110, 180, N_R0) #np.linspace(70,180,40) # in pxels 153\n",
    "w0_s= np.linspace(8, 40, N_w0)#np.linspace( 8, 35, N_w0) #np.linspace(8,50,40) 11\n",
    "Z_s=np.linspace(0, 1, N_Z)\n",
    "rho_0s=R0_s/w0_s\n",
    "\n",
    "\n",
    "resolution_side_nx=image_shortest_side # generated images will be resolution_side x resolution_side\n",
    "# Other parameters\n",
    "max_k=50\n",
    "num_k=1200\n",
    "sim_chunk_ax=image_shortest_side\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "# General considerations\n",
    "image_directory=f\"{output_directory}/SIMULATIONS/\" #nx_{image_shortest_side}_depth_{image_depth}_sat_{saturation}\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "np.random.seed(randomization_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this data generation in parallel, we will generate the data in parallel processes.\n",
    "Eventually, when all is finished, we will manually generate a single h5f from the individual parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 -> 0 to 12\n",
      "Worker 1 -> 12 to 23\n",
      "Worker 2 -> 23 to 34\n",
      "Worker 3 -> 34 to 45\n",
      "Worker 4 -> 45 to 56\n"
     ]
    }
   ],
   "source": [
    "K=5 # workers\n",
    "N=56 # tareas\n",
    "\n",
    "for j in range(K):\n",
    "    print(f\"Worker {j} -> {(N//K)*j + j*((N%K-j)>0) + (N%K)*(j>=N%K) } to {(N//K)*(j+1) + (j+1)*((N%K-j-1)>0)+ (N%K)*(j+1>=N%K)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_WORKERS = 4\n",
    "WORKER_ID = 0 # beginning from 0 till TOTAL_WORKERS-1\n",
    "\n",
    "def beg_index(N,j,K):\n",
    "    # N -> number of total elements in vector, j is worker id, K is total number of workers\n",
    "    return (N//K)*j + j*((N%K-j)>0) + (N%K)*(j>=N%K)\n",
    "def end_index(N,j,K):\n",
    "    return (N//K)*(j+1) + (j+1)*((N%K-j-1)>0)+ (N%K)*(j+1>=N%K)\n",
    "\n",
    "# we just need to partitionate one of the vectors! If you do it with all of them you do not get the whole!!!\n",
    "R0_s = R0_s[beg_index(N_R0, WORKER_ID, TOTAL_WORKERS):end_index(N_R0, WORKER_ID, TOTAL_WORKERS)] \n",
    "# w0_s = w0_s[beg_index(N_w0, WORKER_ID, TOTAL_WORKERS):end_index(N_w0, WORKER_ID, TOTAL_WORKERS)] \n",
    "# Z_s = Z_s[beg_index(N_Z, WORKER_ID, TOTAL_WORKERS):end_index(N_Z, WORKER_ID, TOTAL_WORKERS)]\n",
    "# rho_0s=R0_s/w0_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using h5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the vigilant\n",
    "try:\n",
    "    phase_vigilant = json.load(open(f\"{output_directory}/STRUCTURE_Grid_PART_{WORKER_ID}.json\"))\n",
    "except:\n",
    "    phase_vigilant = {'R0s':[], 'w0s':[], 'Zs':[], 'IDs':[]}\n",
    "\n",
    "# Set the objects ready ##################\n",
    "# The simulator object\n",
    "simulator =RingSimulator_Optimizer_GPU( n=1.5, a0=1.0, max_k=max_k, num_k=num_k, nx=resolution_side_nx, \n",
    "                                      sim_chunk_x=sim_chunk_ax, sim_chunk_y=sim_chunk_ax)\n",
    "\n",
    "# Initialize the hdf5 dataset saver\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset_PART_{WORKER_ID}.h5\", 'a') # append if exists, create if not\n",
    "\n",
    "# save phis\n",
    "try:\n",
    "    h5f.create_dataset('phis', data=simulator.phis[:,:,0], compression=\"lzf\", shuffle=True) #, compression_opts=9)\n",
    "except:\n",
    "    print(f\"phis was already in h5f but not in phase vigilant\")\n",
    "    h5f['phis'][:] = simulator.phis[:,:,0]\n",
    "\n",
    "# Execute the stuff #####################\n",
    "i=1\n",
    "total=Z_s.shape[0]*R0_s.shape[0]*w0_s.shape[0]\n",
    "elapsed=0\n",
    "beg=time()\n",
    "output_info_every=25\n",
    "dump_every=25\n",
    "\n",
    "for Z in Z_s:\n",
    "    for R0 in R0_s:\n",
    "        for w0 in w0_s:\n",
    "            ID=f\"R0_{str(R0)}_w0_{str(w0)}_Z_{str(Z)}\"\n",
    "            if ID not in phase_vigilant['IDs']:\n",
    "                # simulate matrix\n",
    "                D_matrix = simulator.compute_pieces_for_I_LP(R0_pixels=R0, Z=Z, w0_pixels=w0)\n",
    "                \n",
    "                if D_matrix is None:\n",
    "                    raise ValueError\n",
    "                    \n",
    "                # save the matrix\n",
    "                try:\n",
    "                    h5f.create_dataset(ID, data=D_matrix, compression=\"lzf\", shuffle=True) #, compression_opts=9)\n",
    "                except: # in case the phase_vigilant did not record it, but it was already in h5f\n",
    "                    print(f\"{ID} was already in h5f but not in phase vigilant\")\n",
    "                    h5f[ID][:] = D_matrix\n",
    "\n",
    "                #append the data\n",
    "                phase_vigilant['IDs'].append(ID)\n",
    "                phase_vigilant['R0s'].append(str(R0))\n",
    "                phase_vigilant['Zs'].append(str(Z))\n",
    "                phase_vigilant['w0s'].append(str(w0))\n",
    "                \n",
    "                \n",
    "                if i%output_info_every==0:\n",
    "                    display.clear_output(wait=True)\n",
    "                    elapsed=time()-beg\n",
    "                    print(f\"[\"+'#'*(int(100*i/total))+' '*(100-int(100*i/total))+f\"] {100*i/total:3.4}% \\n\\nSimulated: {i}/{total}\\nElapsed time: {elapsed//3600} h {elapsed//60-(elapsed//3600)*60} min {elapsed-(elapsed//60)*60-(elapsed//3600)*60:2.4} s\")\n",
    "                    if i%dump_every==0:\n",
    "                        h5f.flush()\n",
    "                        # we save the progess (in order to be able to quit and resume)\n",
    "                        json.dump(phase_vigilant, open( f\"{output_directory}/STRUCTURE_Grid_PART_{WORKER_ID}.json\", \"w\"))\n",
    "            i+=1\n",
    "            \n",
    "display.clear_output(wait=True)\n",
    "elapsed=time()-beg\n",
    "print(f\"[\"+'#'*(int(100*i/total))+' '*(100-int(100*i/total))+f\"] {100*i/total:3.4}% \\n\\nSimulated: {i}/{total}\\nElapsed time: {elapsed//3600} h {elapsed//60-(elapsed//3600)*60} min {elapsed-(elapsed//60)*60-(elapsed//3600)*60:2.4} s\")               \n",
    "h5f.flush()\n",
    "# we save the progess (in order to be able to quit and resume)\n",
    "json.dump(phase_vigilant, open( f\"{output_directory}/STRUCTURE_Grid_PART_{WORKER_ID}.json\", \"w\"))\n",
    "\n",
    "h5f.close()\n",
    "print(f\"\\n\\nWORKER {WORKER_ID} FINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a file or file object (not a file or file object)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m h5f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m\"\"\" Tell the HDF5 library to flush its buffers.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m phil:\n\u001b[0;32m--> 561\u001b[0m     \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:164\u001b[0m, in \u001b[0;36mh5py.h5f.flush\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not a file or file object (not a file or file object)"
     ]
    }
   ],
   "source": [
    "h5f.flush()\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code to join all the parts individually generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 done!\n",
      "Worker 1 done!\n",
      "Worker 2 done!\n",
      "Worker 3 done!\n"
     ]
    }
   ],
   "source": [
    "#raise ValueError\n",
    "# Open the big h5f that will contain all of the parts\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset_R0_{N_R0}_w0_{N_w0}_Z_{N_Z}.h5\", 'w') # append if exists, create if not\n",
    "total_phase = {'R0s':[], 'w0s':[], 'Zs':[], 'IDs':[]}\n",
    "for j in range(TOTAL_WORKERS):\n",
    "    h5f_worker = h5py.File(f\"{image_directory}/Dataset_PART_{j}.h5\", 'r')\n",
    "    phase_worker = json.load(open(f\"{output_directory}/STRUCTURE_Grid_PART_{j}.json\"))\n",
    "    if j==0:\n",
    "        h5f.create_dataset('phis', data=h5f_worker['phis'][:], compression=\"lzf\", shuffle=True)\n",
    "    for ID in phase_worker['IDs']:\n",
    "        h5f.create_dataset(ID, data=h5f_worker[ID][:], compression=\"lzf\", shuffle=True)\n",
    "    total_phase['R0s'] = total_phase['R0s'] + phase_worker['R0s']\n",
    "    total_phase['w0s'] = total_phase['w0s'] + phase_worker['w0s']\n",
    "    total_phase['Zs'] = total_phase['Zs'] + phase_worker['Zs']\n",
    "    total_phase['IDs'] = total_phase['IDs'] + phase_worker['IDs']\n",
    "    h5f_worker.close()\n",
    "    print(f\"Worker {j} done!\")\n",
    "json.dump(total_phase, open( f\"{output_directory}/STRUCTURE_Grid_R0_{N_R0}_w0_{N_w0}_Z_{N_Z}.json\", \"w\"))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) Using h5 from (A) Generate a Random NOISY Image Library (with just the ground-truth angle $\\phi_{CR}$)\n",
    "## Images in .png format and labels in their names\n",
    "### Useful for the CNN-s and Emedders just dealing with the Noisy images and the GT $\\phi_{CR}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here (in the hidden cell) is the Dataset and Sampler classes designed to use the $.h5$ from (A) directly. It will be used to retrieve the pure images to which afterwards a random noising is applied. These will then be written to $.png$ images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "#device=\"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "'''\n",
    "La idea es que cada 5 epochs, se cambie el dataset efectivo, que sera un subset de los R0,w0,Z posibles\n",
    "multiplicado por el batch size (phiCR posibles). En cada batch, las imagenes enviadas seran todas\n",
    "de un mismo D matrix (R0,w0,Z) con diferentes angulos elegidos aleatoriamente con una uniforme\n",
    "'''\n",
    "class R0_w0_Z_Sampler(Sampler):\n",
    "    def __init__(self, R0_weights, w0_weights, Z_weights, num_batches_per_epoch):\n",
    "        self.num_batches = num_batches_per_epoch\n",
    "        self.R0_weights = R0_weights\n",
    "        self.w0_weights = w0_weights\n",
    "        self.Z_weights = Z_weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.stack((\n",
    "            torch.multinomial(self.R0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.w0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.Z_weights, self.num_batches, replacement=True)),\n",
    "            dim=1).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class CR_Dataset(Dataset):\n",
    "    def __init__(self, D_matrix_file_path, ID_file_path, device, X=605, generate_images_w_depth=8, random_seed=666, \n",
    "                batch_size=10, num_batches_per_epoch=100, apply_noise=True,\n",
    "                all_stregths_random_per_epoch=False,\n",
    "                max_poisson_strength=0.5, max_blob_strength=0.5, max_angular_modulation_strength=0.5,\n",
    "                poisson_strength=0.3, blob_strength=0.1, angular_modulation_strength=0.25,\n",
    "                min_modulation_frec=2*np.pi/6, max_modulation_frec=2*np.pi/2,\n",
    "                max_blobs=1, min_blob_sigma=100, max_blob_sigma=130\n",
    "                ):\n",
    "        # If all_strengths_random_per_ecpoh, then arguments about the maximum will be valid while not the strength arguments\n",
    "        # If false, then the arguments about the particular stregths will be the global stregths\n",
    "        np.random.seed(random_seed) \n",
    "        torch.manual_seed(random_seed)\n",
    "        self.D_matrix_file_path=D_matrix_file_path\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(ID_file_path)))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "        self.epoch_size = batch_size*num_batches_per_epoch\n",
    "        self.device = device\n",
    "        self.im_type = torch.uint16 if generate_images_w_depth==16 else torch.uint8\n",
    "        self.max_intensity = 65535 if generate_images_w_depth==16 else 254\n",
    "        self.X=X\n",
    "        self.apply_noise=apply_noise\n",
    "        self.poisson_strength=poisson_strength\n",
    "        self.blob_strength=blob_strength\n",
    "        self.angular_modulation_strength=angular_modulation_strength\n",
    "        self.min_modulation_frec=min_modulation_frec\n",
    "        self.max_modulation_frec=max_modulation_frec\n",
    "        self.max_blobs=max_blobs\n",
    "        self.min_blob_sigma=min_blob_sigma\n",
    "        self.max_blob_sigma=max_blob_sigma\n",
    "        self.all_stregths_random_per_epoch=all_stregths_random_per_epoch\n",
    "        self.max_poisson_strength=max_poisson_strength\n",
    "        self.max_blob_strength=max_blob_strength\n",
    "        self.max_angular_modulation_strength=max_angular_modulation_strength\n",
    "        \n",
    "    #def update_dataset o set_epoch_number y que aqui se genere directamente el dataset entero para las epochs que vienen\n",
    "    # lo que permitiria es que cada X epochs, se ahorrase el tener que re-generar todas las imagenes\n",
    "    # Pero claro, la pregunta es, la RAM aguantaria?\n",
    "    # Si haces con update_dataset, entonces no haria falta hacer un sampler custom, con el normal ya bastaria\n",
    "    \n",
    "    # Bueno, por ahora, vamos a hacer que en cada minibatch, se haga todo el puroceso. La cosa es que asi se \n",
    "    # puede aprovechar el multiprocessing innato, si no habria que hacer el multiprocessing dentroe del update_dataset\n",
    "    # o simplemente prescindir de hacerlo supongo.\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'h5f_D_matrices'):\n",
    "            self.h5f_D_matrices.close()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "    \n",
    "    def open_hdf5(self):\n",
    "        self.h5f_D_matrices = h5py.File( self.D_matrix_file_path, 'r')\n",
    "        #self.dataset = self.img_hdf5['dataset'] # if you want dataset.\n",
    "        \n",
    "\n",
    "    def compute_intensity_gravity_centers(self, images):\n",
    "        \"\"\"\n",
    "            Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "            It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "            Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "        \"\"\"\n",
    "        # image wise total intensity and marginalized inensities for weighted sum\n",
    "        intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "        intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "        total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "        # Compute mass center for intensity\n",
    "        # [N_images, 2] (h_center,w_center)\n",
    "        return torch.nan_to_num( torch.stack(\n",
    "            (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity,\n",
    "             torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity),\n",
    "            dim=1\n",
    "            ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    def compute_raw_to_centered_iX(self, images):\n",
    "\n",
    "        g_raw = self.compute_intensity_gravity_centers(images) # [ N_images, 2]\n",
    "\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*self.X+1, 2*self.X+1),  dtype = images.dtype, \n",
    "                                      device=self.device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-self.X\n",
    "        unclipped_upper = g_index_raw+self.X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(self.device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(self.device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(g_raw.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images\n",
    "    \n",
    "    def apply_random_camera_noises(self, images):\n",
    "        # Poisson noise\n",
    "        # the images are expected to already be normalized and in the integer range of the camera\n",
    "        return torch.clamp((1-self.poisson_strength)*images+self.poisson_strength*torch.poisson(images), max=self.max_intensity) \n",
    "                                    # rates are the expected intensities of the imaging time\n",
    "\n",
    "    def _gaussian_2D_pdfs(self, x_ys, mus, sigmas, strengths):\n",
    "        '''\n",
    "        x_ys : [batch_size, blob_num, 2 (h,w), 2X+1, 2X+1]\n",
    "        mus : [batch_size, blob_num, 2 (h,w), 1, 1]\n",
    "        sigmas : [batch_size, blob_num, 2(h,w), 1, 1]\n",
    "        strengths : [batch_size, blob_num, 1, 1]\n",
    "        ------\n",
    "        out : [batch_size, 2X+1, 2X+1]\n",
    "        '''\n",
    "        gaussians = torch.sum((strengths/(2*np.pi)/sigmas[:,:,0]/sigmas[:,:,1])*torch.exp(\n",
    "                -(x_ys[:,:,0,:,:]-mus[:,:,0])**2/(2*sigmas[:,:,0]**2))*torch.exp(\n",
    "                -(x_ys[:,:,1,:,:]-mus[:,:,1])**2/(2*sigmas[:,:,1]**2)), dim=1) # since strength is normalized, the whole mixture is normalized as well\n",
    "        return gaussians/gaussians.amax(dim=(1,2)).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    def apply_random_pre_camera_noises(self, images):\n",
    "        # note that the input images are expected to still be centered in the gravicenter and have no normalization\n",
    "\n",
    "        # Gaussian Blobs - subtract gaussian blobs of different depths to the intensity pattern\n",
    "        # First randomly sample the centers of the blobs and their standard deviations for each image\n",
    "        # we will sample the means with probabilities proportional to the CR ring intensity pattern\n",
    "        blob_num = np.random.randint(0, self.max_blobs+1, size=1)[0]\n",
    "        if blob_num!=0:\n",
    "            mu_s = torch.stack(\n",
    "                (torch.multinomial(images.sum(dim=2),\n",
    "                        num_samples=blob_num, \n",
    "                        replacement=False), \n",
    "                 torch.multinomial(images.sum(dim=1),\n",
    "                        num_samples=blob_num, \n",
    "                        replacement=False) ),\n",
    "                 dim=2\n",
    "                ).to(self.device) #[batch_size, blob_num, 2(h,w)] mu-s are in pixel units and coordinates\n",
    "\n",
    "            sigma_s = torch.from_numpy(np.random.randint(self.min_blob_sigma, self.max_blob_sigma, \n",
    "                        size=(images.shape[0], blob_num, 2))).to(self.device) #[batch_size, blob_num, 2(h,w)]\n",
    "            strengths = torch.rand(size=(images.shape[0], blob_num)).to(self.device) #[batch_size, blob_num]\n",
    "            strengths = strengths/strengths.sum(dim=1).unsqueeze(1) # normalized strengths between blobs\n",
    "\n",
    "            w = torch.arange(images.shape[1]).repeat((images.shape[1],1)).to(self.device)\n",
    "            h = w.transpose(0,1).to(self.device)\n",
    "            h_w = torch.stack((h,w), dim=0).to(self.device)\n",
    "            images = images*(1-self.blob_strength*self._gaussian_2D_pdfs( h_w.view((1,1)+h_w.shape), \n",
    "                mu_s.view(mu_s.shape+(1,1)), sigma_s.view(sigma_s.shape+(1,1)), strengths.view(strengths.shape+(1,1)) )\n",
    "                     )           #[batch_size, 2X+1, 2X+1]        \n",
    "        # Poisson noise - makes the intesity be a poissonian generated value instead of the expected values\n",
    "        #images = (1-poisson_strength)*images+poisson_strength*torch.poisson(images) # rates are the expected intensities of the imaging time\n",
    "        # but must be an integer matrix!\n",
    "\n",
    "        # Angular Modulation - apply a pseudo-random continous wave modulation to the ring angularly\n",
    "        random_frecs = (self.min_modulation_frec + (self.max_modulation_frec-self.min_modulation_frec)*torch.rand(\n",
    "                                size=(3,images.shape[0], 1,1))).to(self.device)\n",
    "        strengths = torch.rand(size=(3, images.shape[0], 1,1)).to(self.device) #[3, batch_size, 1,1]\n",
    "        strengths = strengths/strengths.sum(dim=0) # normalized strengths between sin and coss\n",
    "        images = images*(\n",
    "            1-self.angular_modulation_strength*(\n",
    "                strengths[0]*torch.cos(random_frecs[0]*self.phis)+\n",
    "                strengths[1]*torch.sin(random_frecs[1]*self.phis)+\n",
    "                strengths[2]*torch.cos(random_frecs[2]*self.phis)\n",
    "            )**2) #[batch_size, 2X+1, 2X+1]\n",
    "\n",
    "        # Angular-Radial Modulation # serÃ­a coger phis y coger radios y con eso hacer uan funcion de ambas, de forma\n",
    "        # que por ejemplo afecte de manera diferente al mismo angulo en cada ring el pre-pogendorf y el otro\n",
    "\n",
    "        # Modos superiores\n",
    "        # esto ya es un jaleo xD\n",
    "        return images\n",
    "\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, R0_w0_Z_idxs):\n",
    "        # In order to allow multiprocessing data loading, each worker needs to initialize \n",
    "        # the h5f loader, which must be done in the first iteration of getitem and not in the init\n",
    "        # of the parent process\n",
    "        if not hasattr(self, 'h5f_D_matrices'):\n",
    "            self.open_hdf5()\n",
    "            self.phis = torch.from_numpy(self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(self.device) #[1,Nx,Ny]\n",
    "\n",
    "        D_mats = torch.from_numpy(self.h5f_D_matrices[\n",
    "                f\"R0_{self.R0s[R0_w0_Z_idxs[0]]}_w0_{self.w0s[R0_w0_Z_idxs[1]]}_Z_{self.Zs[R0_w0_Z_idxs[2]]}\"][:]\n",
    "                                 ).unsqueeze(1).to(self.device) #[2, 1, Nx, Ny]            \n",
    "         \n",
    "        phiCRs = torch.FloatTensor(self.batch_size, 1, 1).uniform_(-np.pi, np.pi).to(self.device) #[batch_size, 1, 1]\n",
    "        images = D_mats[0]+D_mats[1]*torch.cos(phiCRs-self.phis) #[batch_size, Nx,Ny]\n",
    "        \n",
    "        if self.apply_noise:\n",
    "            if self.all_stregths_random_per_epoch:\n",
    "                self.poisson_strength = self.max_poisson_strength*np.random.rand()\n",
    "                self.angular_modulation_strength = self.max_angular_modulation_strength*np.random.rand()\n",
    "                self.blob_strength = self.max_blob_strength*np.random.rand()\n",
    "            \n",
    "            # Apply precamera noise to images (while still floats)\n",
    "            images = self.apply_random_pre_camera_noises(images)\n",
    "        \n",
    "        # convert images to selected uint format\n",
    "        images = (self.max_intensity*(images/images.amax(dim=(1,2), keepdim=True)[0].unsqueeze(1)))\n",
    "        \n",
    "        if self.apply_noise:\n",
    "            # Apply camera noises (now that normalized and integers)\n",
    "            images = self.apply_random_camera_noises(images)\n",
    "        \n",
    "        images = images.type(self.im_type)\n",
    "\n",
    "        # get iX images\n",
    "        images = self.compute_raw_to_centered_iX(images) #[batch_size, 2X+1, 2X+1]\n",
    "        labels = torch.Tensor([[float(self.R0s[R0_w0_Z_idxs[0]]), float(self.w0s[R0_w0_Z_idxs[1]]), \n",
    "                               float(self.Zs[R0_w0_Z_idxs[2]])]]).to(self.device) #[1,4]\n",
    "        labels = torch.hstack( ( labels.expand(self.batch_size, 3), phiCRs.squeeze(2) ) ) #[4, batch_size]\n",
    "        del D_mats, phiCRs\n",
    "        torch.cuda.empty_cache()\n",
    "        return images, labels #[ batch_size, 2X+1, 2X+1] and [batch_size, 4]\n",
    "        # The whole batch is already in the GPU, since to process it we wanted it to be there\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import h5py\n",
    "from IPython import display\n",
    "\n",
    "output_directory=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NOISY/TRAIN/\"\n",
    "#output_directory=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TRAIN/\"\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Encoder_Alone/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "        \n",
    "\n",
    "total_images_to_generate = 500000 # para el test set unos 100000 bien supongo\n",
    "\n",
    "batch_size = 10\n",
    "number_of_batches_per_epoch = int(total_images_to_generate/batch_size)\n",
    "\n",
    "assert(total_images_to_generate%batch_size==0)\n",
    "\n",
    "X=302\n",
    "generate_images_w_depth=8\n",
    "random_seed=666 # 669 aldatu seede para generar los validation set!!!\n",
    "\n",
    "apply_noise=True # Genera otro dataset pair sin noise tb\n",
    "all_stregths_random_per_epoch=True\n",
    "max_poisson_strength=0.5\n",
    "max_blob_strength=0.5\n",
    "max_angular_modulation_strength=0.5\n",
    "poisson_strength=0.4\n",
    "blob_strength=0.2\n",
    "angular_modulation_strength=0.2\n",
    "min_modulation_frec=2*np.pi/6\n",
    "max_modulation_frec=2*np.pi/2\n",
    "max_blobs=2\n",
    "min_blob_sigma=100\n",
    "max_blob_sigma=130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma, normalized_output=True):\n",
    "    p_s = (1/np.sqrt(2*np.pi)/sigma)*torch.exp(-(x-mu)**2/(2*sigma**2))\n",
    "    return p_s/p_s.sum() if normalized_output else p_s\n",
    "\n",
    "phase_vigilant = pd.DataFrame.from_dict(json.load(open(ID_file_path)))\n",
    "R0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['R0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=158, sigma=8)\n",
    "w0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['w0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=25, sigma=4)\n",
    "Z_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['Zs'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=0, sigma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = R0_w0_Z_Sampler( R0_weights, w0_weights, Z_weights, num_batches_per_epoch=number_of_batches_per_epoch)\n",
    "dataset = CR_Dataset(D_matrix_file_path=D_matrix_file_path,\n",
    "            ID_file_path =ID_file_path, \n",
    "            device = device,\n",
    "            X=X, generate_images_w_depth=generate_images_w_depth, random_seed=random_seed, \n",
    "            batch_size=batch_size, num_batches_per_epoch=number_of_batches_per_epoch,\n",
    "            apply_noise=apply_noise, all_stregths_random_per_epoch=all_stregths_random_per_epoch,\n",
    "            max_poisson_strength=max_poisson_strength, max_blob_strength=max_blob_strength,\n",
    "            max_angular_modulation_strength=max_angular_modulation_strength,\n",
    "            poisson_strength=poisson_strength, blob_strength=blob_strength, \n",
    "            angular_modulation_strength=angular_modulation_strength,\n",
    "            min_modulation_frec=min_modulation_frec, max_modulation_frec=max_modulation_frec,\n",
    "            max_blobs=max_blobs, min_blob_sigma=min_blob_sigma, max_blob_sigma=max_blob_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "j=0\n",
    "output_info_every=100\n",
    "ground_truths={'ID':[], 'phiCR':[]}\n",
    "for i in sampler:\n",
    "    imgs, labs = dataset[i]\n",
    "    imgs = np.asarray(imgs.to('cpu'))\n",
    "    labs = np.asarray(labs.to('cpu'))\n",
    "    for k in range(imgs.shape[0]):\n",
    "        cv2.imwrite(f\"{output_directory}/IM_{j}_phiCR_{labs[k][-1]}.png\", imgs[k])\n",
    "        ground_truths['ID'].append(j)\n",
    "        ground_truths['phiCR'].append(f\"{labs[k][-1]}\")\n",
    "        j+=1\n",
    "        if j%output_info_every==0:\n",
    "            display.clear_output(wait=True)\n",
    "            print(f\"Processed {j}/{total_images_to_generate} images {j/total_images_to_generate*100} %\")\n",
    "json.dump(ground_truths, open( f\"{output_directory}/GROUND_TRUTHS.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (C) Using h5 (A) Generate a Random NOISY and corresponding NON-NOISY Image h5 Dataset\n",
    "# (with the GT denoised image and the ground-truth angle $\\phi_{CR}$)\n",
    "## Noisy and Original Images in numpy array batches in an h5 format and labels in a json relating the index of the h5 with the ground-truth $phi_CR$ list\n",
    "### Useful for the Denoising CNN-s and Metric Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here (in the hidden cell) is the Dataset and Sampler classes designed to use the $.h5$ from (A) directly. It will be used to retrieve the pure images to which afterwards a random noising is applied. It will have a little modification to allow the retrieval of the denoised images as well. These will be packed in batches of uint8 images to write them to an $.h5$ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "#device=\"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "'''\n",
    "La idea es que cada 5 epochs, se cambie el dataset efectivo, que sera un subset de los R0,w0,Z posibles\n",
    "multiplicado por el batch size (phiCR posibles). En cada batch, las imagenes enviadas seran todas\n",
    "de un mismo D matrix (R0,w0,Z) con diferentes angulos elegidos aleatoriamente con una uniforme\n",
    "'''\n",
    "class R0_w0_Z_Sampler(Sampler):\n",
    "    def __init__(self, R0_weights, w0_weights, Z_weights, num_batches_per_epoch):\n",
    "        self.num_batches = num_batches_per_epoch\n",
    "        self.R0_weights = R0_weights\n",
    "        self.w0_weights = w0_weights\n",
    "        self.Z_weights = Z_weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.stack((\n",
    "            torch.multinomial(self.R0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.w0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.Z_weights, self.num_batches, replacement=True)),\n",
    "            dim=1).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class CR_Dataset(Dataset):\n",
    "    def __init__(self, D_matrix_file_path, ID_file_path, device, X=605, generate_images_w_depth=8, random_seed=666, \n",
    "                batch_size=10, num_batches_per_epoch=100, apply_noise=True,\n",
    "                all_stregths_random_per_epoch=False,\n",
    "                max_poisson_strength=0.5, max_blob_strength=0.5, max_angular_modulation_strength=0.5,\n",
    "                poisson_strength=0.3, blob_strength=0.1, angular_modulation_strength=0.25,\n",
    "                min_modulation_frec=2*np.pi/6, max_modulation_frec=2*np.pi/2,\n",
    "                max_blobs=1, min_blob_sigma=100, max_blob_sigma=130\n",
    "                ):\n",
    "        # If all_strengths_random_per_ecpoh, then arguments about the maximum will be valid while not the strength arguments\n",
    "        # If false, then the arguments about the particular stregths will be the global stregths\n",
    "        np.random.seed(random_seed) \n",
    "        torch.manual_seed(random_seed)\n",
    "        self.D_matrix_file_path=D_matrix_file_path\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(ID_file_path)))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "        self.epoch_size = batch_size*num_batches_per_epoch\n",
    "        self.device = device\n",
    "        self.im_type = torch.uint16 if generate_images_w_depth==16 else torch.uint8\n",
    "        self.max_intensity = 65535 if generate_images_w_depth==16 else 254\n",
    "        self.X=X\n",
    "        self.apply_noise=apply_noise\n",
    "        self.poisson_strength=poisson_strength\n",
    "        self.blob_strength=blob_strength\n",
    "        self.angular_modulation_strength=angular_modulation_strength\n",
    "        self.min_modulation_frec=min_modulation_frec\n",
    "        self.max_modulation_frec=max_modulation_frec\n",
    "        self.max_blobs=max_blobs\n",
    "        self.min_blob_sigma=min_blob_sigma\n",
    "        self.max_blob_sigma=max_blob_sigma\n",
    "        self.all_stregths_random_per_epoch=all_stregths_random_per_epoch\n",
    "        self.max_poisson_strength=max_poisson_strength\n",
    "        self.max_blob_strength=max_blob_strength\n",
    "        self.max_angular_modulation_strength=max_angular_modulation_strength\n",
    "        \n",
    "    #def update_dataset o set_epoch_number y que aqui se genere directamente el dataset entero para las epochs que vienen\n",
    "    # lo que permitiria es que cada X epochs, se ahorrase el tener que re-generar todas las imagenes\n",
    "    # Pero claro, la pregunta es, la RAM aguantaria?\n",
    "    # Si haces con update_dataset, entonces no haria falta hacer un sampler custom, con el normal ya bastaria\n",
    "    \n",
    "    # Bueno, por ahora, vamos a hacer que en cada minibatch, se haga todo el puroceso. La cosa es que asi se \n",
    "    # puede aprovechar el multiprocessing innato, si no habria que hacer el multiprocessing dentroe del update_dataset\n",
    "    # o simplemente prescindir de hacerlo supongo.\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'h5f_D_matrices'):\n",
    "            self.h5f_D_matrices.close()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "    \n",
    "    def open_hdf5(self):\n",
    "        self.h5f_D_matrices = h5py.File( self.D_matrix_file_path, 'r')\n",
    "        #self.dataset = self.img_hdf5['dataset'] # if you want dataset.\n",
    "        \n",
    "\n",
    "    def compute_intensity_gravity_centers(self, images):\n",
    "        \"\"\"\n",
    "            Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "            It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "            Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "        \"\"\"\n",
    "        # image wise total intensity and marginalized inensities for weighted sum\n",
    "        intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "        intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "        total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "        # Compute mass center for intensity\n",
    "        # [N_images, 2] (h_center,w_center)\n",
    "        return torch.nan_to_num( torch.stack(\n",
    "            (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity,\n",
    "             torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity),\n",
    "            dim=1\n",
    "            ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    def compute_raw_to_centered_iX(self, images):\n",
    "\n",
    "        g_raw = self.compute_intensity_gravity_centers(images) # [ N_images, 2]\n",
    "\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*self.X+1, 2*self.X+1),  dtype = images.dtype, \n",
    "                                      device=self.device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-self.X\n",
    "        unclipped_upper = g_index_raw+self.X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(self.device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(self.device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(g_raw.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images\n",
    "    \n",
    "    def apply_random_camera_noises(self, images):\n",
    "        # Poisson noise\n",
    "        # the images are expected to already be normalized and in the integer range of the camera\n",
    "        return torch.clamp((1-self.poisson_strength)*images+self.poisson_strength*torch.poisson(images), max=self.max_intensity) \n",
    "                                    # rates are the expected intensities of the imaging time\n",
    "\n",
    "    def _gaussian_2D_pdfs(self, x_ys, mus, sigmas, strengths):\n",
    "        '''\n",
    "        x_ys : [batch_size, blob_num, 2 (h,w), 2X+1, 2X+1]\n",
    "        mus : [batch_size, blob_num, 2 (h,w), 1, 1]\n",
    "        sigmas : [batch_size, blob_num, 2(h,w), 1, 1]\n",
    "        strengths : [batch_size, blob_num, 1, 1]\n",
    "        ------\n",
    "        out : [batch_size, 2X+1, 2X+1]\n",
    "        '''\n",
    "        gaussians = torch.sum((strengths/(2*np.pi)/sigmas[:,:,0]/sigmas[:,:,1])*torch.exp(\n",
    "                -(x_ys[:,:,0,:,:]-mus[:,:,0])**2/(2*sigmas[:,:,0]**2))*torch.exp(\n",
    "                -(x_ys[:,:,1,:,:]-mus[:,:,1])**2/(2*sigmas[:,:,1]**2)), dim=1) # since strength is normalized, the whole mixture is normalized as well\n",
    "        return gaussians/gaussians.amax(dim=(1,2)).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    def apply_random_pre_camera_noises(self, images):\n",
    "        # note that the input images are expected to still be centered in the gravicenter and have no normalization\n",
    "\n",
    "        # Gaussian Blobs - subtract gaussian blobs of different depths to the intensity pattern\n",
    "        # First randomly sample the centers of the blobs and their standard deviations for each image\n",
    "        # we will sample the means with probabilities proportional to the CR ring intensity pattern\n",
    "        blob_num = np.random.randint(0, self.max_blobs+1, size=1)[0]\n",
    "        if blob_num!=0:\n",
    "            mu_s = torch.stack(\n",
    "                (torch.multinomial(images.sum(dim=2),\n",
    "                        num_samples=blob_num, \n",
    "                        replacement=False), \n",
    "                 torch.multinomial(images.sum(dim=1),\n",
    "                        num_samples=blob_num, \n",
    "                        replacement=False) ),\n",
    "                 dim=2\n",
    "                ).to(self.device) #[batch_size, blob_num, 2(h,w)] mu-s are in pixel units and coordinates\n",
    "\n",
    "            sigma_s = torch.from_numpy(np.random.randint(self.min_blob_sigma, self.max_blob_sigma, \n",
    "                        size=(images.shape[0], blob_num, 2))).to(self.device) #[batch_size, blob_num, 2(h,w)]\n",
    "            strengths = torch.rand(size=(images.shape[0], blob_num)).to(self.device) #[batch_size, blob_num]\n",
    "            strengths = strengths/strengths.sum(dim=1).unsqueeze(1) # normalized strengths between blobs\n",
    "\n",
    "            w = torch.arange(images.shape[1]).repeat((images.shape[1],1)).to(self.device)\n",
    "            h = w.transpose(0,1).to(self.device)\n",
    "            h_w = torch.stack((h,w), dim=0).to(self.device)\n",
    "            images = images*(1-self.blob_strength*self._gaussian_2D_pdfs( h_w.view((1,1)+h_w.shape), \n",
    "                mu_s.view(mu_s.shape+(1,1)), sigma_s.view(sigma_s.shape+(1,1)), strengths.view(strengths.shape+(1,1)) )\n",
    "                     )           #[batch_size, 2X+1, 2X+1]        \n",
    "        # Poisson noise - makes the intesity be a poissonian generated value instead of the expected values\n",
    "        #images = (1-poisson_strength)*images+poisson_strength*torch.poisson(images) # rates are the expected intensities of the imaging time\n",
    "        # but must be an integer matrix!\n",
    "\n",
    "        # Angular Modulation - apply a pseudo-random continous wave modulation to the ring angularly\n",
    "        random_frecs = (self.min_modulation_frec + (self.max_modulation_frec-self.min_modulation_frec)*torch.rand(\n",
    "                                size=(3,images.shape[0], 1,1))).to(self.device)\n",
    "        strengths = torch.rand(size=(3, images.shape[0], 1,1)).to(self.device) #[3, batch_size, 1,1]\n",
    "        strengths = strengths/strengths.sum(dim=0) # normalized strengths between sin and coss\n",
    "        images = images*(\n",
    "            1-self.angular_modulation_strength*(\n",
    "                strengths[0]*torch.cos(random_frecs[0]*self.phis)+\n",
    "                strengths[1]*torch.sin(random_frecs[1]*self.phis)+\n",
    "                strengths[2]*torch.cos(random_frecs[2]*self.phis)\n",
    "            )**2) #[batch_size, 2X+1, 2X+1]\n",
    "\n",
    "        # Angular-Radial Modulation # serÃ­a coger phis y coger radios y con eso hacer uan funcion de ambas, de forma\n",
    "        # que por ejemplo afecte de manera diferente al mismo angulo en cada ring el pre-pogendorf y el otro\n",
    "\n",
    "        # Modos superiores\n",
    "        # esto ya es un jaleo xD\n",
    "        return images\n",
    "\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, R0_w0_Z_idxs):\n",
    "        # In order to allow multiprocessing data loading, each worker needs to initialize \n",
    "        # the h5f loader, which must be done in the first iteration of getitem and not in the init\n",
    "        # of the parent process\n",
    "        if not hasattr(self, 'h5f_D_matrices'):\n",
    "            self.open_hdf5()\n",
    "            self.phis = torch.from_numpy(self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(self.device) #[1,Nx,Ny]\n",
    "\n",
    "        D_mats = torch.from_numpy(self.h5f_D_matrices[\n",
    "                f\"R0_{self.R0s[R0_w0_Z_idxs[0]]}_w0_{self.w0s[R0_w0_Z_idxs[1]]}_Z_{self.Zs[R0_w0_Z_idxs[2]]}\"][:]\n",
    "                                 ).unsqueeze(1).to(self.device) #[2, 1, Nx, Ny]            \n",
    "         \n",
    "        phiCRs = torch.FloatTensor(self.batch_size, 1, 1).uniform_(-np.pi, np.pi).to(self.device) #[batch_size, 1, 1]\n",
    "        images = D_mats[0]+D_mats[1]*torch.cos(phiCRs-self.phis) #[batch_size, Nx,Ny]\n",
    "        \n",
    "        original_images = images.clone() # Alteration of the original code to allow their output\n",
    "        \n",
    "        if self.apply_noise:\n",
    "            if self.all_stregths_random_per_epoch:\n",
    "                self.poisson_strength = self.max_poisson_strength*np.random.rand()\n",
    "                self.angular_modulation_strength = self.max_angular_modulation_strength*np.random.rand()\n",
    "                self.blob_strength = self.max_blob_strength*np.random.rand()\n",
    "            \n",
    "            # Apply precamera noise to images (while still floats)\n",
    "            images = self.apply_random_pre_camera_noises(images)\n",
    "        \n",
    "        # convert original and precamera noisy images to selected uint format\n",
    "        images = (self.max_intensity*(images/images.amax(dim=(1,2), keepdim=True)[0].unsqueeze(1)))\n",
    "        original_images = (self.max_intensity*(original_images/original_images.amax(dim=(1,2), keepdim=True)[0].unsqueeze(1)))\n",
    "        \n",
    "        if self.apply_noise:\n",
    "            # Apply camera noises (now that normalized and integers)\n",
    "            images = self.apply_random_camera_noises(images)\n",
    "        \n",
    "        images = images.type(self.im_type)\n",
    "        original_images = original_images.type(self.im_type)\n",
    "        \n",
    "        # concatenate the noisy and non-noisy images\n",
    "        images = torch.cat((images, original_images), 0)\n",
    "\n",
    "        # get iX images\n",
    "        images = self.compute_raw_to_centered_iX(images) #[2*batch_size, 2X+1, 2X+1]\n",
    "        \n",
    "        labels = torch.Tensor([[float(self.R0s[R0_w0_Z_idxs[0]]), float(self.w0s[R0_w0_Z_idxs[1]]), \n",
    "                               float(self.Zs[R0_w0_Z_idxs[2]])]]).to(self.device) #[1,4]\n",
    "        labels = torch.hstack( ( labels.expand(self.batch_size, 3), phiCRs.squeeze(2) ) ) #[4, batch_size]\n",
    "        del D_mats, phiCRs, original_images\n",
    "        torch.cuda.empty_cache()\n",
    "        return images, labels #[ 2*batch_size, 2X+1, 2X+1] and [batch_size, 4]\n",
    "        # The whole batch is already in the GPU, since to process it we wanted it to be there\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import h5py\n",
    "from IPython import display\n",
    "\n",
    "output_directory=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/Noisy_Non_Noisy_Different_Angles/TRAIN/\"\n",
    "#output_directory=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/\"\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Encoder_Alone/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "        \n",
    "\n",
    "total_images_to_generate = 200000 # para el test set unos 100000 bien supongo\n",
    "\n",
    "batch_size = 10\n",
    "number_of_batches_per_epoch = int(total_images_to_generate/batch_size)\n",
    "\n",
    "assert(total_images_to_generate%batch_size==0)\n",
    "\n",
    "X=302\n",
    "generate_images_w_depth=8\n",
    "random_seed=666 # 669 aldatu seede para generar los validation set!!!\n",
    "\n",
    "apply_noise=True # Genera otro dataset pair sin noise tb\n",
    "all_stregths_random_per_epoch=True\n",
    "max_poisson_strength=0.5\n",
    "max_blob_strength=0.5\n",
    "max_angular_modulation_strength=0.5\n",
    "poisson_strength=0.4\n",
    "blob_strength=0.2\n",
    "angular_modulation_strength=0.2\n",
    "min_modulation_frec=2*np.pi/6\n",
    "max_modulation_frec=2*np.pi/2\n",
    "max_blobs=2\n",
    "min_blob_sigma=100\n",
    "max_blob_sigma=130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma, normalized_output=True):\n",
    "    p_s = (1/np.sqrt(2*np.pi)/sigma)*torch.exp(-(x-mu)**2/(2*sigma**2))\n",
    "    return p_s/p_s.sum() if normalized_output else p_s\n",
    "\n",
    "phase_vigilant = pd.DataFrame.from_dict(json.load(open(ID_file_path)))\n",
    "R0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['R0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=158, sigma=8)\n",
    "w0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['w0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=25, sigma=4)\n",
    "Z_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['Zs'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=0, sigma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = R0_w0_Z_Sampler( R0_weights, w0_weights, Z_weights, num_batches_per_epoch=number_of_batches_per_epoch)\n",
    "dataset = CR_Dataset(D_matrix_file_path=D_matrix_file_path,\n",
    "            ID_file_path =ID_file_path, \n",
    "            device = device,\n",
    "            X=X, generate_images_w_depth=generate_images_w_depth, random_seed=random_seed, \n",
    "            batch_size=batch_size, num_batches_per_epoch=number_of_batches_per_epoch,\n",
    "            apply_noise=apply_noise, all_stregths_random_per_epoch=all_stregths_random_per_epoch,\n",
    "            max_poisson_strength=max_poisson_strength, max_blob_strength=max_blob_strength,\n",
    "            max_angular_modulation_strength=max_angular_modulation_strength,\n",
    "            poisson_strength=poisson_strength, blob_strength=blob_strength, \n",
    "            angular_modulation_strength=angular_modulation_strength,\n",
    "            min_modulation_frec=min_modulation_frec, max_modulation_frec=max_modulation_frec,\n",
    "            max_blobs=max_blobs, min_blob_sigma=min_blob_sigma, max_blob_sigma=max_blob_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "h5f = h5py.File(f\"{output_directory}/Dataset_Noisy_Non_Noisy.h5\", 'a') # append if exists, create if not\n",
    "prev_batches = len(h5f)\n",
    "\n",
    "\n",
    "batch=0\n",
    "output_info_every=100\n",
    "\n",
    "try:\n",
    "    ground_truths = json.load(open(f\"{output_directory}/GROUND_TRUTHS_Noisy_Non_Noisy.json\"))\n",
    "except:\n",
    "    ground_truths={'ID':[], 'phiCRs':[]}\n",
    "\n",
    "for i in sampler:\n",
    "    imgs, labs = dataset[i]\n",
    "    imgs = np.asarray(imgs.to('cpu'))\n",
    "    labs = np.asarray(labs.to('cpu'))\n",
    "    ID=f\"{batch+prev_batches}\"\n",
    "    h5f.create_dataset(ID, data=imgs, compression=\"lzf\", shuffle=True)\n",
    "    ground_truths['ID'].append(batch+prev_batches)\n",
    "    ground_truths['phiCRs'].append( [f\"{ang}\" for ang in labs[:,-1]] )\n",
    "    batch+=1\n",
    "    if batch%output_info_every==0:\n",
    "        h5f.flush()\n",
    "        display.clear_output(wait=True)\n",
    "        print(f\"Processed {batch}/{number_of_batches_per_epoch} batches {batch/number_of_batches_per_epoch*100} %\")\n",
    "        json.dump(ground_truths, open( f\"{output_directory}/GROUND_TRUTHS.json\", \"w\"))\n",
    "\n",
    "h5f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "h5f = h5py.File(f\"{output_directory}/Dataset_Noisy_Non_Noisy.h5\",'r')\n",
    "print(len(h5f))\n",
    "imgs = h5f['800']\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(221)\n",
    "ax.imshow(imgs[0])\n",
    "ax=fig.add_subplot(222)\n",
    "ax.imshow(imgs[6])\n",
    "ax=fig.add_subplot(223)\n",
    "ax.imshow(imgs[10])\n",
    "ax=fig.add_subplot(224)\n",
    "ax.imshow(imgs[16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (D) Using h5 (A) Generate a Random NON-NOISY and corresponding train of NOISY Image h5 Dataset\n",
    "# (with the GT denoised image and the ground-truth angle $\\phi_{CR}$)\n",
    "## Noisy and Original Images in numpy array batches in an h5 format and labels in a json relating the index of the h5 with the ground-truth $phi_CR$ list\n",
    "### Useful for the Denoising CNN-s and Metric Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here (in the hidden cell) is the Dataset and Sampler classes designed to use the $.h5$ from (A) directly. It will be used to retrieve the pure images to which afterwards a random noising is applied. It will have a little modification to allow the retrieval of the denoised images as well. These will be packed in batches of uint8 images to write them to an $.h5$ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "#device=\"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "'''\n",
    "La idea es que cada 5 epochs, se cambie el dataset efectivo, que sera un subset de los R0,w0,Z posibles\n",
    "multiplicado por el batch size (phiCR posibles). En cada batch, las imagenes enviadas seran todas\n",
    "de un mismo D matrix (R0,w0,Z) con diferentes angulos elegidos aleatoriamente con una uniforme\n",
    "'''\n",
    "class R0_w0_Z_Sampler(Sampler):\n",
    "    def __init__(self, R0_weights, w0_weights, Z_weights, num_batches_per_epoch):\n",
    "        self.num_batches = num_batches_per_epoch\n",
    "        self.R0_weights = R0_weights\n",
    "        self.w0_weights = w0_weights\n",
    "        self.Z_weights = Z_weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.stack((\n",
    "            torch.multinomial(self.R0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.w0_weights, self.num_batches, replacement=True),\n",
    "            torch.multinomial(self.Z_weights, self.num_batches, replacement=True)),\n",
    "            dim=1).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class CR_Dataset(Dataset):\n",
    "    def __init__(self, D_matrix_file_path, ID_file_path, device, X=605, generate_images_w_depth=8, random_seed=666, \n",
    "                batch_size=10, num_batches_per_epoch=100, apply_noise=True,\n",
    "                all_stregths_random_per_epoch=False,\n",
    "                max_poisson_strength=0.5, max_blob_strength=0.5, max_angular_modulation_strength=0.5,\n",
    "                poisson_strength=0.3, blob_strength=0.1, angular_modulation_strength=0.25,\n",
    "                min_modulation_frec=2*np.pi/6, max_modulation_frec=2*np.pi/2,\n",
    "                max_blobs=1, min_blob_sigma=100, max_blob_sigma=130, K=4\n",
    "                ):\n",
    "        # If all_strengths_random_per_ecpoh, then arguments about the maximum will be valid while not the strength arguments\n",
    "        # If false, then the arguments about the particular stregths will be the global stregths\n",
    "        np.random.seed(random_seed) \n",
    "        torch.manual_seed(random_seed)\n",
    "        self.D_matrix_file_path=D_matrix_file_path\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(ID_file_path)))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "        self.epoch_size = batch_size*num_batches_per_epoch\n",
    "        self.device = device\n",
    "        self.im_type = torch.uint16 if generate_images_w_depth==16 else torch.uint8\n",
    "        self.max_intensity = 65535 if generate_images_w_depth==16 else 254\n",
    "        self.X=X\n",
    "        self.apply_noise=apply_noise\n",
    "        self.poisson_strength=poisson_strength\n",
    "        self.blob_strength=blob_strength\n",
    "        self.angular_modulation_strength=angular_modulation_strength\n",
    "        self.min_modulation_frec=min_modulation_frec\n",
    "        self.max_modulation_frec=max_modulation_frec\n",
    "        self.max_blobs=max_blobs\n",
    "        self.min_blob_sigma=min_blob_sigma\n",
    "        self.max_blob_sigma=max_blob_sigma\n",
    "        self.all_stregths_random_per_epoch=all_stregths_random_per_epoch\n",
    "        self.max_poisson_strength=max_poisson_strength\n",
    "        self.max_blob_strength=max_blob_strength\n",
    "        self.max_angular_modulation_strength=max_angular_modulation_strength\n",
    "        self.K=K\n",
    "        \n",
    "    #def update_dataset o set_epoch_number y que aqui se genere directamente el dataset entero para las epochs que vienen\n",
    "    # lo que permitiria es que cada X epochs, se ahorrase el tener que re-generar todas las imagenes\n",
    "    # Pero claro, la pregunta es, la RAM aguantaria?\n",
    "    # Si haces con update_dataset, entonces no haria falta hacer un sampler custom, con el normal ya bastaria\n",
    "    \n",
    "    # Bueno, por ahora, vamos a hacer que en cada minibatch, se haga todo el puroceso. La cosa es que asi se \n",
    "    # puede aprovechar el multiprocessing innato, si no habria que hacer el multiprocessing dentroe del update_dataset\n",
    "    # o simplemente prescindir de hacerlo supongo.\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'h5f_D_matrices'):\n",
    "            self.h5f_D_matrices.close()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "    \n",
    "    def open_hdf5(self):\n",
    "        self.h5f_D_matrices = h5py.File( self.D_matrix_file_path, 'r')\n",
    "        #self.dataset = self.img_hdf5['dataset'] # if you want dataset.\n",
    "        \n",
    "\n",
    "    def compute_intensity_gravity_centers(self, images):\n",
    "        \"\"\"\n",
    "            Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "            It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "            Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "        \"\"\"\n",
    "        # image wise total intensity and marginalized inensities for weighted sum\n",
    "        intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "        intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "        total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "        # Compute mass center for intensity\n",
    "        # [N_images, 2] (h_center,w_center)\n",
    "        return torch.nan_to_num( torch.stack(\n",
    "            (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity,\n",
    "             torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                        dtype=torch.float32, device=self.device))/total_intensity),\n",
    "            dim=1\n",
    "            ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    def compute_raw_to_centered_iX(self, images):\n",
    "\n",
    "        g_raw = self.compute_intensity_gravity_centers(images) # [ N_images, 2]\n",
    "\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*self.X+1, 2*self.X+1),  dtype = images.dtype, \n",
    "                                      device=self.device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-self.X\n",
    "        unclipped_upper = g_index_raw+self.X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(self.device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(self.device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(g_raw.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images\n",
    "    \n",
    "    def apply_random_camera_noises(self, images):\n",
    "        # Poisson noise\n",
    "        # the images are expected to already be normalized and in the integer range of the camera\n",
    "        return torch.clamp((1-self.poisson_strength)*images+self.poisson_strength*torch.poisson(images), max=self.max_intensity) \n",
    "                                    # rates are the expected intensities of the imaging time\n",
    "\n",
    "    def _gaussian_2D_pdfs(self, x_ys, mus, sigmas, strengths):\n",
    "        '''\n",
    "        x_ys : [batch_size, blob_num, 2 (h,w), 2X+1, 2X+1]\n",
    "        mus : [batch_size, blob_num, 2 (h,w), 1, 1]\n",
    "        sigmas : [batch_size, blob_num, 2(h,w), 1, 1]\n",
    "        strengths : [batch_size, blob_num, 1, 1]\n",
    "        ------\n",
    "        out : [batch_size, 2X+1, 2X+1]\n",
    "        '''\n",
    "        gaussians = torch.sum((strengths/(2*np.pi)/sigmas[:,:,0]/sigmas[:,:,1])*torch.exp(\n",
    "                -(x_ys[:,:,0,:,:]-mus[:,:,0])**2/(2*sigmas[:,:,0]**2))*torch.exp(\n",
    "                -(x_ys[:,:,1,:,:]-mus[:,:,1])**2/(2*sigmas[:,:,1]**2)), dim=1) # since strength is normalized, the whole mixture is normalized as well\n",
    "        return gaussians/gaussians.amax(dim=(1,2)).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    def apply_random_pre_camera_noises(self, images):\n",
    "        # note that the input images are expected to still be centered in the gravicenter and have no normalization\n",
    "\n",
    "        # Gaussian Blobs - subtract gaussian blobs of different depths to the intensity pattern\n",
    "        # First randomly sample the centers of the blobs and their standard deviations for each image\n",
    "        # we will sample the means with probabilities proportional to the CR ring intensity pattern\n",
    "        blob_num = np.random.randint(0, self.max_blobs+1, size=1)[0]\n",
    "        if blob_num!=0:\n",
    "            mu_s = torch.stack(\n",
    "                (torch.multinomial(images.sum(dim=2),\n",
    "                        num_samples=blob_num, \n",
    "                        replacement=False), \n",
    "                 torch.multinomial(images.sum(dim=1),\n",
    "                        num_samples=blob_num, \n",
    "                        replacement=False) ),\n",
    "                 dim=2\n",
    "                ).to(self.device) #[batch_size, blob_num, 2(h,w)] mu-s are in pixel units and coordinates\n",
    "\n",
    "            sigma_s = torch.from_numpy(np.random.randint(self.min_blob_sigma, self.max_blob_sigma, \n",
    "                        size=(images.shape[0], blob_num, 2))).to(self.device) #[batch_size, blob_num, 2(h,w)]\n",
    "            strengths = torch.rand(size=(images.shape[0], blob_num)).to(self.device) #[batch_size, blob_num]\n",
    "            strengths = strengths/strengths.sum(dim=1).unsqueeze(1) # normalized strengths between blobs\n",
    "\n",
    "            w = torch.arange(images.shape[1]).repeat((images.shape[1],1)).to(self.device)\n",
    "            h = w.transpose(0,1).to(self.device)\n",
    "            h_w = torch.stack((h,w), dim=0).to(self.device)\n",
    "            images = images*(1-self.blob_strength*self._gaussian_2D_pdfs( h_w.view((1,1)+h_w.shape), \n",
    "                mu_s.view(mu_s.shape+(1,1)), sigma_s.view(sigma_s.shape+(1,1)), strengths.view(strengths.shape+(1,1)) )\n",
    "                     )           #[batch_size, 2X+1, 2X+1]        \n",
    "        # Poisson noise - makes the intesity be a poissonian generated value instead of the expected values\n",
    "        #images = (1-poisson_strength)*images+poisson_strength*torch.poisson(images) # rates are the expected intensities of the imaging time\n",
    "        # but must be an integer matrix!\n",
    "\n",
    "        # Angular Modulation - apply a pseudo-random continous wave modulation to the ring angularly\n",
    "        random_frecs = (self.min_modulation_frec + (self.max_modulation_frec-self.min_modulation_frec)*torch.rand(\n",
    "                                size=(3,images.shape[0], 1,1))).to(self.device)\n",
    "        strengths = torch.rand(size=(3, images.shape[0], 1,1)).to(self.device) #[3, batch_size, 1,1]\n",
    "        strengths = strengths/strengths.sum(dim=0) # normalized strengths between sin and coss\n",
    "        images = images*(\n",
    "            1-self.angular_modulation_strength*(\n",
    "                strengths[0]*torch.cos(random_frecs[0]*self.phis)+\n",
    "                strengths[1]*torch.sin(random_frecs[1]*self.phis)+\n",
    "                strengths[2]*torch.cos(random_frecs[2]*self.phis)\n",
    "            )**2) #[batch_size, 2X+1, 2X+1]\n",
    "\n",
    "        # Angular-Radial Modulation # serÃ­a coger phis y coger radios y con eso hacer uan funcion de ambas, de forma\n",
    "        # que por ejemplo afecte de manera diferente al mismo angulo en cada ring el pre-pogendorf y el otro\n",
    "\n",
    "        # Modos superiores\n",
    "        # esto ya es un jaleo xD\n",
    "        return images\n",
    "\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, R0_w0_Z_idxs):\n",
    "        # In order to allow multiprocessing data loading, each worker needs to initialize \n",
    "        # the h5f loader, which must be done in the first iteration of getitem and not in the init\n",
    "        # of the parent process\n",
    "        if not hasattr(self, 'h5f_D_matrices'):\n",
    "            self.open_hdf5()\n",
    "            self.phis = torch.from_numpy(self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(self.device) #[1,Nx,Ny]\n",
    "\n",
    "        D_mats = torch.from_numpy(self.h5f_D_matrices[\n",
    "                f\"R0_{self.R0s[R0_w0_Z_idxs[0]]}_w0_{self.w0s[R0_w0_Z_idxs[1]]}_Z_{self.Zs[R0_w0_Z_idxs[2]]}\"][:]\n",
    "                                 ).unsqueeze(1).to(self.device) #[2, 1, Nx, Ny]            \n",
    "         \n",
    "        phiCRs = torch.FloatTensor(self.batch_size, 1, 1).uniform_(-np.pi, np.pi).to(self.device) #[batch_size, 1, 1]\n",
    "        images = D_mats[0]+D_mats[1]*torch.cos(phiCRs-self.phis) #[batch_size, Nx,Ny]\n",
    "        \n",
    "        original_images = images.clone() # Alteration of the original code to allow their output\n",
    "        output = torch.zeros(( images.shape[0], self.K, 2*self.X+1, 2*self.X+1), device=device, dtype=self.im_type)\n",
    "        # [batch_size, K, 2X+1, 2X+1] for each different angle in this configuration, we will have the original and K-1 noisy versions\n",
    "        \n",
    "        for k in range(1,self.K):\n",
    "            if self.apply_noise:\n",
    "                if self.all_stregths_random_per_epoch:\n",
    "                    self.poisson_strength = self.max_poisson_strength*np.random.rand()\n",
    "                    self.angular_modulation_strength = self.max_angular_modulation_strength*np.random.rand()\n",
    "                    self.blob_strength = self.max_blob_strength*np.random.rand()\n",
    "            \n",
    "                # Apply precamera noise to images (while still floats)\n",
    "                images = self.apply_random_pre_camera_noises(images)\n",
    "        \n",
    "            # convert original and precamera noisy images to selected uint format\n",
    "            images = (self.max_intensity*(images/images.amax(dim=(1,2), keepdim=True)[0].unsqueeze(1)))\n",
    "        \n",
    "            if self.apply_noise:\n",
    "                # Apply camera noises (now that normalized and integers)\n",
    "                images = self.apply_random_camera_noises(images)\n",
    "        \n",
    "            images = images.type(self.im_type)\n",
    "            images = self.compute_raw_to_centered_iX(images)\n",
    "            \n",
    "            output[:,k,:,:] = images[:,:,:]\n",
    "            \n",
    "            del images\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            images = original_images.clone()\n",
    "        \n",
    "        original_images = (self.max_intensity*(original_images/original_images.amax(dim=(1,2), keepdim=True)[0].unsqueeze(1)))\n",
    "        original_images = original_images.type(self.im_type)\n",
    "        original_images = self.compute_raw_to_centered_iX(original_images)\n",
    "        \n",
    "        output[:,0,:,:] = original_images[:,:,:]\n",
    "                       \n",
    "        labels = torch.Tensor([[float(self.R0s[R0_w0_Z_idxs[0]]), float(self.w0s[R0_w0_Z_idxs[1]]), \n",
    "                               float(self.Zs[R0_w0_Z_idxs[2]])]]).to(self.device) #[1,4]\n",
    "        labels = torch.hstack( ( labels.expand(self.batch_size, 3), phiCRs.squeeze(2) ) ) #[4, batch_size]\n",
    "        del D_mats, phiCRs, original_images\n",
    "        torch.cuda.empty_cache()\n",
    "        return output, labels #[batch_size, K, 2X+1, 2X+1] and [batch_size, 4]\n",
    "        # The whole batch is already in the GPU, since to process it we wanted it to be there\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import h5py\n",
    "from IPython import display\n",
    "\n",
    "output_directory=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/Noisy_Non_Noisy_same_angle/TEST/\"\n",
    "#output_directory=\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/\"\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Encoder_Alone/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "        \n",
    "\n",
    "total_images_to_generate = 200000 # para el test set unos 100000 bien supongo\n",
    "\n",
    "different_angles_per_batch = 5\n",
    "K = 4      # number of noisy images per angle + 1\n",
    "# then \"per epoch\" we are generating K*different_angles_per_batch images\n",
    "number_of_batches_per_epoch = int(total_images_to_generate/(K*different_angles_per_batch))\n",
    "\n",
    "assert(total_images_to_generate%(different_angles_per_batch*K)==0)\n",
    "\n",
    "X=302\n",
    "generate_images_w_depth=8\n",
    "random_seed=666 # 669 aldatu seede para generar los validation set!!!\n",
    "\n",
    "apply_noise=True # Genera otro dataset pair sin noise tb\n",
    "all_stregths_random_per_epoch=True\n",
    "max_poisson_strength=0.5\n",
    "max_blob_strength=0.5\n",
    "max_angular_modulation_strength=0.5\n",
    "poisson_strength=0.4\n",
    "blob_strength=0.2\n",
    "angular_modulation_strength=0.2\n",
    "min_modulation_frec=2*np.pi/6\n",
    "max_modulation_frec=2*np.pi/2\n",
    "max_blobs=2\n",
    "min_blob_sigma=100\n",
    "max_blob_sigma=130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma, normalized_output=True):\n",
    "    p_s = (1/np.sqrt(2*np.pi)/sigma)*torch.exp(-(x-mu)**2/(2*sigma**2))\n",
    "    return p_s/p_s.sum() if normalized_output else p_s\n",
    "\n",
    "phase_vigilant = pd.DataFrame.from_dict(json.load(open(ID_file_path)))\n",
    "R0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['R0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=158, sigma=8)\n",
    "w0_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['w0s'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=25, sigma=4)\n",
    "Z_weights = gaussian_pdf(torch.from_numpy(np.array( phase_vigilant['Zs'].drop_duplicates(), dtype=np.float64)),\n",
    "                          mu=0, sigma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = R0_w0_Z_Sampler( R0_weights, w0_weights, Z_weights, num_batches_per_epoch=number_of_batches_per_epoch)\n",
    "dataset = CR_Dataset(D_matrix_file_path=D_matrix_file_path,\n",
    "            ID_file_path =ID_file_path, \n",
    "            device = device,\n",
    "            X=X, generate_images_w_depth=generate_images_w_depth, random_seed=random_seed, \n",
    "            batch_size=different_angles_per_batch, num_batches_per_epoch=number_of_batches_per_epoch,\n",
    "            apply_noise=apply_noise, all_stregths_random_per_epoch=all_stregths_random_per_epoch,\n",
    "            max_poisson_strength=max_poisson_strength, max_blob_strength=max_blob_strength,\n",
    "            max_angular_modulation_strength=max_angular_modulation_strength,\n",
    "            poisson_strength=poisson_strength, blob_strength=blob_strength, \n",
    "            angular_modulation_strength=angular_modulation_strength,\n",
    "            min_modulation_frec=min_modulation_frec, max_modulation_frec=max_modulation_frec,\n",
    "            max_blobs=max_blobs, min_blob_sigma=min_blob_sigma, max_blob_sigma=max_blob_sigma, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "h5f = h5py.File(f\"{output_directory}/Dataset_K={K}_Noisy_Non_Noisy_same_angle.h5\", 'a') # append if exists, create if not\n",
    "prev_batches = len(h5f)\n",
    "print(prev_batches)\n",
    "\n",
    "batch=0\n",
    "output_info_every=400\n",
    "\n",
    "try:\n",
    "    ground_truths = json.load( open(f\"{output_directory}/GROUND_TRUTHS_K={K}_Noisy_Non_Noisy_same_angle.json\") )\n",
    "except:\n",
    "    ground_truths={'ID':[], 'R0':[], 'w0':[], 'Z':[], 'phiCR':[]}\n",
    "\n",
    "for i in sampler:\n",
    "    imgs, labs = dataset[i]\n",
    "    imgs = np.asarray(imgs.to('cpu'))\n",
    "    labs = np.asarray(labs.to('cpu'))\n",
    "    for p in range(different_angles_per_batch):\n",
    "        ID=f\"{batch+prev_batches}\"\n",
    "        h5f.create_dataset(ID, data=imgs[p], compression=\"lzf\", shuffle=True)\n",
    "        ground_truths['ID'].append(batch+prev_batches)\n",
    "        ground_truths['R0'].append( f\"{labs[p][0]}\" )\n",
    "        ground_truths['w0'].append( f\"{labs[p][1]}\" )\n",
    "        ground_truths['Z'].append( f\"{labs[p][2]}\" )\n",
    "        ground_truths['phiCR'].append( f\"{labs[p][3]}\" )\n",
    "\n",
    "        batch+=1\n",
    "    if batch%output_info_every==0:\n",
    "        h5f.flush()\n",
    "        display.clear_output(wait=True)\n",
    "        print(f\"Processed {batch}/{number_of_batches_per_epoch} batches {batch/number_of_batches_per_epoch*100} %\")\n",
    "        json.dump(ground_truths, open( f\"{output_directory}/GROUND_TRUTHS_K={K}_Noisy_Non_Noisy_same_angle.json\", \"w\"))\n",
    "h5f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test to open the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "h5f = h5py.File(f\"{output_directory}/Dataset_K={K}_Noisy_Non_Noisy_same_angle.h5\",'r')\n",
    "print(len(h5f))\n",
    "imgs = h5f['10320']\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(221)\n",
    "ax.imshow(imgs[0])\n",
    "ax=fig.add_subplot(222)\n",
    "ax.imshow(imgs[1])\n",
    "ax=fig.add_subplot(223)\n",
    "ax.imshow(imgs[2])\n",
    "ax=fig.add_subplot(224)\n",
    "ax.imshow(imgs[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time()\n",
    "h5f = h5py.File(f\"{image_directory}/Dataset.h5\",'r')\n",
    "D_mat = h5f[ID][:]\n",
    "phis = h5f['phis'][:]\n",
    "#print(list(h5f.keys()))\n",
    "h5f.close()\n",
    "print(f\"hf5:{time()-t}s size {os.path.getsize(image_directory+'/Dataset.h5')}\")   \n",
    "print(D_mat.dtype, D_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize(image_directory+'/Dataset.h5')/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle, gzip, lzma, bz2\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Initialize the vigilant\n",
    "try:\n",
    "    phase_vigilant = json.load(open(f\"{output_directory}/STRUCTURE_Grid.json\"))\n",
    "except:\n",
    "    phase_vigilant = {'R0s':[], 'w0s':[], 'Zs':[], 'IDs':[], 'rel_path':[]}\n",
    "\n",
    "# Set the objects ready ##################\n",
    "# The simulator object\n",
    "simulator=RingSimulator_Optimizer_GPU( n=1.5, a0=1.0, max_k=max_k, num_k=num_k, nx=resolution_side_nx, sim_chunk_x=sim_chunk_ax, sim_chunk_y=sim_chunk_ax)\n",
    "\n",
    "# Execute the stuff #####################\n",
    "i=1\n",
    "total=Z_s.shape[0]*R0_s.shape[0]*w0_s.shape[0]\n",
    "elapsed=0\n",
    "beg=time()\n",
    "output_info_every=100\n",
    "dump_every=10000\n",
    "\n",
    "for Z in Z_s:\n",
    "    for R0 in R0_s:\n",
    "        for w0 in w0_s:\n",
    "            ID=f\"R0_{R0}_w0_{w0}_Z_{Z}\"\n",
    "            if ID not in phase_vigilant['IDs']:\n",
    "                # simulate matrix\n",
    "                #D_matrix = simulator.compute_D_matrix( R0_pixels=R0, Z=Z, w0_pixels=w0)\n",
    "                D_matrix = simulator.compute_pieces_for_I_LP(R0_pixels=R0, Z=Z, w0_pixels=w0)\n",
    "                \n",
    "                # save the matrix\n",
    "                rel_path=f\"{image_directory}/{ID}.pkl.lzma\"\n",
    "                #np.save( rel_path, D_matrix, allow_pickle=False)\n",
    "                print(f\"\\nDUMP {i}\")\n",
    "                t=time()\n",
    "                pickle.dump(D_matrix, lzma.open(rel_path, 'wb'))\n",
    "                print(f\"lzma:{time()-t}s size {os.path.getsize(rel_path)}\")\n",
    "                t=time()\n",
    "                pickle.dump(D_matrix, gzip.open(rel_path+\".gzip\", 'wb'))\n",
    "                print(f\"gzip:{time()-t}s size {os.path.getsize(rel_path+'.gzip')}\")\n",
    "                t=time()\n",
    "                pickle.dump(D_matrix, bz2.open(rel_path+\".bz2\", 'wb'))\n",
    "                print(f\"bz2:{time()-t}s size {os.path.getsize(rel_path+'.bz2')}\")\n",
    "                t=time()\n",
    "                fp = np.memmap(rel_path+\".p\", dtype='complex64', mode='w+', shape=(3,image_shortest_side,image_shortest_side))\n",
    "                fp=D_matrix\n",
    "                print(f\"memmap:{time()-t}s size {os.path.getsize(rel_path+'.p')}\")\n",
    "                t=time()\n",
    "                h5f = h5py.File(rel_path+'.h5', 'w')\n",
    "                h5f.create_dataset('dataset_1', data=D_matrix, compression=\"gzip\", shuffle=True) #, compression_opts=9)\n",
    "                h5f.close()\n",
    "                print(f\"hf5 lzf:{time()-t}s size {os.path.getsize(rel_path+'.h5')}\")     \n",
    "\n",
    "\n",
    "                \n",
    "                print(f\"\\nLOAD {i}\")\n",
    "                t=time()\n",
    "                D_mat=pickle.load(lzma.open(rel_path, 'rb'))\n",
    "                print(f\"lzma:{time()-t}s size {os.path.getsize(rel_path)}\")\n",
    "                t=time()\n",
    "                D_mat=pickle.load(gzip.open(rel_path+\".gzip\", 'rb'))\n",
    "                print(f\"gzip:{time()-t}s size {os.path.getsize(rel_path+'.gzip')}\")\n",
    "                t=time()\n",
    "                D_mat=pickle.load( bz2.open(rel_path+\".bz2\",'rb'))\n",
    "                #print(D_mat.dtype, D_mat.shape)\n",
    "                print(f\"bz2:{time()-t}s size {os.path.getsize(rel_path+'.bz2')}\")     \n",
    "                t=time()\n",
    "                D_mat= np.memmap(rel_path+\".p\", dtype='complex64', mode='r+', shape=(3,image_shortest_side,image_shortest_side))\n",
    "                print(f\"memmap:{time()-t}s size {os.path.getsize(rel_path+'.p')}\")     \n",
    "                t=time()\n",
    "                h5f = h5py.File(rel_path+'.h5','r')\n",
    "                D_mat = h5f['dataset_1'][:]\n",
    "                h5f.close()\n",
    "                print(f\"hf5:{time()-t}s size {os.path.getsize(rel_path+'.h5')}\")     \n",
    "                print(type(D_mat), D_mat.dtype, D_mat.shape)\n",
    "                print(np.allclose(D_mat, D_matrix))\n",
    "\n",
    "                \n",
    "\n",
    "                if D_matrix is None:\n",
    "                    raise ValueError\n",
    "\n",
    "                #append the data\n",
    "                phase_vigilant['IDs'].append(ID)\n",
    "                phase_vigilant['R0s'].append(float(R0))\n",
    "                phase_vigilant['Zs'].append(float(Z))\n",
    "                phase_vigilant['w0s'].append(float(w0))\n",
    "                phase_vigilant['rel_path'].append(rel_path)\n",
    "                \n",
    "                \n",
    "                if i%output_info_every==0:\n",
    "                    display.clear_output(wait=True)\n",
    "                    elapsed=time()-beg\n",
    "                    print(f\"[\"+'#'*(int(100*i/total))+' '*(100-int(100*i/total))+f\"] {100*i/total:3.4}% \\n\\nSimulated: {i}/{total}\\nElapsed time: {elapsed//3600} h {elapsed//60-(elapsed//3600)*60} min {elapsed-(elapsed//60)*60-(elapsed//3600)*60:2.4} s\")\n",
    "                    if i%dump_every==0:\n",
    "                        # we save the progess (in order to be able to quit and resume)\n",
    "                        json.dump(phase_vigilant, open( f\"{output_directory}/STRUCTURE_Grid.json\", \"w\"))\n",
    "            i+=1\n",
    "print(\"\\n\\nFINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=np.abs(D_mat)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=(D_mat*D_mat.conjugate()).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=D_mat.real**2+D_mat.imag**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a=D_mat.real**2\n",
    "    a+=D_mat.imag**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose( (D_mat*D_mat.conjugate()).real, D_mat.real**2+D_mat.imag**2, rtol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
