{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Encoder CNN to get the $\\phi_{CR}$ parameter of a CR image\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from IPython import display as display_IPython\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the functions and routines for the DL\n",
    "### Define the model and its constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_Encoder(nn.Module):\n",
    "    def __init__(self, X=302, feats_1=15, feats_2=20, feats_3=20, feats_4=20,\n",
    "                 prop1=3, prop2=2, prop3=1, av_pool1_div=4, conv4_feat_size=15, av_pool2_div=10, \n",
    "                 out_fc_1=10,\n",
    "                 dropout_p1=0.2, dropout_p2=0.1\n",
    "                ): \n",
    "        # propj is such that the_ image getting out from stage j is propj/prop_{j-1}-ths of the previous (with j=0 being 5)\n",
    "        # clearly, prop_{j-1}>prop_{j}>...\n",
    "        # 2X+1 will be assumed to be divisible by 5\n",
    "        assert((2*X+1)%5==0)\n",
    "        assert(prop1>prop2)\n",
    "        assert(prop2>prop3)\n",
    "        assert((int((prop3*(2*X+1)/5)/av_pool1_div)-conv4_feat_size)>0)\n",
    "        \n",
    "        \n",
    "        super(Simple_Encoder, self).__init__()\n",
    "        # in is [epoch_size, 1, 2X+1, 2X+1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=feats_1, \n",
    "                               kernel_size = int((2*X+1)/5*(5-prop1)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        self.conv2 = nn.Conv2d(in_channels=feats_1, out_channels=feats_2, \n",
    "                               kernel_size = int((2*X+1)/5*(prop1-prop2)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_2, prop2*(prop1*(2X+1)/5)/prop1, prop2*(prop1*(2X+1)/5)/prop1]\n",
    "        # that is [epoch_size, feats_2, prop2*(2X+1)/5), prop2*(2X+1)/5)]\n",
    "        self.conv3 = nn.Conv2d(in_channels=feats_2, out_channels=feats_3, \n",
    "                               kernel_size = int((2*X+1)/5*(prop2-prop3)+1), bias=True)\n",
    "        # out conv3 is [epoch_size, feats_3, prop3*(2X+1)/5), prop3*(2X+1)/5)]\n",
    "\n",
    "        self.avPool1 = nn.AvgPool2d(kernel_size= int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=feats_3, out_channels=feats_4, \n",
    "                              kernel_size= int((prop3*(2*X+1)/5)/av_pool1_div+1)-conv4_feat_size+1, bias=True)\n",
    "        # [epoch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        \n",
    "        self.avPool2 = nn.AvgPool2d(kernel_size= int(conv4_feat_size*(1-1/av_pool2_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_4, conv4_feat_size/av_pool2_div+1, conv4_feat_size/av_pool2_div+1]\n",
    "        \n",
    "        #self.in_fc = int(feats_4*(conv4_feat_size/av_pool2_div+1)**2)\n",
    "        self.in_fc = feats_4*((((((2*X+1-int((2*X+1)/5*(5-prop1)+1)+1)\n",
    "                                  -int((2*X+1)/5*(prop1-prop2)+1)+1)\n",
    "                                 -int((2*X+1)/5*(prop2-prop3)+1)+1)\n",
    "                                -int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) -1+1)\n",
    "                               -int((prop3*(2*X+1)/5)/av_pool1_div+1)+conv4_feat_size-1+1)\n",
    "                              -int(conv4_feat_size*(1-1/av_pool2_div)) -1+1)**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc, out_features=out_fc_1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc_1, out_features=1, bias=True)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1, inplace=False)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2, inplace=False)\n",
    "        self.relu = torch.nn.functional.relu\n",
    "\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=feats_2)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=feats_4)\n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        \n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, 1]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def print_shapes(self, batch_size=10, X=302):\n",
    "        x = torch.ones((batch_size, 1, 2*X+1, 2*X+1)).to(device)\n",
    "        print(f\"Initial shape {x.shape}\")\n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        print(f\"Post Conv1+relu shape {x.shape}\")\n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "        print(f\"Post drop1+Conv2+relu+batchnorm shape {x.shape}\")\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "        print(f\"Post drop2+Conv3+relu shape {x.shape}\")\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        print(f\"Post Av Pool1 shape {x.shape}\")\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        print(f\"Post drop2+Conv4+batchnorm shape {x.shape}\")\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "        print(f\"Post Av. Pool2 shape {x.shape}\")\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "        print(f\"Post Pre-fc shape {x.shape}\")\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, 1]\n",
    "        print(f\"Post fc1+relu+fc2 shape {x.shape}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subroutine to count number of parameters in the model\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.numel()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The routines to validate and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # prevent this function from computing gradients \n",
    "def validate_epoch(criterion, model, dataloader, per_epoch_use_max_batches=None): #show_confusion_matrix = False):\n",
    "    if per_epoch_use_max_batches is None:\n",
    "        per_epoch_use_max_batches = len(dataloader)\n",
    "    val_loss = 0\n",
    "    max_abs_error = torch.Tensor([0]).to(device)\n",
    "    mean_abs_error = 0\n",
    "    preds = torch.Tensor().to(device)\n",
    "    targets = torch.Tensor().to(device)\n",
    "\n",
    "    model.eval() # disable the dropout, among others\n",
    "\n",
    "    for batch_id, (data, target) in enumerate(dataloader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)       \n",
    "        prediction = model(data)\n",
    "        target = target.view(prediction.shape)\n",
    "        loss = criterion(prediction, target)\n",
    "        val_loss += loss.item()                                                              \n",
    "        max_abs_error = torch.maximum(torch.max(torch.abs(prediction-target), 0).values, max_abs_error)\n",
    "        mean_abs_error += torch.sum(torch.abs(prediction-target), 0)\n",
    "        if batch_id % per_epoch_use_max_batches == per_epoch_use_max_batches-1:\n",
    "            break\n",
    "    val_loss /= min(len(dataloader), per_epoch_use_max_batches)\n",
    "    mean_abs_error /= min(len(dataloader), per_epoch_use_max_batches)\n",
    "    #accuracy = 100. * correct / len(loader.dataset)\n",
    "    print(f'\\nValidation set: Average loss: {val_loss:.4f}, Average Abs Error: {np.array(mean_abs_error.cpu())}, Maximum Abs Error: {np.array(max_abs_error.cpu())} \\n')\n",
    "\n",
    "    #if show_confusion_matrix:\n",
    "    #    visualize_confusion_matrix(preds.to(torch.device('cpu')), targets.to(torch.device('cpu')))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def train_epoch(epoch, criterion, model, optimizer, dataloader, print_loss_every_batches=20,\n",
    "                optimizer_step_every_batches=1, per_epoch_use_max_batches=None):\n",
    "    if per_epoch_use_max_batches is None:\n",
    "        per_epoch_use_max_batches = len(dataloader)\n",
    "        \n",
    "    total_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #t = time()\n",
    "    for batch_id, (data, target) in enumerate(dataloader):        \n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        prediction = model(data) # data is [batch_size, 1, 2X+1, 2X+1]\n",
    "        loss = criterion(prediction, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        if batch_id % optimizer_step_every_batches==optimizer_step_every_batches-1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # print loss every N batches\n",
    "        if batch_id % print_loss_every_batches == print_loss_every_batches-1:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_id+1) * len(data), len(dataloader)*batch_size,\n",
    "                100*(batch_id+1)*len(data) / (len(dataloader)*batch_size), loss.item()))\n",
    "\n",
    "        if batch_id % per_epoch_use_max_batches == per_epoch_use_max_batches-1:\n",
    "            break\n",
    "        #t9=time()\n",
    "        #print(f\"it time {t9-t}\")\n",
    "\n",
    "        total_loss += loss.item()  #.item() is very important here\n",
    "        # In order to avoid having total_loss as a tensor in the gpu\n",
    "        #t = time()\n",
    "\n",
    "    return total_loss / min(len(dataloader), per_epoch_use_max_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_training_loop(model, criterion, optimizer, train_loader, test_loader, epochs=10,\n",
    "                       print_loss_every_batches=20, validate_every_epochs=2, optimizer_step_every_batches=1,\n",
    "                      per_epoch_use_max_train_batches=None, per_epoch_use_max_test_batches=None,\n",
    "                      image_path=None, save_model_every_epochs=1, model_path=None, best_model_path=None, scheduler=None):\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "    %matplotlib inline\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss = train_epoch(epoch, criterion, model, optimizer, train_loader,\n",
    "                                 print_loss_every_batches=print_loss_every_batches,\n",
    "                                optimizer_step_every_batches=optimizer_step_every_batches,\n",
    "                                per_epoch_use_max_batches=per_epoch_use_max_train_batches)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch%validate_every_epochs==0 and epoch!=0:\n",
    "            val_loss = validate_epoch(criterion, model, test_loader, per_epoch_use_max_test_batches)\n",
    "        else:\n",
    "            try:\n",
    "                val_loss = losses[\"val\"][-1]\n",
    "            except:\n",
    "                val_loss = train_loss\n",
    "        if epoch and train_loss<=min(losses[\"train\"]) and best_model_path:\n",
    "            torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "            }, best_model_path)\n",
    "        \n",
    "        losses[\"train\"].append(train_loss)\n",
    "        losses[\"val\"].append(val_loss)        \n",
    "        plt.plot(losses[\"train\"], label=\"training loss\")\n",
    "        plt.plot(losses[\"val\"], label=\"validation loss\")\n",
    "        #plt.yscale('log')\n",
    "        plt.legend()\n",
    "        if image_path is not None:\n",
    "            plt.savefig(image_path)\n",
    "            plt.clf()\n",
    "        else:\n",
    "            display_IPython.clear_output(wait=True)\n",
    "            plt.pause(0.001)\n",
    "            plt.show()\n",
    "        if epoch % save_model_every_epochs==save_model_every_epochs-1 and model_path:\n",
    "            torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "            }, model_path)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset class and Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Initialize the dataset and sampler (choose the number of batches per epoch, and their length) and fix the artificial noise hyperparameters\n",
    "\n",
    "Note that since in each epoch the dataset shown to the model will be random, we can use the same dataset as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GT_file_path_train = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TRAIN/GROUND_TRUTHS.json\"\n",
    "#images_dir_path_train =f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TRAIN/\" \n",
    "#GT_file_path_test = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "#images_dir_path_test = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/\"\n",
    "\n",
    "GT_file_path_train = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/GROUND_TRUTHS.json\"\n",
    "images_dir_path_train =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TRAIN/\" \n",
    "GT_file_path_test = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/\" \n",
    "\n",
    "total_epochs = 100000\n",
    "batch_size = 10\n",
    "validate_every_epochs = 11000000\n",
    "optimizer_step_every_batches = 10\n",
    "per_epoch_use_max_train_batches= 30\n",
    "per_epoch_use_max_test_batches=20\n",
    "save_model_every_epochs = 1\n",
    "\n",
    "worker_num=5\n",
    "\n",
    "save_stuff_path = '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "exp_name = 'Simple_Encoder'\n",
    "# 6 segundos por batch de 10 unidades, hacemos que pasen 40.000 batches (400.000 imagenes)\n",
    "# lo haremos de forma que se de una optimizer step cada 4 batches, en 10 epochs de \n",
    "# cada una 4000 batches (para plotear la curva) \n",
    "# y tras cada epoch haremos un save del modelo\n",
    "# deberian ser 2.8 dias de training\n",
    "\n",
    "# todo esto dividido por dos de forma que podemos entrenar simulatnaeamente ambos modelos? (con noisy y non-noisy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageDataset(GT_file_path_train, images_dir_path_train)\n",
    "test_data = ImageDataset(GT_file_path_test, images_dir_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(511)\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=worker_num,\n",
    "                              pin_memory=True, drop_last=False, persistent_workers=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=worker_num, \n",
    "                             pin_memory=True, drop_last=False, persistent_workers=False)\n",
    "\n",
    "\n",
    "assert(len(train_dataloader)%batch_size==0 or per_epoch_use_max_train_batches%batch_size==0 ) # make batch_size an integer proportion of data files\n",
    "batch_number_per_epoch = min(len(train_dataloader)/batch_size, per_epoch_use_max_train_batches)\n",
    "assert(batch_number_per_epoch%optimizer_step_every_batches==0) # make optimizer steps every divisble number of its"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix the Hyperparameters and Initialize the Model and the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=302\n",
    "feats_1=20\n",
    "feats_2=20\n",
    "feats_3=20\n",
    "feats_4=5\n",
    "prop1=2.5\n",
    "prop2=1.5\n",
    "prop3=0.6\n",
    "av_pool1_div=2\n",
    "conv4_feat_size=8\n",
    "av_pool2_div=10\n",
    "out_fc_1=5\n",
    "dropout_p1=0.2\n",
    "dropout_p2=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters 12632406\n",
      "Initial shape torch.Size([10, 1, 605, 605])\n",
      "Post Conv1+relu shape torch.Size([10, 20, 303, 303])\n",
      "Post drop1+Conv2+relu+batchnorm shape torch.Size([10, 20, 182, 182])\n",
      "Post drop2+Conv3+relu shape torch.Size([10, 20, 74, 74])\n",
      "Post Av Pool1 shape torch.Size([10, 20, 38, 38])\n",
      "Post drop2+Conv4+batchnorm shape torch.Size([10, 5, 9, 9])\n",
      "Post Av. Pool2 shape torch.Size([10, 5, 2, 2])\n",
      "Post Pre-fc shape torch.Size([10, 20])\n",
      "Post fc1+relu+fc2 shape torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "model = Simple_Encoder( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                 prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                av_pool2_div=av_pool2_div, \n",
    "                 out_fc_1=out_fc_1,\n",
    "                 dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "print(f\"Number of parameters {get_n_params(model)}\")\n",
    "\n",
    "# In case we wish to transfer the learned parameters of another run\n",
    "check_file=\"NNs/BEST_Noisy_Model_and_Optimizer_2022-02-28 19:46:32.542886_Simple_Encoder.pt\"\n",
    "checkpoint = torch.load(save_stuff_path+f\"/{check_file}\")\n",
    "\n",
    "# move model to gpu if available\n",
    "model.to(device)\n",
    "model.print_shapes()\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "\n",
    "# Initialize the weights of the model! Default initialization might already be fine!\n",
    "\n",
    "# we can use a MSE loss for the regression task we have in hands\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we will choose as optimizer the \n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=0.1, lr_decay=0.01, weight_decay=0.3,\n",
    "#                                initial_accumulator_value=0, eps=1e-10)\n",
    "#check_file=\"NNs/Noisy_Model_and_Optimizer_2022-02-22 20:58:41.632916_Simple_Encoder.pt\"\n",
    "#checkpoint = torch.load(save_stuff_path+f\"/{check_file}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001, betas=(0.5, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# we will perform learning rate scheduling at this phase\n",
    "lmbda = lambda epoch: 0.40\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "#scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [100/500000 (0%)]\tLoss: 0.032107\n",
      "Train Epoch: 0 [200/500000 (0%)]\tLoss: 0.007645\n",
      "Train Epoch: 0 [300/500000 (0%)]\tLoss: 0.022283\n",
      "Train Epoch: 1 [100/500000 (0%)]\tLoss: 0.016656\n",
      "Train Epoch: 1 [200/500000 (0%)]\tLoss: 0.054952\n",
      "Train Epoch: 1 [300/500000 (0%)]\tLoss: 0.003444\n",
      "Train Epoch: 2 [100/500000 (0%)]\tLoss: 0.009010\n",
      "Train Epoch: 2 [200/500000 (0%)]\tLoss: 0.012104\n",
      "Train Epoch: 2 [300/500000 (0%)]\tLoss: 0.019212\n",
      "Train Epoch: 3 [100/500000 (0%)]\tLoss: 0.010004\n",
      "Train Epoch: 3 [200/500000 (0%)]\tLoss: 0.076137\n",
      "Train Epoch: 3 [300/500000 (0%)]\tLoss: 0.023584\n",
      "Train Epoch: 4 [100/500000 (0%)]\tLoss: 0.056404\n",
      "Train Epoch: 4 [200/500000 (0%)]\tLoss: 0.031674\n",
      "Train Epoch: 4 [300/500000 (0%)]\tLoss: 0.045822\n",
      "Train Epoch: 5 [100/500000 (0%)]\tLoss: 0.031644\n",
      "Train Epoch: 5 [200/500000 (0%)]\tLoss: 0.222913\n",
      "Train Epoch: 5 [300/500000 (0%)]\tLoss: 0.018920\n",
      "Train Epoch: 6 [100/500000 (0%)]\tLoss: 0.039771\n",
      "Train Epoch: 6 [200/500000 (0%)]\tLoss: 0.022216\n",
      "Train Epoch: 6 [300/500000 (0%)]\tLoss: 0.010937\n",
      "Train Epoch: 7 [100/500000 (0%)]\tLoss: 0.080444\n",
      "Train Epoch: 7 [200/500000 (0%)]\tLoss: 0.009276\n",
      "Train Epoch: 7 [300/500000 (0%)]\tLoss: 0.034514\n",
      "Train Epoch: 8 [100/500000 (0%)]\tLoss: 0.029054\n",
      "Train Epoch: 8 [200/500000 (0%)]\tLoss: 0.059556\n",
      "Train Epoch: 8 [300/500000 (0%)]\tLoss: 1.330550\n",
      "Train Epoch: 9 [100/500000 (0%)]\tLoss: 0.035250\n",
      "Train Epoch: 9 [200/500000 (0%)]\tLoss: 0.043036\n",
      "Train Epoch: 9 [300/500000 (0%)]\tLoss: 0.006828\n",
      "Train Epoch: 10 [100/500000 (0%)]\tLoss: 0.006182\n",
      "Train Epoch: 10 [200/500000 (0%)]\tLoss: 0.065233\n",
      "Train Epoch: 10 [300/500000 (0%)]\tLoss: 0.277594\n",
      "Train Epoch: 11 [100/500000 (0%)]\tLoss: 0.057043\n",
      "Train Epoch: 11 [200/500000 (0%)]\tLoss: 0.018820\n",
      "Train Epoch: 11 [300/500000 (0%)]\tLoss: 0.007101\n",
      "Train Epoch: 12 [100/500000 (0%)]\tLoss: 0.045984\n",
      "Train Epoch: 12 [200/500000 (0%)]\tLoss: 0.023032\n",
      "Train Epoch: 12 [300/500000 (0%)]\tLoss: 0.205626\n",
      "Train Epoch: 13 [100/500000 (0%)]\tLoss: 0.019698\n",
      "Train Epoch: 13 [200/500000 (0%)]\tLoss: 0.052244\n",
      "Train Epoch: 13 [300/500000 (0%)]\tLoss: 0.015881\n",
      "Train Epoch: 14 [100/500000 (0%)]\tLoss: 0.029863\n",
      "Train Epoch: 14 [200/500000 (0%)]\tLoss: 0.140888\n",
      "Train Epoch: 14 [300/500000 (0%)]\tLoss: 0.005186\n",
      "Train Epoch: 15 [100/500000 (0%)]\tLoss: 0.008109\n",
      "Train Epoch: 15 [200/500000 (0%)]\tLoss: 0.530589\n",
      "Train Epoch: 15 [300/500000 (0%)]\tLoss: 0.060573\n",
      "Train Epoch: 16 [100/500000 (0%)]\tLoss: 0.013187\n",
      "Train Epoch: 16 [200/500000 (0%)]\tLoss: 0.018706\n",
      "Train Epoch: 16 [300/500000 (0%)]\tLoss: 0.013690\n",
      "Train Epoch: 17 [100/500000 (0%)]\tLoss: 0.019764\n",
      "Train Epoch: 17 [200/500000 (0%)]\tLoss: 0.070506\n",
      "Train Epoch: 17 [300/500000 (0%)]\tLoss: 0.060282\n",
      "Train Epoch: 18 [100/500000 (0%)]\tLoss: 0.008242\n",
      "Train Epoch: 18 [200/500000 (0%)]\tLoss: 0.024018\n",
      "Train Epoch: 18 [300/500000 (0%)]\tLoss: 0.029584\n",
      "Train Epoch: 19 [100/500000 (0%)]\tLoss: 0.026901\n",
      "Train Epoch: 19 [200/500000 (0%)]\tLoss: 0.037634\n",
      "Train Epoch: 19 [300/500000 (0%)]\tLoss: 0.059683\n",
      "Train Epoch: 20 [100/500000 (0%)]\tLoss: 0.004424\n",
      "Train Epoch: 20 [200/500000 (0%)]\tLoss: 0.017288\n",
      "Train Epoch: 20 [300/500000 (0%)]\tLoss: 0.028535\n",
      "Train Epoch: 21 [100/500000 (0%)]\tLoss: 0.085662\n",
      "Train Epoch: 21 [200/500000 (0%)]\tLoss: 0.160853\n",
      "Train Epoch: 21 [300/500000 (0%)]\tLoss: 0.643245\n",
      "Train Epoch: 22 [100/500000 (0%)]\tLoss: 0.033829\n",
      "Train Epoch: 22 [200/500000 (0%)]\tLoss: 0.012111\n",
      "Train Epoch: 22 [300/500000 (0%)]\tLoss: 0.051225\n",
      "Train Epoch: 23 [100/500000 (0%)]\tLoss: 0.022486\n",
      "Train Epoch: 23 [200/500000 (0%)]\tLoss: 0.011156\n",
      "Train Epoch: 23 [300/500000 (0%)]\tLoss: 0.421661\n",
      "Train Epoch: 24 [100/500000 (0%)]\tLoss: 0.023968\n",
      "Train Epoch: 24 [200/500000 (0%)]\tLoss: 0.103525\n",
      "Train Epoch: 24 [300/500000 (0%)]\tLoss: 0.013891\n",
      "Train Epoch: 25 [100/500000 (0%)]\tLoss: 0.034874\n",
      "Train Epoch: 25 [200/500000 (0%)]\tLoss: 0.010203\n",
      "Train Epoch: 25 [300/500000 (0%)]\tLoss: 0.011516\n",
      "Train Epoch: 26 [100/500000 (0%)]\tLoss: 0.034393\n",
      "Train Epoch: 26 [200/500000 (0%)]\tLoss: 0.032138\n",
      "Train Epoch: 26 [300/500000 (0%)]\tLoss: 0.007882\n",
      "Train Epoch: 27 [100/500000 (0%)]\tLoss: 0.010090\n",
      "Train Epoch: 27 [200/500000 (0%)]\tLoss: 0.054210\n",
      "Train Epoch: 27 [300/500000 (0%)]\tLoss: 0.037028\n",
      "Train Epoch: 28 [100/500000 (0%)]\tLoss: 0.089345\n",
      "Train Epoch: 28 [200/500000 (0%)]\tLoss: 0.094202\n",
      "Train Epoch: 28 [300/500000 (0%)]\tLoss: 0.016541\n",
      "Train Epoch: 29 [100/500000 (0%)]\tLoss: 0.047658\n",
      "Train Epoch: 29 [200/500000 (0%)]\tLoss: 0.115093\n",
      "Train Epoch: 29 [300/500000 (0%)]\tLoss: 0.029763\n",
      "Train Epoch: 30 [100/500000 (0%)]\tLoss: 0.026098\n",
      "Train Epoch: 30 [200/500000 (0%)]\tLoss: 0.019992\n",
      "Train Epoch: 30 [300/500000 (0%)]\tLoss: 0.009114\n",
      "Train Epoch: 31 [100/500000 (0%)]\tLoss: 0.033967\n",
      "Train Epoch: 31 [200/500000 (0%)]\tLoss: 0.037036\n",
      "Train Epoch: 31 [300/500000 (0%)]\tLoss: 0.009871\n",
      "Train Epoch: 32 [100/500000 (0%)]\tLoss: 0.030482\n",
      "Train Epoch: 32 [200/500000 (0%)]\tLoss: 0.028568\n",
      "Train Epoch: 32 [300/500000 (0%)]\tLoss: 0.016072\n",
      "Train Epoch: 33 [100/500000 (0%)]\tLoss: 0.042041\n",
      "Train Epoch: 33 [200/500000 (0%)]\tLoss: 0.030515\n",
      "Train Epoch: 33 [300/500000 (0%)]\tLoss: 0.038157\n",
      "Train Epoch: 34 [100/500000 (0%)]\tLoss: 0.018059\n",
      "Train Epoch: 34 [200/500000 (0%)]\tLoss: 0.042026\n",
      "Train Epoch: 34 [300/500000 (0%)]\tLoss: 0.114316\n",
      "Train Epoch: 35 [100/500000 (0%)]\tLoss: 0.024599\n",
      "Train Epoch: 35 [200/500000 (0%)]\tLoss: 0.026006\n",
      "Train Epoch: 35 [300/500000 (0%)]\tLoss: 0.031015\n",
      "Train Epoch: 36 [100/500000 (0%)]\tLoss: 0.010228\n",
      "Train Epoch: 36 [200/500000 (0%)]\tLoss: 0.019192\n",
      "Train Epoch: 36 [300/500000 (0%)]\tLoss: 0.053195\n",
      "Train Epoch: 37 [100/500000 (0%)]\tLoss: 0.090219\n",
      "Train Epoch: 37 [200/500000 (0%)]\tLoss: 0.048056\n",
      "Train Epoch: 37 [300/500000 (0%)]\tLoss: 0.012389\n",
      "Train Epoch: 38 [100/500000 (0%)]\tLoss: 0.020293\n",
      "Train Epoch: 38 [200/500000 (0%)]\tLoss: 0.026361\n",
      "Train Epoch: 38 [300/500000 (0%)]\tLoss: 0.014112\n",
      "Train Epoch: 39 [100/500000 (0%)]\tLoss: 0.051356\n",
      "Train Epoch: 39 [200/500000 (0%)]\tLoss: 0.189602\n",
      "Train Epoch: 39 [300/500000 (0%)]\tLoss: 0.008384\n",
      "Train Epoch: 40 [100/500000 (0%)]\tLoss: 0.018023\n",
      "Train Epoch: 40 [200/500000 (0%)]\tLoss: 0.047807\n",
      "Train Epoch: 40 [300/500000 (0%)]\tLoss: 0.015215\n",
      "Train Epoch: 41 [100/500000 (0%)]\tLoss: 0.022860\n",
      "Train Epoch: 41 [200/500000 (0%)]\tLoss: 0.050709\n",
      "Train Epoch: 41 [300/500000 (0%)]\tLoss: 0.022102\n",
      "Train Epoch: 42 [100/500000 (0%)]\tLoss: 0.017455\n",
      "Train Epoch: 42 [200/500000 (0%)]\tLoss: 0.024579\n",
      "Train Epoch: 42 [300/500000 (0%)]\tLoss: 0.011254\n",
      "Train Epoch: 43 [100/500000 (0%)]\tLoss: 0.023830\n",
      "Train Epoch: 43 [200/500000 (0%)]\tLoss: 0.812295\n",
      "Train Epoch: 43 [300/500000 (0%)]\tLoss: 0.010770\n",
      "Train Epoch: 44 [100/500000 (0%)]\tLoss: 0.006587\n",
      "Train Epoch: 44 [200/500000 (0%)]\tLoss: 0.012865\n",
      "Train Epoch: 44 [300/500000 (0%)]\tLoss: 0.005979\n",
      "Train Epoch: 45 [100/500000 (0%)]\tLoss: 0.020599\n",
      "Train Epoch: 45 [200/500000 (0%)]\tLoss: 0.096712\n",
      "Train Epoch: 45 [300/500000 (0%)]\tLoss: 0.017686\n",
      "Train Epoch: 46 [100/500000 (0%)]\tLoss: 0.174898\n",
      "Train Epoch: 46 [200/500000 (0%)]\tLoss: 0.044102\n",
      "Train Epoch: 46 [300/500000 (0%)]\tLoss: 0.006951\n",
      "Train Epoch: 47 [100/500000 (0%)]\tLoss: 0.036641\n",
      "Train Epoch: 47 [200/500000 (0%)]\tLoss: 0.062396\n",
      "Train Epoch: 47 [300/500000 (0%)]\tLoss: 0.018029\n",
      "Train Epoch: 48 [100/500000 (0%)]\tLoss: 0.013761\n",
      "Train Epoch: 48 [200/500000 (0%)]\tLoss: 0.016798\n",
      "Train Epoch: 48 [300/500000 (0%)]\tLoss: 0.011058\n",
      "Train Epoch: 49 [100/500000 (0%)]\tLoss: 0.020892\n",
      "Train Epoch: 49 [200/500000 (0%)]\tLoss: 0.017975\n",
      "Train Epoch: 49 [300/500000 (0%)]\tLoss: 0.016499\n",
      "Train Epoch: 50 [100/500000 (0%)]\tLoss: 0.022180\n",
      "Train Epoch: 50 [200/500000 (0%)]\tLoss: 0.080643\n",
      "Train Epoch: 50 [300/500000 (0%)]\tLoss: 0.022446\n",
      "Train Epoch: 51 [100/500000 (0%)]\tLoss: 0.034123\n",
      "Train Epoch: 51 [200/500000 (0%)]\tLoss: 0.022189\n",
      "Train Epoch: 51 [300/500000 (0%)]\tLoss: 0.069187\n",
      "Train Epoch: 52 [100/500000 (0%)]\tLoss: 0.024098\n",
      "Train Epoch: 52 [200/500000 (0%)]\tLoss: 0.010705\n",
      "Train Epoch: 52 [300/500000 (0%)]\tLoss: 0.054022\n",
      "Train Epoch: 53 [100/500000 (0%)]\tLoss: 0.026654\n",
      "Train Epoch: 53 [200/500000 (0%)]\tLoss: 0.071167\n",
      "Train Epoch: 53 [300/500000 (0%)]\tLoss: 1.359697\n",
      "Train Epoch: 54 [100/500000 (0%)]\tLoss: 0.091433\n",
      "Train Epoch: 54 [200/500000 (0%)]\tLoss: 0.013492\n",
      "Train Epoch: 54 [300/500000 (0%)]\tLoss: 0.035643\n",
      "Train Epoch: 55 [100/500000 (0%)]\tLoss: 0.018569\n",
      "Train Epoch: 55 [200/500000 (0%)]\tLoss: 0.025031\n",
      "Train Epoch: 55 [300/500000 (0%)]\tLoss: 0.052298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [100/500000 (0%)]\tLoss: 0.012086\n",
      "Train Epoch: 56 [200/500000 (0%)]\tLoss: 0.008649\n",
      "Train Epoch: 56 [300/500000 (0%)]\tLoss: 0.012376\n",
      "Train Epoch: 57 [100/500000 (0%)]\tLoss: 0.039378\n",
      "Train Epoch: 57 [200/500000 (0%)]\tLoss: 0.023279\n",
      "Train Epoch: 57 [300/500000 (0%)]\tLoss: 0.015729\n",
      "Train Epoch: 58 [100/500000 (0%)]\tLoss: 0.027639\n",
      "Train Epoch: 58 [200/500000 (0%)]\tLoss: 0.022186\n",
      "Train Epoch: 58 [300/500000 (0%)]\tLoss: 0.025652\n",
      "Train Epoch: 59 [100/500000 (0%)]\tLoss: 0.022658\n",
      "Train Epoch: 59 [200/500000 (0%)]\tLoss: 0.012627\n",
      "Train Epoch: 59 [300/500000 (0%)]\tLoss: 0.003524\n",
      "Train Epoch: 60 [100/500000 (0%)]\tLoss: 0.004039\n",
      "Train Epoch: 60 [200/500000 (0%)]\tLoss: 0.035669\n",
      "Train Epoch: 60 [300/500000 (0%)]\tLoss: 0.027085\n",
      "Train Epoch: 61 [100/500000 (0%)]\tLoss: 0.109643\n",
      "Train Epoch: 61 [200/500000 (0%)]\tLoss: 0.036045\n",
      "Train Epoch: 61 [300/500000 (0%)]\tLoss: 0.012235\n",
      "Train Epoch: 62 [100/500000 (0%)]\tLoss: 0.009894\n",
      "Train Epoch: 62 [200/500000 (0%)]\tLoss: 0.022963\n",
      "Train Epoch: 62 [300/500000 (0%)]\tLoss: 0.010163\n",
      "Train Epoch: 63 [100/500000 (0%)]\tLoss: 0.046018\n",
      "Train Epoch: 63 [200/500000 (0%)]\tLoss: 0.004957\n",
      "Train Epoch: 63 [300/500000 (0%)]\tLoss: 0.805921\n",
      "Train Epoch: 64 [100/500000 (0%)]\tLoss: 0.021027\n",
      "Train Epoch: 64 [200/500000 (0%)]\tLoss: 0.020977\n",
      "Train Epoch: 64 [300/500000 (0%)]\tLoss: 0.037864\n",
      "Train Epoch: 65 [100/500000 (0%)]\tLoss: 0.015406\n",
      "Train Epoch: 65 [200/500000 (0%)]\tLoss: 0.016211\n",
      "Train Epoch: 65 [300/500000 (0%)]\tLoss: 0.053836\n",
      "Train Epoch: 66 [100/500000 (0%)]\tLoss: 0.009963\n",
      "Train Epoch: 66 [200/500000 (0%)]\tLoss: 0.033365\n",
      "Train Epoch: 66 [300/500000 (0%)]\tLoss: 0.021937\n",
      "Train Epoch: 67 [100/500000 (0%)]\tLoss: 0.007747\n",
      "Train Epoch: 67 [200/500000 (0%)]\tLoss: 0.413936\n",
      "Train Epoch: 67 [300/500000 (0%)]\tLoss: 0.020746\n",
      "Train Epoch: 68 [100/500000 (0%)]\tLoss: 0.017626\n",
      "Train Epoch: 68 [200/500000 (0%)]\tLoss: 0.049174\n",
      "Train Epoch: 68 [300/500000 (0%)]\tLoss: 0.009635\n",
      "Train Epoch: 69 [100/500000 (0%)]\tLoss: 0.091823\n",
      "Train Epoch: 69 [200/500000 (0%)]\tLoss: 2.099707\n",
      "Train Epoch: 69 [300/500000 (0%)]\tLoss: 0.043852\n",
      "Train Epoch: 70 [100/500000 (0%)]\tLoss: 0.023293\n",
      "Train Epoch: 70 [200/500000 (0%)]\tLoss: 0.058651\n",
      "Train Epoch: 70 [300/500000 (0%)]\tLoss: 0.003728\n",
      "Train Epoch: 71 [100/500000 (0%)]\tLoss: 0.023492\n",
      "Train Epoch: 71 [200/500000 (0%)]\tLoss: 0.028155\n",
      "Train Epoch: 71 [300/500000 (0%)]\tLoss: 0.022515\n",
      "Train Epoch: 72 [100/500000 (0%)]\tLoss: 0.035879\n",
      "Train Epoch: 72 [200/500000 (0%)]\tLoss: 0.053933\n",
      "Train Epoch: 72 [300/500000 (0%)]\tLoss: 0.015841\n",
      "Train Epoch: 73 [100/500000 (0%)]\tLoss: 0.031847\n",
      "Train Epoch: 73 [200/500000 (0%)]\tLoss: 0.006923\n",
      "Train Epoch: 73 [300/500000 (0%)]\tLoss: 0.082188\n",
      "Train Epoch: 74 [100/500000 (0%)]\tLoss: 0.090929\n",
      "Train Epoch: 74 [200/500000 (0%)]\tLoss: 0.085431\n",
      "Train Epoch: 74 [300/500000 (0%)]\tLoss: 1.141878\n",
      "Train Epoch: 75 [100/500000 (0%)]\tLoss: 0.010102\n",
      "Train Epoch: 75 [200/500000 (0%)]\tLoss: 0.921785\n",
      "Train Epoch: 75 [300/500000 (0%)]\tLoss: 0.032303\n",
      "Train Epoch: 76 [100/500000 (0%)]\tLoss: 0.028452\n",
      "Train Epoch: 76 [200/500000 (0%)]\tLoss: 0.025758\n",
      "Train Epoch: 76 [300/500000 (0%)]\tLoss: 0.051554\n",
      "Train Epoch: 77 [100/500000 (0%)]\tLoss: 0.013422\n",
      "Train Epoch: 77 [200/500000 (0%)]\tLoss: 0.027268\n",
      "Train Epoch: 77 [300/500000 (0%)]\tLoss: 2.942646\n",
      "Train Epoch: 78 [100/500000 (0%)]\tLoss: 0.026979\n",
      "Train Epoch: 78 [200/500000 (0%)]\tLoss: 0.005716\n",
      "Train Epoch: 78 [300/500000 (0%)]\tLoss: 0.048383\n",
      "Train Epoch: 79 [100/500000 (0%)]\tLoss: 0.025808\n",
      "Train Epoch: 79 [200/500000 (0%)]\tLoss: 0.016001\n",
      "Train Epoch: 79 [300/500000 (0%)]\tLoss: 1.415516\n",
      "Train Epoch: 80 [100/500000 (0%)]\tLoss: 0.043512\n",
      "Train Epoch: 80 [200/500000 (0%)]\tLoss: 2.260154\n",
      "Train Epoch: 80 [300/500000 (0%)]\tLoss: 0.028630\n",
      "Train Epoch: 81 [100/500000 (0%)]\tLoss: 0.044466\n",
      "Train Epoch: 81 [200/500000 (0%)]\tLoss: 0.028000\n",
      "Train Epoch: 81 [300/500000 (0%)]\tLoss: 0.019463\n",
      "Train Epoch: 82 [100/500000 (0%)]\tLoss: 0.035544\n",
      "Train Epoch: 82 [200/500000 (0%)]\tLoss: 0.060968\n",
      "Train Epoch: 82 [300/500000 (0%)]\tLoss: 0.042283\n",
      "Train Epoch: 83 [100/500000 (0%)]\tLoss: 0.016430\n",
      "Train Epoch: 83 [200/500000 (0%)]\tLoss: 0.017505\n",
      "Train Epoch: 83 [300/500000 (0%)]\tLoss: 0.024493\n",
      "Train Epoch: 84 [100/500000 (0%)]\tLoss: 0.027777\n",
      "Train Epoch: 84 [200/500000 (0%)]\tLoss: 0.030773\n",
      "Train Epoch: 84 [300/500000 (0%)]\tLoss: 0.028179\n",
      "Train Epoch: 85 [100/500000 (0%)]\tLoss: 0.106388\n",
      "Train Epoch: 85 [200/500000 (0%)]\tLoss: 0.015341\n",
      "Train Epoch: 85 [300/500000 (0%)]\tLoss: 0.006972\n",
      "Train Epoch: 86 [100/500000 (0%)]\tLoss: 0.022729\n",
      "Train Epoch: 86 [200/500000 (0%)]\tLoss: 0.019414\n",
      "Train Epoch: 86 [300/500000 (0%)]\tLoss: 0.062229\n",
      "Train Epoch: 87 [100/500000 (0%)]\tLoss: 0.011726\n",
      "Train Epoch: 87 [200/500000 (0%)]\tLoss: 0.029620\n",
      "Train Epoch: 87 [300/500000 (0%)]\tLoss: 0.021022\n",
      "Train Epoch: 88 [100/500000 (0%)]\tLoss: 0.058132\n",
      "Train Epoch: 88 [200/500000 (0%)]\tLoss: 0.021066\n",
      "Train Epoch: 88 [300/500000 (0%)]\tLoss: 0.048403\n",
      "Train Epoch: 89 [100/500000 (0%)]\tLoss: 0.009745\n",
      "Train Epoch: 89 [200/500000 (0%)]\tLoss: 0.005809\n",
      "Train Epoch: 89 [300/500000 (0%)]\tLoss: 0.011587\n",
      "Train Epoch: 90 [100/500000 (0%)]\tLoss: 0.042133\n",
      "Train Epoch: 90 [200/500000 (0%)]\tLoss: 0.037925\n",
      "Train Epoch: 90 [300/500000 (0%)]\tLoss: 0.112495\n",
      "Train Epoch: 91 [100/500000 (0%)]\tLoss: 0.032969\n",
      "Train Epoch: 91 [200/500000 (0%)]\tLoss: 0.052697\n",
      "Train Epoch: 91 [300/500000 (0%)]\tLoss: 0.020755\n",
      "Train Epoch: 92 [100/500000 (0%)]\tLoss: 0.006512\n",
      "Train Epoch: 92 [200/500000 (0%)]\tLoss: 0.012896\n",
      "Train Epoch: 92 [300/500000 (0%)]\tLoss: 0.030665\n",
      "Train Epoch: 93 [100/500000 (0%)]\tLoss: 0.022945\n",
      "Train Epoch: 93 [200/500000 (0%)]\tLoss: 0.009144\n",
      "Train Epoch: 93 [300/500000 (0%)]\tLoss: 0.018156\n",
      "Train Epoch: 94 [100/500000 (0%)]\tLoss: 0.019550\n",
      "Train Epoch: 94 [200/500000 (0%)]\tLoss: 0.024377\n",
      "Train Epoch: 94 [300/500000 (0%)]\tLoss: 0.042285\n",
      "Train Epoch: 95 [100/500000 (0%)]\tLoss: 0.014709\n",
      "Train Epoch: 95 [200/500000 (0%)]\tLoss: 0.011929\n",
      "Train Epoch: 95 [300/500000 (0%)]\tLoss: 0.086691\n",
      "Train Epoch: 96 [100/500000 (0%)]\tLoss: 0.010794\n",
      "Train Epoch: 96 [200/500000 (0%)]\tLoss: 0.037989\n",
      "Train Epoch: 96 [300/500000 (0%)]\tLoss: 0.065397\n",
      "Train Epoch: 97 [100/500000 (0%)]\tLoss: 0.037966\n",
      "Train Epoch: 97 [200/500000 (0%)]\tLoss: 0.020371\n",
      "Train Epoch: 97 [300/500000 (0%)]\tLoss: 0.022839\n",
      "Train Epoch: 98 [100/500000 (0%)]\tLoss: 0.474434\n",
      "Train Epoch: 98 [200/500000 (0%)]\tLoss: 0.046658\n",
      "Train Epoch: 98 [300/500000 (0%)]\tLoss: 0.129797\n",
      "Train Epoch: 99 [100/500000 (0%)]\tLoss: 0.005231\n",
      "Train Epoch: 99 [200/500000 (0%)]\tLoss: 0.065592\n",
      "Train Epoch: 99 [300/500000 (0%)]\tLoss: 0.038024\n",
      "Train Epoch: 100 [100/500000 (0%)]\tLoss: 0.018362\n",
      "Train Epoch: 100 [200/500000 (0%)]\tLoss: 0.095074\n",
      "Train Epoch: 100 [300/500000 (0%)]\tLoss: 0.006929\n",
      "Train Epoch: 101 [100/500000 (0%)]\tLoss: 0.014147\n",
      "Train Epoch: 101 [200/500000 (0%)]\tLoss: 0.026318\n",
      "Train Epoch: 101 [300/500000 (0%)]\tLoss: 0.016943\n",
      "Train Epoch: 102 [100/500000 (0%)]\tLoss: 0.025810\n",
      "Train Epoch: 102 [200/500000 (0%)]\tLoss: 0.018521\n",
      "Train Epoch: 102 [300/500000 (0%)]\tLoss: 0.014238\n",
      "Train Epoch: 103 [100/500000 (0%)]\tLoss: 0.037009\n",
      "Train Epoch: 103 [200/500000 (0%)]\tLoss: 0.012779\n",
      "Train Epoch: 103 [300/500000 (0%)]\tLoss: 0.027952\n",
      "Train Epoch: 104 [100/500000 (0%)]\tLoss: 0.015749\n",
      "Train Epoch: 104 [200/500000 (0%)]\tLoss: 0.010856\n",
      "Train Epoch: 104 [300/500000 (0%)]\tLoss: 0.011635\n",
      "Train Epoch: 105 [100/500000 (0%)]\tLoss: 0.019065\n",
      "Train Epoch: 105 [200/500000 (0%)]\tLoss: 0.012640\n",
      "Train Epoch: 105 [300/500000 (0%)]\tLoss: 0.015792\n",
      "Train Epoch: 106 [100/500000 (0%)]\tLoss: 1.135899\n",
      "Train Epoch: 106 [200/500000 (0%)]\tLoss: 0.013730\n",
      "Train Epoch: 106 [300/500000 (0%)]\tLoss: 0.034316\n",
      "Train Epoch: 107 [100/500000 (0%)]\tLoss: 0.027077\n",
      "Train Epoch: 107 [200/500000 (0%)]\tLoss: 0.013579\n",
      "Train Epoch: 107 [300/500000 (0%)]\tLoss: 0.009254\n",
      "Train Epoch: 108 [100/500000 (0%)]\tLoss: 0.029248\n",
      "Train Epoch: 108 [200/500000 (0%)]\tLoss: 0.185030\n",
      "Train Epoch: 108 [300/500000 (0%)]\tLoss: 0.029788\n",
      "Train Epoch: 109 [100/500000 (0%)]\tLoss: 0.020416\n",
      "Train Epoch: 109 [200/500000 (0%)]\tLoss: 0.012415\n",
      "Train Epoch: 109 [300/500000 (0%)]\tLoss: 0.014078\n",
      "Train Epoch: 110 [100/500000 (0%)]\tLoss: 0.012541\n",
      "Train Epoch: 110 [200/500000 (0%)]\tLoss: 0.118292\n",
      "Train Epoch: 110 [300/500000 (0%)]\tLoss: 0.008149\n",
      "Train Epoch: 111 [100/500000 (0%)]\tLoss: 0.013056\n",
      "Train Epoch: 111 [200/500000 (0%)]\tLoss: 0.019237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 111 [300/500000 (0%)]\tLoss: 0.021893\n",
      "Train Epoch: 112 [100/500000 (0%)]\tLoss: 0.004763\n",
      "Train Epoch: 112 [200/500000 (0%)]\tLoss: 0.025831\n",
      "Train Epoch: 112 [300/500000 (0%)]\tLoss: 0.023067\n",
      "Train Epoch: 113 [100/500000 (0%)]\tLoss: 0.015112\n",
      "Train Epoch: 113 [200/500000 (0%)]\tLoss: 0.017460\n",
      "Train Epoch: 113 [300/500000 (0%)]\tLoss: 0.022448\n",
      "Train Epoch: 114 [100/500000 (0%)]\tLoss: 0.013311\n",
      "Train Epoch: 114 [200/500000 (0%)]\tLoss: 0.014393\n",
      "Train Epoch: 114 [300/500000 (0%)]\tLoss: 0.022457\n",
      "Train Epoch: 115 [100/500000 (0%)]\tLoss: 0.057628\n",
      "Train Epoch: 115 [200/500000 (0%)]\tLoss: 0.070957\n",
      "Train Epoch: 115 [300/500000 (0%)]\tLoss: 0.024153\n",
      "Train Epoch: 116 [100/500000 (0%)]\tLoss: 0.014099\n",
      "Train Epoch: 116 [200/500000 (0%)]\tLoss: 0.016828\n",
      "Train Epoch: 116 [300/500000 (0%)]\tLoss: 0.043525\n",
      "Train Epoch: 117 [100/500000 (0%)]\tLoss: 0.019170\n",
      "Train Epoch: 117 [200/500000 (0%)]\tLoss: 0.025073\n",
      "Train Epoch: 117 [300/500000 (0%)]\tLoss: 0.022874\n",
      "Train Epoch: 118 [100/500000 (0%)]\tLoss: 0.051869\n",
      "Train Epoch: 118 [200/500000 (0%)]\tLoss: 0.191308\n",
      "Train Epoch: 118 [300/500000 (0%)]\tLoss: 0.010453\n",
      "Train Epoch: 119 [100/500000 (0%)]\tLoss: 0.018904\n",
      "Train Epoch: 119 [200/500000 (0%)]\tLoss: 0.020491\n",
      "Train Epoch: 119 [300/500000 (0%)]\tLoss: 0.015974\n",
      "Train Epoch: 120 [100/500000 (0%)]\tLoss: 0.018776\n",
      "Train Epoch: 120 [200/500000 (0%)]\tLoss: 0.399784\n",
      "Train Epoch: 120 [300/500000 (0%)]\tLoss: 0.040775\n",
      "Train Epoch: 121 [100/500000 (0%)]\tLoss: 0.041785\n",
      "Train Epoch: 121 [200/500000 (0%)]\tLoss: 0.012974\n",
      "Train Epoch: 121 [300/500000 (0%)]\tLoss: 0.026646\n",
      "Train Epoch: 122 [100/500000 (0%)]\tLoss: 0.109011\n",
      "Train Epoch: 122 [200/500000 (0%)]\tLoss: 0.016572\n",
      "Train Epoch: 122 [300/500000 (0%)]\tLoss: 0.330204\n",
      "Train Epoch: 123 [100/500000 (0%)]\tLoss: 0.146972\n",
      "Train Epoch: 123 [200/500000 (0%)]\tLoss: 0.007610\n",
      "Train Epoch: 123 [300/500000 (0%)]\tLoss: 0.011826\n",
      "Train Epoch: 124 [100/500000 (0%)]\tLoss: 0.032163\n",
      "Train Epoch: 124 [200/500000 (0%)]\tLoss: 0.007043\n",
      "Train Epoch: 124 [300/500000 (0%)]\tLoss: 0.010886\n",
      "Train Epoch: 125 [100/500000 (0%)]\tLoss: 0.034505\n",
      "Train Epoch: 125 [200/500000 (0%)]\tLoss: 0.013876\n",
      "Train Epoch: 125 [300/500000 (0%)]\tLoss: 0.037044\n",
      "Train Epoch: 126 [100/500000 (0%)]\tLoss: 0.018663\n",
      "Train Epoch: 126 [200/500000 (0%)]\tLoss: 0.014285\n",
      "Train Epoch: 126 [300/500000 (0%)]\tLoss: 0.017305\n",
      "Train Epoch: 127 [100/500000 (0%)]\tLoss: 0.162155\n",
      "Train Epoch: 127 [200/500000 (0%)]\tLoss: 2.644139\n",
      "Train Epoch: 127 [300/500000 (0%)]\tLoss: 0.019296\n",
      "Train Epoch: 128 [100/500000 (0%)]\tLoss: 0.045719\n",
      "Train Epoch: 128 [200/500000 (0%)]\tLoss: 3.105922\n",
      "Train Epoch: 128 [300/500000 (0%)]\tLoss: 0.038097\n",
      "Train Epoch: 129 [100/500000 (0%)]\tLoss: 0.089416\n",
      "Train Epoch: 129 [200/500000 (0%)]\tLoss: 0.016951\n",
      "Train Epoch: 129 [300/500000 (0%)]\tLoss: 0.042674\n",
      "Train Epoch: 130 [100/500000 (0%)]\tLoss: 0.026336\n",
      "Train Epoch: 130 [200/500000 (0%)]\tLoss: 0.042717\n",
      "Train Epoch: 130 [300/500000 (0%)]\tLoss: 0.019275\n",
      "Train Epoch: 131 [100/500000 (0%)]\tLoss: 0.773377\n",
      "Train Epoch: 131 [200/500000 (0%)]\tLoss: 0.029295\n",
      "Train Epoch: 131 [300/500000 (0%)]\tLoss: 0.126871\n",
      "Train Epoch: 132 [100/500000 (0%)]\tLoss: 0.019303\n",
      "Train Epoch: 132 [200/500000 (0%)]\tLoss: 0.037227\n",
      "Train Epoch: 132 [300/500000 (0%)]\tLoss: 0.032478\n",
      "Train Epoch: 133 [100/500000 (0%)]\tLoss: 0.051473\n",
      "Train Epoch: 133 [200/500000 (0%)]\tLoss: 0.024155\n",
      "Train Epoch: 133 [300/500000 (0%)]\tLoss: 0.458254\n",
      "Train Epoch: 134 [100/500000 (0%)]\tLoss: 0.032421\n",
      "Train Epoch: 134 [200/500000 (0%)]\tLoss: 0.021252\n",
      "Train Epoch: 134 [300/500000 (0%)]\tLoss: 0.072954\n",
      "Train Epoch: 135 [100/500000 (0%)]\tLoss: 0.047554\n",
      "Train Epoch: 135 [200/500000 (0%)]\tLoss: 0.040154\n",
      "Train Epoch: 135 [300/500000 (0%)]\tLoss: 0.044067\n",
      "Train Epoch: 136 [100/500000 (0%)]\tLoss: 0.019306\n",
      "Train Epoch: 136 [200/500000 (0%)]\tLoss: 0.115293\n",
      "Train Epoch: 136 [300/500000 (0%)]\tLoss: 0.025835\n",
      "Train Epoch: 137 [100/500000 (0%)]\tLoss: 0.006124\n",
      "Train Epoch: 137 [200/500000 (0%)]\tLoss: 0.054927\n",
      "Train Epoch: 137 [300/500000 (0%)]\tLoss: 0.045122\n",
      "Train Epoch: 138 [100/500000 (0%)]\tLoss: 0.030009\n",
      "Train Epoch: 138 [200/500000 (0%)]\tLoss: 0.024266\n",
      "Train Epoch: 138 [300/500000 (0%)]\tLoss: 0.723241\n",
      "Train Epoch: 139 [100/500000 (0%)]\tLoss: 0.010092\n",
      "Train Epoch: 139 [200/500000 (0%)]\tLoss: 0.023394\n",
      "Train Epoch: 139 [300/500000 (0%)]\tLoss: 1.158289\n",
      "Train Epoch: 140 [100/500000 (0%)]\tLoss: 0.025027\n",
      "Train Epoch: 140 [200/500000 (0%)]\tLoss: 0.022011\n",
      "Train Epoch: 140 [300/500000 (0%)]\tLoss: 0.024041\n",
      "Train Epoch: 141 [100/500000 (0%)]\tLoss: 0.013908\n",
      "Train Epoch: 141 [200/500000 (0%)]\tLoss: 0.026339\n",
      "Train Epoch: 141 [300/500000 (0%)]\tLoss: 0.035953\n",
      "Train Epoch: 142 [100/500000 (0%)]\tLoss: 0.021749\n",
      "Train Epoch: 142 [200/500000 (0%)]\tLoss: 0.109918\n",
      "Train Epoch: 142 [300/500000 (0%)]\tLoss: 0.005261\n",
      "Train Epoch: 143 [100/500000 (0%)]\tLoss: 0.018344\n",
      "Train Epoch: 143 [200/500000 (0%)]\tLoss: 0.004534\n",
      "Train Epoch: 143 [300/500000 (0%)]\tLoss: 0.047588\n",
      "Train Epoch: 144 [100/500000 (0%)]\tLoss: 0.008588\n",
      "Train Epoch: 144 [200/500000 (0%)]\tLoss: 0.017145\n",
      "Train Epoch: 144 [300/500000 (0%)]\tLoss: 0.371049\n",
      "Train Epoch: 145 [100/500000 (0%)]\tLoss: 0.030213\n",
      "Train Epoch: 145 [200/500000 (0%)]\tLoss: 0.038232\n",
      "Train Epoch: 145 [300/500000 (0%)]\tLoss: 0.023471\n",
      "Train Epoch: 146 [100/500000 (0%)]\tLoss: 0.012831\n",
      "Train Epoch: 146 [200/500000 (0%)]\tLoss: 0.132385\n",
      "Train Epoch: 146 [300/500000 (0%)]\tLoss: 1.676221\n",
      "Train Epoch: 147 [100/500000 (0%)]\tLoss: 0.006196\n",
      "Train Epoch: 147 [200/500000 (0%)]\tLoss: 0.032681\n",
      "Train Epoch: 147 [300/500000 (0%)]\tLoss: 0.034696\n",
      "Train Epoch: 148 [100/500000 (0%)]\tLoss: 0.012499\n",
      "Train Epoch: 148 [200/500000 (0%)]\tLoss: 0.557895\n",
      "Train Epoch: 148 [300/500000 (0%)]\tLoss: 0.251167\n",
      "Train Epoch: 149 [100/500000 (0%)]\tLoss: 0.021893\n",
      "Train Epoch: 149 [200/500000 (0%)]\tLoss: 0.010153\n",
      "Train Epoch: 149 [300/500000 (0%)]\tLoss: 0.060334\n",
      "Train Epoch: 150 [100/500000 (0%)]\tLoss: 0.005937\n",
      "Train Epoch: 150 [200/500000 (0%)]\tLoss: 0.056558\n",
      "Train Epoch: 150 [300/500000 (0%)]\tLoss: 0.014304\n",
      "Train Epoch: 151 [100/500000 (0%)]\tLoss: 0.033967\n",
      "Train Epoch: 151 [200/500000 (0%)]\tLoss: 0.020241\n",
      "Train Epoch: 151 [300/500000 (0%)]\tLoss: 0.022868\n",
      "Train Epoch: 152 [100/500000 (0%)]\tLoss: 0.032505\n",
      "Train Epoch: 152 [200/500000 (0%)]\tLoss: 0.032624\n",
      "Train Epoch: 152 [300/500000 (0%)]\tLoss: 0.009465\n",
      "Train Epoch: 153 [100/500000 (0%)]\tLoss: 0.019231\n",
      "Train Epoch: 153 [200/500000 (0%)]\tLoss: 0.027485\n",
      "Train Epoch: 153 [300/500000 (0%)]\tLoss: 0.346429\n",
      "Train Epoch: 154 [100/500000 (0%)]\tLoss: 0.027839\n",
      "Train Epoch: 154 [200/500000 (0%)]\tLoss: 0.041591\n",
      "Train Epoch: 154 [300/500000 (0%)]\tLoss: 0.022778\n",
      "Train Epoch: 155 [100/500000 (0%)]\tLoss: 0.016965\n",
      "Train Epoch: 155 [200/500000 (0%)]\tLoss: 0.027096\n",
      "Train Epoch: 155 [300/500000 (0%)]\tLoss: 0.050498\n",
      "Train Epoch: 156 [100/500000 (0%)]\tLoss: 0.019094\n",
      "Train Epoch: 156 [200/500000 (0%)]\tLoss: 0.012022\n",
      "Train Epoch: 156 [300/500000 (0%)]\tLoss: 2.323374\n",
      "Train Epoch: 157 [100/500000 (0%)]\tLoss: 0.016161\n",
      "Train Epoch: 157 [200/500000 (0%)]\tLoss: 0.009577\n",
      "Train Epoch: 157 [300/500000 (0%)]\tLoss: 0.020926\n",
      "Train Epoch: 158 [100/500000 (0%)]\tLoss: 0.027684\n",
      "Train Epoch: 158 [200/500000 (0%)]\tLoss: 0.016520\n",
      "Train Epoch: 158 [300/500000 (0%)]\tLoss: 0.012622\n",
      "Train Epoch: 159 [100/500000 (0%)]\tLoss: 0.020014\n",
      "Train Epoch: 159 [200/500000 (0%)]\tLoss: 0.020903\n",
      "Train Epoch: 159 [300/500000 (0%)]\tLoss: 0.022156\n",
      "Train Epoch: 160 [100/500000 (0%)]\tLoss: 0.038581\n",
      "Train Epoch: 160 [200/500000 (0%)]\tLoss: 0.029492\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_274141/476139893.py\u001b[0m in \u001b[0;36mfull_training_loop\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, epochs, print_loss_every_batches, validate_every_epochs, optimizer_step_every_batches, per_epoch_use_max_train_batches, per_epoch_use_max_test_batches, image_path, save_model_every_epochs, model_path, best_model_path, scheduler)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         train_loss = train_epoch(epoch, criterion, model, optimizer, train_loader,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                  \u001b[0mprint_loss_every_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_loss_every_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0moptimizer_step_every_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_step_every_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_274141/2802419939.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, criterion, model, optimizer, dataloader, print_loss_every_batches, optimizer_step_every_batches, per_epoch_use_max_batches)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#print(f\"it time {t9-t}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#.item() is very important here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;31m# In order to avoid having total_loss as a tensor in the gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#t = time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "losses = full_training_loop(model, criterion, optimizer, train_dataloader, test_dataloader, \n",
    "                    epochs=total_epochs, print_loss_every_batches=10,\n",
    "                            validate_every_epochs=validate_every_epochs,\n",
    "                           optimizer_step_every_batches=optimizer_step_every_batches,\n",
    "                           per_epoch_use_max_train_batches=per_epoch_use_max_train_batches, \n",
    "                            per_epoch_use_max_test_batches=per_epoch_use_max_test_batches,\n",
    "                           image_path=save_stuff_path+f\"Noisy_Training_{datetime.now()}_{exp_name}.png\",\n",
    "                           save_model_every_epochs=save_model_every_epochs, \n",
    "                            model_path=save_stuff_path+f\"/Noisy_Model_and_Optimizer_{datetime.now()}_{exp_name}.pt\",\n",
    "                            best_model_path=save_stuff_path+f\"/BEST_Noisy_Model_and_Optimizer_{datetime.now()}_{exp_name}.pt\",\n",
    "                            scheduler=scheduler\n",
    "                           )\n",
    "# Execute the training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, el pb es exclusivamente el Backjprop, ni es el data transfer (ya ke el crazy no improvea el tiempo practicamente), ni es nigun print. Tb un poco es el model inference, ke es la mitad del tiempo de cada batch! \n",
    "\n",
    "\n",
    "Turns out ke unos 7 segdos y medio son inferencia y 25 en total si haces backward -backpropagate-.\n",
    "Asike todo el tiempo gordo, no es ni el retrieval (image library o in situ generation), ni el sending al device (ya ke sendeas o no en cada batch no cambia tpco casi), ni los prints:\n",
    "Son 1/3 del tiempo el inference, y 2/3 del tiempo el backpropagate!\n",
    "\n",
    "LA cosa es en si ppodrias hacer backward solo cuando hagas el step del optimizer y no en cada batch. Lo ke pasa es ke tienes el trade off de ke iras acumulando cada vez un computational graph mas grande! Asike kizas no cunda, porke la memoria se ira llenando mas, y en realidad kizas sea secuencial el backprop ke ejekutes?\n",
    "\n",
    "Pues lo he probado y efectivamente, las batches sin backprop son de 7 y pico secs, pero luego la cuarta (cadda 4 se hace backw pa hacer step), es de 80 secs, en total, 100 secs, como si cada uno hubiese tardado 25 secs. En fin, no hay solucion magica: Solo una-> hacer el modelo mas pequeño..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the resulting model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            }, f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/Noisy_Model_opt_Adam_it_1_8sperbatchx10batchperepx20epochs_samples_feats_1={feats_1}_feats_2={feats_2}_feats_3={feats_3}_feats_4={feats_4}_prop1={prop1}_prop2={prop2}_prop3={prop3}_av_pool1_div={av_pool1_div}_conv4_feat_size={conv4_feat_size}_av_pool2_div={av_pool2_div}_out_fc_1={out_fc_1}_dropout_p1={dropout_p1}_dropout_p2={dropout_p2}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "FINAL VALIDATION! ####################################################\n",
      "\n",
      "\n",
      "Train Set\n",
      "Test Set\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_274141/2114560714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#validate_epoch(nn.MSELoss(), model, sampler, dataset, per_epoch_use_max_train_batches)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_epoch_use_max_test_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_274141/2802419939.py\u001b[0m in \u001b[0;36mvalidate_epoch\u001b[0;34m(criterion, model, dataloader, per_epoch_use_max_batches)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmax_abs_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_abs_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmean_abs_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\\nFINAL VALIDATION! ####################################################\\n\\n\")\n",
    "print(\"Train Set\")\n",
    "#validate_epoch(nn.MSELoss(), model, sampler, dataset, per_epoch_use_max_train_batches)\n",
    "print(\"Test Set\")\n",
    "validate_epoch(nn.MSELoss(), model, test_dataloader, per_epoch_use_max_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEGREES-----------------------------------------------------\n",
      "EXPERIMENTALES ###########\n",
      "Positivo-Ref deberian ser 13.85 deg son 15.90104580291028 deg\n",
      "Negativo-Ref deberian ser 9.45 deg son 8.016457278834212 deg\n",
      "Ambos-Ref deberian ser 4.4 deg son 2.5753723454247903 deg\n",
      "\n",
      "Positivo-Ref2 deberian ser 13.85 deg son 15.960475278878562 deg\n",
      "Negativo-Ref2 deberian ser 9.45 deg son 7.957027802865931 deg\n",
      "Ambos-Ref2 deberian ser 4.4 deg son 2.6348018213930713 deg\n",
      "\n",
      "Ref2-Ref deberian ser 0 deg son -0.059429475968280944 deg\n",
      "\n",
      "El de noventa deberian ser 90 deg son 97.54919202803983 deg\n",
      "TEORICOS NOISY #############\n",
      "Should be 121.0568385095803 deg predicted 128.74694166590848\n",
      "Should be 50.818810160902196 deg predicted 51.217073368763764\n",
      "Should be -8.379306809622909 deg predicted -10.082516932003138\n",
      "Should be 84.2488312516184 deg predicted 82.95722028145418\n",
      "Should be 11.417651575105966 deg predicted 10.207977261772516\n",
      "TEORICOS NON NOISY #########\n",
      "Should be -24.312744784671974 deg predicted -22.964219555701337\n",
      "Should be -122.6263749997142 deg predicted -122.10247899980672\n",
      "\n",
      "\n",
      "RADIANS-----------------------------------------------------\n",
      "EXPERIMENTALES ###########\n",
      "Positivo-Ref deberian ser 0.24172810140121462 rad son 0.2775256037712097 rad\n",
      "Negativo-Ref deberian ser 0.16493361431346412 rad son 0.13991357386112213 rad\n",
      "Ambos-Ref deberian ser 0.07679448708775051 rad son 0.044948726892471313 rad\n",
      "\n",
      "Positivo-Ref2 deberian ser 0.24172810140121462 rad son 0.27856284379959106 rad\n",
      "Negativo-Ref2 deberian ser 0.16493361431346412 rad son 0.13887633383274078 rad\n",
      "Ambos-Ref2 deberian ser 0.07679448708775051 rad son 0.04598596692085266 rad\n",
      "\n",
      "Ref2-Ref deberian ser 0 rad son -0.0010372400283813477 rad\n",
      "\n",
      "El de noventa deberian ser 1.5707963267948966 rad son 1.7025545835494995 rad\n",
      "TEORICOS NOISY #############\n",
      "Should be 2.112840414047241 rad predicted 2.2470580339431763\n",
      "Should be 0.8869555592536926 rad predicted 0.8939065635204315\n",
      "Should be -0.14624649286270142 rad predicted -0.17597311735153198\n",
      "Should be 1.4704194962978363 rad predicted 1.4478766322135925\n",
      "Should be 0.19927561283111572 rad predicted 0.1781628131866455\n",
      "TEORICOS NON NOISY #########\n",
      "Should be -0.4243374466896057 rad predicted -0.40080124139785767\n",
      "Should be -2.1402339935302734 rad predicted -2.13109028339386\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "path = \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/UMAP_Regressor/TEST_IMAGES/\"\n",
    "image_names = os.listdir(f\"{path}\")\n",
    "\n",
    "predictions={}\n",
    "\n",
    "for im_n in image_names:\n",
    "    model.eval()\n",
    "    im = cv2.imread(path+im_n, cv2.IMREAD_ANYDEPTH)\n",
    "    im = compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))\n",
    "    predictions[im_n] = model(im)[0].item()\n",
    "print(\"DEGREES-----------------------------------------------------\")\n",
    "print(\"EXPERIMENTALES ###########\")\n",
    "print(f\"Positivo-Ref deberian ser {13.85} deg son {-(predictions['sin_el_negativo.png']-predictions['antes_de_la_estandar.png'])*180/np.pi/2} deg\")\n",
    "print(f\"Negativo-Ref deberian ser {9.45} deg son {(predictions['sin_el_positivo.png']-predictions['antes_de_la_estandar.png'])*180/np.pi/2} deg\")\n",
    "print(f\"Ambos-Ref deberian ser {4.4} deg son {-(predictions['con_los_dos.png']-predictions['antes_de_la_estandar.png'])*180/np.pi/2} deg\\n\")\n",
    "\n",
    "print(f\"Positivo-Ref2 deberian ser {13.85} deg son {-(predictions['sin_el_negativo.png']-predictions['sin_los_dos_solo_tubo.png'])*180/np.pi/2} deg\")\n",
    "print(f\"Negativo-Ref2 deberian ser {9.45} deg son {(predictions['sin_el_positivo.png']-predictions['sin_los_dos_solo_tubo.png'])*180/np.pi/2} deg\")\n",
    "print(f\"Ambos-Ref2 deberian ser {4.4} deg son {-(predictions['con_los_dos.png']-predictions['sin_los_dos_solo_tubo.png'])*180/np.pi/2} deg\\n\")\n",
    "\n",
    "print(f\"Ref2-Ref deberian ser {0} deg son {(predictions['antes_de_la_estandar.png']-predictions['sin_los_dos_solo_tubo.png'])*180/np.pi/2} deg\\n\")\n",
    "\n",
    "print(f\"El de noventa deberian ser {90} deg son {(predictions['Reference__100.png']-predictions['90__100.png'])*180/np.pi/2} deg\")\n",
    "\n",
    "print(\"TEORICOS NOISY #############\")\n",
    "print(f\"Should be {(2.6544740200042725+1.57120680809021)*180/np.pi/2} deg predicted {(predictions['IM_44_phiCR_2.6544740200042725.png']-predictions['IM_43_phiCR_-1.57120680809021.png'])*180/np.pi/2}\")\n",
    "print(f\"Should be {(-0.6731816530227661+2.4470927715301514)*180/np.pi/2} deg predicted {(predictions['IM_40870_phiCR_-0.6731816530227661.png']-predictions['IM_40871_phiCR_-2.4470927715301514.png'])*180/np.pi/2}\")\n",
    "print(f\"Should be {(0.6789670586585999-0.9714600443840027)*180/np.pi/2} deg predicted {(predictions['IM_52928_phiCR_0.6789670586585999.png']-predictions['IM_52929_phiCR_0.9714600443840027.png'])*180/np.pi/2}\")\n",
    "print(f\"Should be {(0.659442126750946+2.2813968658447266)*180/np.pi/2} deg predicted {(predictions['IM_53017_phiCR_0.659442126750946.png']-predictions['IM_53018_phiCR_-2.2813968658447266.png'])*180/np.pi/2}\")\n",
    "print(f\"Should be {(-2.2813968658447266+2.679948091506958)*180/np.pi/2} deg predicted {(predictions['IM_53018_phiCR_-2.2813968658447266.png']-predictions['IM_53019_phiCR_-2.679948091506958.png'])*180/np.pi/2}\")\n",
    "print(\"TEORICOS NON NOISY #########\")\n",
    "print(f\"Should be {(-2.6049387454986572+1.7562638521194458)*180/np.pi/2} deg predicted {(predictions['IM_5_phiCR_-2.6049387454986572.png']-predictions['IM_6_phiCR_-1.7562638521194458.png'])*180/np.pi/2}\")\n",
    "print(f\"Should be {(-2.946422576904297-1.33404541015625)*180/np.pi/2} deg predicted {(predictions['IM_72_phiCR_-2.946422576904297.png']-predictions['IM_73_phiCR_1.33404541015625.png'])*180/np.pi/2}\")\n",
    "\n",
    "print(\"\\n\\nRADIANS-----------------------------------------------------\")\n",
    "print(\"EXPERIMENTALES ###########\")\n",
    "print(f\"Positivo-Ref deberian ser {13.85*np.pi/180} rad son {-(predictions['sin_el_negativo.png']-predictions['antes_de_la_estandar.png'])/2} rad\")\n",
    "print(f\"Negativo-Ref deberian ser {9.45*np.pi/180} rad son {(predictions['sin_el_positivo.png']-predictions['antes_de_la_estandar.png'])/2} rad\")\n",
    "print(f\"Ambos-Ref deberian ser {4.4*np.pi/180} rad son {-(predictions['con_los_dos.png']-predictions['antes_de_la_estandar.png'])/2} rad\\n\")\n",
    "\n",
    "print(f\"Positivo-Ref2 deberian ser {13.85*np.pi/180} rad son {-(predictions['sin_el_negativo.png']-predictions['sin_los_dos_solo_tubo.png'])/2} rad\")\n",
    "print(f\"Negativo-Ref2 deberian ser {9.45*np.pi/180} rad son {(predictions['sin_el_positivo.png']-predictions['sin_los_dos_solo_tubo.png'])/2} rad\")\n",
    "print(f\"Ambos-Ref2 deberian ser {4.4*np.pi/180} rad son {-(predictions['con_los_dos.png']-predictions['sin_los_dos_solo_tubo.png'])/2} rad\\n\")\n",
    "\n",
    "print(f\"Ref2-Ref deberian ser {0} rad son {(predictions['antes_de_la_estandar.png']-predictions['sin_los_dos_solo_tubo.png'])/2} rad\\n\")\n",
    "\n",
    "print(f\"El de noventa deberian ser {np.pi/2} rad son {(predictions['Reference__100.png']-predictions['90__100.png'])/2} rad\")\n",
    "\n",
    "print(\"TEORICOS NOISY #############\")\n",
    "print(f\"Should be {(2.6544740200042725+1.57120680809021)/2} rad predicted {(predictions['IM_44_phiCR_2.6544740200042725.png']-predictions['IM_43_phiCR_-1.57120680809021.png'])/2}\")\n",
    "print(f\"Should be {(-0.6731816530227661+2.4470927715301514)/2} rad predicted {(predictions['IM_40870_phiCR_-0.6731816530227661.png']-predictions['IM_40871_phiCR_-2.4470927715301514.png'])/2}\")\n",
    "print(f\"Should be {(0.6789670586585999-0.9714600443840027)/2} rad predicted {(predictions['IM_52928_phiCR_0.6789670586585999.png']-predictions['IM_52929_phiCR_0.9714600443840027.png'])/2}\")\n",
    "print(f\"Should be {(0.659442126750946+2.2813968658447266)/2} rad predicted {(predictions['IM_53017_phiCR_0.659442126750946.png']-predictions['IM_53018_phiCR_-2.2813968658447266.png'])/2}\")\n",
    "print(f\"Should be {(-2.2813968658447266+2.679948091506958)/2} rad predicted {(predictions['IM_53018_phiCR_-2.2813968658447266.png']-predictions['IM_53019_phiCR_-2.679948091506958.png'])/2}\")\n",
    "print(\"TEORICOS NON NOISY #########\")\n",
    "print(f\"Should be {(-2.6049387454986572+1.7562638521194458)/2} rad predicted {(predictions['IM_5_phiCR_-2.6049387454986572.png']-predictions['IM_6_phiCR_-1.7562638521194458.png'])/2}\")\n",
    "print(f\"Should be {(-2.946422576904297-1.33404541015625)/2} rad predicted {(predictions['IM_72_phiCR_-2.946422576904297.png']-predictions['IM_73_phiCR_1.33404541015625.png'])/2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charge models and do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/Noisy_Model_and_Optimizer_2022-01-24 19:57:31.886991.pt\")\n",
    "\n",
    "model = Simple_Encoder( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                 prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, av_pool2_div=av_pool2_div, \n",
    "                 out_fc_1=out_fc_1,\n",
    "                 dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity_gravity_centers(images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "def compute_raw_to_centered_iX(images, X=302):\n",
    "\n",
    "        g_raw = compute_intensity_gravity_centers(images) # [ N_images, 2]\n",
    "\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                      device=device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-X\n",
    "        unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(g_raw.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a FileChooser widget\n",
    "from ipyfilechooser import FileChooser\n",
    "path=\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter\"\n",
    "fc = FileChooser(path+'/LAB/EXPERIMENTAL/Fotos_Turpin/Day2/laser_gaussian_thesis/')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a single experimental image to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_full_path=fc.selected\n",
    "#image_full_path=\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/Experimental_Stuff/Fotos_Turpin/Day2/laser_gaussian_thesis/All_Taken_Photos/sin_el_positivo.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "if im is None:\n",
    "    print(f\" Unable to import image {image_full_path}\")\n",
    "    raise ValueError\n",
    "# Center in gravicenter, generating iX\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot its Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3d_resolution=0.7\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "prof_x=np.sum(im, axis=0)\n",
    "prof_y=np.sum(im, axis=1)\n",
    "fig = plt.figure(figsize=(2*4.5, 2*4.5))\n",
    "axes=fig.subplots(2,2)\n",
    "\n",
    "cm=axes[0, 0].imshow(im, cmap='viridis')\n",
    "axes[0,0].grid(True)\n",
    "axes[0,1].scatter(prof_y, np.arange(len(prof_y)), s=1, label=f'Intensity profile in y')\n",
    "axes[0,1].set_ylim((0,len(prof_y)))\n",
    "axes[0,1].invert_yaxis()\n",
    "axes[1,0].scatter(np.arange(len(prof_x)), prof_x, s=1, label=f'Intensity profile in y')\n",
    "axes[1,0].set_xlim((0,len(prof_x)))\n",
    "axes[1,0].invert_yaxis()\n",
    "axes[0,0].set_xlabel(\"x (pixels)\")\n",
    "#axes[0,0].set_ylabel(\"y (pixels)\")\n",
    "axes[0,1].set_xlabel(\"Cummulative Intensity\")\n",
    "axes[0,1].set_ylabel(\"y (pixels)\")\n",
    "axes[1,0].set_ylabel(\"Cummulative Intensity\")\n",
    "axes[1,0].set_xlabel(\"x (pixels)\")\n",
    "axes[1,0].grid(True)\n",
    "axes[0,1].grid(True)\n",
    "axes[1,1].set_visible(False)\n",
    "ax = fig.add_subplot(224, projection='3d')\n",
    "Xs,Ys = np.meshgrid(np.arange(len(prof_y)),np.arange(len(prof_x)))\n",
    "fig.suptitle(f\"Intesity Profiles for Image\\n{image_full_path.split('/')[-1]}\")\n",
    "files_for_gif=[]\n",
    "cbax=fig.add_axes([0.54,0.05,0.4,0.01])\n",
    "fig.colorbar(cm, ax=axes[0,0], cax=cbax, orientation='horizontal')\n",
    "theta=25\n",
    "phi=30\n",
    "ax.plot_surface(Xs, Ys, im.T, rcount=int(len(prof_y)*plot3d_resolution), ccount=int(len(prof_x)*plot3d_resolution), cmap='viridis') # rstride=1, cstride=1, linewidth=0\n",
    "#cset = ax.contourf(X, Y, im, 2, zdir='z', offset=-20, cmap='viridis', alpha=0.5)\n",
    "#cset = ax.contourf(X, Y, im, 1, zdir='x', offset=-8, cmap='viridis')\n",
    "#cset = ax.contourf(X, Y, im, 1, zdir='y', offset=0, cmap='viridis')\n",
    "ax.set_xlabel('Y')\n",
    "#ax.set_xlim(-8, 8)\n",
    "ax.set_ylabel('X')\n",
    "#ax.set_ylim(-10, 8)\n",
    "ax.set_zlabel('Intensity')\n",
    "ax.set_zlim(-0.078*np.max(im), np.max(im))\n",
    "ax.set_title(\"Image intensity 3D plot\")\n",
    "ax.view_init(10, theta)\n",
    "#ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1.3, 1.3, 1.3, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NN predictions for $R_0, w_0, \\phi_{CR}, Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Custom\")\n",
    "model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "print(f\"Predicted phi_CR {predictions[0]} rad {predictions[0]*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {predictions[0]/2} rad {predictions[0]*180/np.pi/2} deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(\"Referencia sin nada\\n\")\n",
    "%matplotlib inline\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day2/laser_gaussian_thesis/All_Taken_Photos/sin_los_dos_solo_tubo.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "ref=predictions[0].item()\n",
    "print(f\"Predicted phi_CR {ref} rad {ref*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {ref/2} rad {ref*180/np.pi/2} deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Referencia sin nada\\n\")\n",
    "%matplotlib inline\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day2/laser_gaussian_thesis/All_Taken_Photos/antes_de_la_estandar.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "ref2=predictions[0].item()\n",
    "print(f\"Predicted phi_CR {ref2} rad {ref2*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {ref2/2} rad {ref2*180/np.pi/2} deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sin el negativo\\n\")\n",
    "%matplotlib inline\n",
    "\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day2/laser_gaussian_thesis/All_Taken_Photos/sin_el_negativo.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "pos=predictions[0].item()\n",
    "print(f\"Predicted phi_CR {pos} rad {pos*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {pos/2} rad {pos*180/np.pi/2} deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sin el positivo\\n\")\n",
    "%matplotlib inline\n",
    "\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day2/laser_gaussian_thesis/All_Taken_Photos/sin_el_positivo.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "neg = predictions[0].item()\n",
    "print(f\"Predicted phi_CR {neg} rad {neg*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {neg/2} rad {neg*180/np.pi/2} deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Con ambos\\n\")\n",
    "%matplotlib inline\n",
    "\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day2/laser_gaussian_thesis/All_Taken_Photos/con_los_dos.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "both=predictions[0].item()\n",
    "print(f\"Predicted phi_CR {both} rad {both*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {both/2} rad {both*180/np.pi/2} deg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ref Ort\\n\")\n",
    "%matplotlib inline\n",
    "\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day3/Reference/Reference__100.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "ref_ort=predictions[0].item()\n",
    "print(f\"Predicted phi_CR {ref_ort} rad {ref_ort*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {ref_ort/2} rad {ref_ort*180/np.pi/2} deg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ref Ort\\n\")\n",
    "%matplotlib inline\n",
    "\n",
    "image_full_path = \"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/Fotos_Turpin/Day3/Problem/90__100.png\"\n",
    "im = cv2.imread(image_full_path, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "im = np.asarray((compute_raw_to_centered_iX(torch.from_numpy(im).unsqueeze(0).to(device))).to('cpu').squeeze(0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#model.eval()\n",
    "predictions = model(torch.from_numpy(im).to(device).unsqueeze(0))[0]\n",
    "ort=predictions[0].item()\n",
    "print(f\"Predicted phi_CR {ref_ort} rad {ort*180/np.pi} deg\")\n",
    "print(f\"\\n\\nPredicted Polarization plane -relative to the image plane w axis- is {ort/2} rad {ort*180/np.pi/2} deg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Positivo-Ref deberian ser {13.85} deg son {-(pos-ref)*180/np.pi/2} deg\")\n",
    "print(f\"Negativo-Ref deberian ser {9.45} deg son {(neg-ref)*180/np.pi/2} deg\")\n",
    "print(f\"Ambos-Ref deberian ser {4.4} deg son {(both-ref)*180/np.pi/2} deg\\n\")\n",
    "\n",
    "print(f\"Positivo-Ref2 deberian ser {13.85} deg son {-(pos-ref2)*180/np.pi/2} deg\")\n",
    "print(f\"Negativo-Ref2 deberian ser {9.45} deg son {(neg-ref2)*180/np.pi/2} deg\")\n",
    "print(f\"Ambos-Ref2 deberian ser {4.4} deg son {(both-ref2)*180/np.pi/2} deg\\n\")\n",
    "\n",
    "print(f\"Ref2-Ref deberian ser {0} deg son {(ref2-ref)*180/np.pi/2} deg\\n\")\n",
    "\n",
    "print(f\"El de noventa deberian ser {90} deg son {(ref_ort-ort)*180/np.pi/2} deg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the non-black-box algorithm estimate for $\\phi_{CR}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"../../..\")\n",
    "import sys\n",
    "from SOURCE.CLASS_CODE_GPU_Classes import *\n",
    "from SOURCE.CLASS_CODE_Image_Manager import *\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm, Gradient_Algorithm\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image=im.copy()\n",
    "saturation=0.9\n",
    "pol_or_CR=\"pol\" \n",
    "deg_or_rad=\"deg\" # for the final output\n",
    "image_depth=8 # or 16 bit per pixel\n",
    "image_shortest_side=540\n",
    "randomization_seed=666\n",
    "recenter_average_image=False\n",
    "\n",
    "\n",
    "# 5. POLARIZATION RELATIVE ANGLES ###################################\n",
    "# Mirror with affine interpolation & Rotation Algorithms will be employed\n",
    "# Each using both Fibonacci and Quadratic Fit Search\n",
    "# Also a gradient algorithm\n",
    "theta_min_Rot=-np.pi\n",
    "theta_max_Rot=np.pi\n",
    "rad_min_Grav=3\n",
    "rad_max_Grav=image_shortest_side\n",
    "theta_min_Mir=0\n",
    "theta_max_Mir=np.pi\n",
    "initial_guess_delta_rad=0.1\n",
    "initial_guess_delta_pix=10\n",
    "use_exact_gravicenter=True\n",
    "precision_quadratic=1e-10\n",
    "max_it_quadratic=100\n",
    "cost_tolerance_quadratic=1e-14\n",
    "precision_fibonacci=1e-10\n",
    "max_points_fibonacci=100\n",
    "cost_tolerance_fibonacci=1e-14\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "im_type=np.uint16 if image_depth==16 else np.uint8\n",
    "max_intensity=65535 if image_depth==16 else 255\n",
    "np.random.seed(randomization_seed)\n",
    "polCR=1 if pol_or_CR=='CR' else 0.5\n",
    "\n",
    "# 6. POLARIZATION RELATIVE ANGLES ###################################\n",
    "# Mirror with affine interpolation & Rotation Algorithms will be employed\n",
    "# Each using both Fibonacci and Quadratic Fit Search\n",
    "# Results will be gathered in a table and outputed as an excel csv\n",
    "# Mock Image Loader\n",
    "# Computar el angulo de cada uno en un dataframe donde una de las entradas sea results y haya un result per fibo qfs y per rotation y mirror affine. Y luego procesar en un 7º paso estos angulos para obtener los angulos relativos etc y perhaps hacer tablucha con ground truth menos el resulting delta angle medido por el algoritmo\n",
    "image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "# Define the ROTATION ALGORITHM\n",
    "rotation_algorithm = Rotation_Algorithm(image_loader,\n",
    "    theta_min_Rot, theta_max_Rot, None,\n",
    "    initial_guess_delta_rad, use_exact_gravicenter, initialize_it=False)\n",
    "\n",
    "# Define the Affine Mirror algorithm\n",
    "mirror_algorithm = Mirror_Flip_Algorithm(image_loader,\n",
    "    theta_min_Mir, theta_max_Mir, None,\n",
    "    initial_guess_delta_rad, method=\"aff\", left_vs_right=True, use_exact_gravicenter=use_exact_gravicenter, initialize_it=False)\n",
    "\n",
    "# Define the Gradient algorithm\n",
    "gradient_algorithm = Gradient_Algorithm(image_loader,\n",
    "        rad_min_Grav, rad_max_Grav,\n",
    "        initial_guess_delta_pix,\n",
    "        use_exact_gravicenter)\n",
    "\n",
    "# A dictionary to gather all the resulting angles for each image\n",
    "\n",
    "individual_image_results = { 'polarization_method':[], 'optimization_1d':[], 'found_phiCR':[], 'predicted_opt_precision':[] }\n",
    "\n",
    "def to_result_dict(result_dict, alg, alg_name, opt_name, im_names):\n",
    "    for key, name in zip(alg.times.keys(), im_names):\n",
    "        result_dict['polarization_method'].append(alg_name)\n",
    "        result_dict['optimization_1d'].append(opt_name)\n",
    "        result_dict['found_phiCR'].append(alg.angles[key])\n",
    "        result_dict['predicted_opt_precision'].append(alg.precisions[key])\n",
    "image_container=np.zeros( (1, 2*X+1, 2*X+1), dtype=np.float64)\n",
    "image_names=[]\n",
    "# charge the image\n",
    "image_container[0]=image.astype(np.float64)\n",
    "image_names.append(f\"{fc.selected_filename}\")\n",
    "\n",
    "# charge the image loader:\n",
    "image_loader.import_converted_images_as_array(image_container, image_names)\n",
    "# Execute the Rotation and Mirror Algorithms:\n",
    "# ROTATION ######\n",
    "interpolation_flag=None\n",
    "# the interpolation algorithm used in case we disbale its usage for the iX image obtention will be the Lanczos one\n",
    "rotation_algorithm.interpolation_flag=interpolation_flag if interpolation_flag is not None else cv2.INTER_CUBIC\n",
    "rotation_algorithm.reInitialize(image_loader)\n",
    "rotation_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Rotation\", \"Quadratic\", image_names)\n",
    "rotation_algorithm.reInitialize(image_loader)\n",
    "rotation_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Rotation\", \"Fibonacci\", image_names)\n",
    "\n",
    "# MIRROR #######\n",
    "mirror_algorithm.interpolation_flag=interpolation_flag if interpolation_flag is not None else cv2.INTER_CUBIC\n",
    "mirror_algorithm.reInitialize(image_loader)\n",
    "mirror_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Mirror\", \"Quadratic\", image_names)\n",
    "mirror_algorithm.reInitialize(image_loader)\n",
    "mirror_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "to_result_dict( individual_image_results, rotation_algorithm, \"Mirror\", \"Fibonacci\", image_names)\n",
    "\n",
    "# GRADIENT #######\n",
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "optimal_masked_gravs={}\n",
    "optimal_radii={}\n",
    "grav=compute_intensity_gravity_center(image)\n",
    "\n",
    "gradient_algorithm.interpolation_flag=interpolation_flag if interpolation_flag is not None else cv2.INTER_CUBIC\n",
    "gradient_algorithm.reInitialize(image_loader)\n",
    "gradient_algorithm.quadratic_fit_search(precision_quadratic, max_it_quadratic, cost_tolerance_quadratic)\n",
    "to_result_dict( individual_image_results, gradient_algorithm, \"Gradient\", \"Quadratic\", image_names)\n",
    "#optimal_masked_gravs['quad'] = gradient_algorithm.masked_gravs[f\"Quadratic_Search_{fc.selected_filename}\"]\n",
    "#optimal_radii['quad'] = gradient_algorithm.optimals[f\"Quadratic_Search_{fc.selected_filename}\"]\n",
    "\n",
    "gradient_algorithm.reInitialize(image_loader)\n",
    "gradient_algorithm.fibonacci_ratio_search(precision_fibonacci, max_points_fibonacci, cost_tolerance_fibonacci)\n",
    "to_result_dict( individual_image_results, gradient_algorithm, \"Gradient\", \"Fibonacci\", image_names)\n",
    "\n",
    "#optimal_masked_gravs['fibo'] = gradient_algorithm.masked_gravs[f\"Fibonacci_Search_{fc.selected_filename}\"]\n",
    "#optimal_radii['fibo'] = gradient_algorithm.optimals[f\"Fibonacci_Search_{fc.selected_filename}\"]\n",
    "\n",
    "#masked_grav=(optimal_masked_gravs['quad']+optimal_masked_gravs['fibo'])/2.0\n",
    "#optimal_radi = (optimal_radii['quad']+optimal_radii['fibo'])/2\n",
    "#print(f\"\\n\\nOptimal masked gravs: {optimal_masked_gravs}\\nOptimal radii: {optimal_radii}\\n\\n\\n\")\n",
    "print(pd.DataFrame.from_dict(individual_image_results))\n",
    "\n",
    "# 7. PROCESS FINAL RESULTS ##########################################\n",
    "def angle_to_pi_pi( angle): # convert any angle to range ()-pi,pi]\n",
    "    angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\n",
    "    return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle    \n",
    "\n",
    "average_found_phiCR=np.mean([angle_to_pi_pi(phi) for i,phi in enumerate(individual_image_results['found_phiCR']) if individual_image_results['polarization_method'][i]!='Gradient'])\n",
    "print(\"Average found phiCR:\", average_found_phiCR)\n",
    "#print(f\"\\n\\nPredicted slope for main axis: by Gradient {(masked_grav[0]-grav[0])/(masked_grav[1]-grav[1])} and by the others averaged {np.tan(-average_found_phiCR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "    x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]) # [batch_size, 1, 2X+1, 2X+1]\n",
    "    X=302\n",
    "    feats_1=15\n",
    "    feats_2=20\n",
    "    feats_3=20\n",
    "    feats_4=20\n",
    "    prop1=3\n",
    "    prop2=2\n",
    "    prop3=1\n",
    "    av_pool1_div=4\n",
    "    conv4_feat_size=15\n",
    "    av_pool2_div=10\n",
    "    out_fc_1=10 \n",
    "    print(x.shape, 2*X+1)\n",
    "\n",
    "    x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "    print(\"conv1\",x.shape, prop1*(2*X+1)/5)\n",
    "\n",
    "\n",
    "    x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "    print(\"conv2\",x.shape,  prop2*(2*X+1)/5)\n",
    "\n",
    "\n",
    "    x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "    print(\"conv3\",x.shape,  prop3*(2*X+1)/5)\n",
    "\n",
    "\n",
    "    x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "    print(\"av_pool1\",x.shape, int((prop3*(2*X+1)/5)/av_pool1_div))\n",
    "\n",
    "\n",
    "    x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "    print(\"conv4+batchn\",x.shape, conv4_feat_size)\n",
    "\n",
    "\n",
    "    x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "    print(\"av_pool2\",x.shape, int(conv4_feat_size/av_pool2_div)+1)\n",
    "\n",
    "\n",
    "    x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "    print(\"view_change\",x.shape, feats_4*int(conv4_feat_size/av_pool2_div+1)**2)\n",
    "\n",
    "\n",
    "    x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, 4]\n",
    "    print(x.shape, 4)\n",
    "\n",
    "        return x\n",
    "a = Simple_Encoder().to(device)\n",
    "a(torch.ones(2,1, 605,605).to(device))\n",
    "del a\n",
    "torch.cuda.empty_cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crazy_epoch(epoch, criterion, model, optimizer, datas, targets, batch_number, batch_size,\n",
    "                      print_loss_every_batches=20,\n",
    "                    optimizer_step_every_batches=1):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    t2 = time()\n",
    "    for k in range(batch_number):        \n",
    "        \n",
    "        prediction = model(datas[k*batch_size:(k+1)*batch_size]) # data is [batch_size, 1, 2X+1, 2X+1]\n",
    "        loss = criterion(prediction, targets[k*batch_size:(k+1)*batch_size])\n",
    "        loss.backward()\n",
    "        \n",
    "        if k % optimizer_step_every_batches==optimizer_step_every_batches-1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # print loss every N batches\n",
    "        if k % print_loss_every_batches == print_loss_every_batches-1:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (k+1) * batch_size, len(datas),\n",
    "                100*(k+1)*batch_size / len(datas), loss.item()))\n",
    "\n",
    "        #total_loss += loss.item()  #.item() is very important here\n",
    "        # Why?-> In order to avoid having total_loss as a tensor in the gpu\n",
    "        t1= time()\n",
    "        print(f\"Iteration time{t1-t2}\")\n",
    "        t2 = time()\n",
    "\n",
    "    return total_loss / len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_crazy_training_loop(model, criterion, optimizer_generator, train_loader,\n",
    "                             batch_number, batch_size, epochs=10,\n",
    "                       print_loss_every_batches=20, optimizer_step_every_batches=1,\n",
    "                            meta_epoch_number=1):\n",
    "    %matplotlib inline\n",
    "    for meta_epoch in range(meta_epoch_number):\n",
    "        for meta_batch_id, (datas, targets) in enumerate(train_loader):        \n",
    "            datas, targets = datas.to(device), targets.to(device) # pero muuh gordos\n",
    "            losses = {\"train\": []}\n",
    "            optimizer = optimizer_generator(model)\n",
    "            for epoch in range(epochs): # que overfitee el muuh gordo este\n",
    "                train_loss = train_crazy_epoch(epoch, criterion, model, optimizer, datas,\n",
    "                                         targets, batch_number, batch_size,\n",
    "                                          print_loss_every_batches=20,\n",
    "                                            optimizer_step_every_batches=1)\n",
    "\n",
    "                display_IPython.clear_output(wait=True)\n",
    "                losses[\"train\"].append(train_loss)\n",
    "                plt.plot(losses[\"train\"], label=f\"log training loss- MetaBatch {meta_batch_id/len(train_loader)*100}%\")\n",
    "                plt.yscale('log')\n",
    "                plt.legend()\n",
    "                plt.pause(0.001)\n",
    "                plt.show()   \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_epoch_number = 1\n",
    "meta_batch_size = 100\n",
    "batch_size = 10\n",
    "batch_number = int(meta_batch_size/batch_size)\n",
    "assert(meta_batch_size%batch_size==0)\n",
    "\n",
    "crazy_loader = DataLoader(training_data, batch_size=meta_batch_size, shuffle=True, num_workers=worker_num,\n",
    "                              pin_memory=True, drop_last=False, persistent_workers=False)\n",
    "\n",
    "def adam_generator(model):\n",
    "    return torch.optim.Adam(model.parameters(), lr=0.05, betas=(0.99, 0.9999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "full_crazy_training_loop(model, criterion, \n",
    "                         adam_generator, \n",
    "                         crazy_loader,\n",
    "                             batch_number, batch_size, epochs=10,\n",
    "                       print_loss_every_batches=10, optimizer_step_every_batches=2, \n",
    "                         meta_epoch_number=meta_epoch_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time()\n",
    "for datas, targets in train_dataloader:\n",
    "    datas, targets = datas.to(device), targets.to(device)\n",
    "    pred = model(datas)\n",
    "    t2=time()\n",
    "    print(f\"inf time {t2-t1}\")\n",
    "    loss = criterion(pred, targets)\n",
    "    loss.backward()\n",
    "    t3=time()\n",
    "    print(f\"with backward {t3-t1}\")\n",
    "    t1=time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
