{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- histograms kopixe\n",
    "- estaditik metrikek komputetie kopixe beridñetik ta inklusibe excela generetie ni tan mal\n",
    "- probeu dauzen hirurekaz. Ein depuraziñoa simualtion algirthmeri eta pipelineri en general\n",
    "- Implementu nire ideia illuminado bicek/hirurek\n",
    "- ein similarity metrike al izetie aukeratu en el simualtor\n",
    "- plantieu 3.600 imagen puroren kordenatuek eukitzie en plan library eta komputetie en el embedding space euren koordenadak\n",
    "de forma ke solo sea computar embedding space de la img problema y ver la media de los dos o tres más cercanos edo\n",
    "Esto será un método adicional por supuesto.\n",
    "- Probeu berdiñe con lo del UMAP embedder no?\n",
    "- Ein pipeline bien de bien de gordo gordo eta jarri Melanie indar betean\n",
    "Ein pipeline bat detail guztixekaz en el expeirmental image nano-dataset\n",
    "Ein pipeline bat bakarrik detail estadistikoak batzeko pero de bien de mazo de noisy images. Pa eso\n",
    "haz que se vayan entrando en chunks o algo ze ostantzie va a petar jajaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE TO COMPARE ALGORITHMS\n",
    "---\n",
    "---\n",
    "\n",
    "    def alg tal (image_refs, image_pbs, save_output_plots_path=None):\n",
    "        ...\n",
    "        return predicted_delta_phiCRs, times (de cada pairwise image pair ref pb -que están en los mismos indices claro)\n",
    "\n",
    "Ke guarde los plots ke se outputean si hace falta en ese path dado.\n",
    "\n",
    "Ta gero funkiño bat que coja algs, que coja image pairs y si acaso coja sus ground-truths como opctional argument, y que te outputee la tabla de imagen, algoritmos delta phicR, delta pol, times, GT, absolute errors.\n",
    "\n",
    "Ta gero bebai outputee pa cada algoritmo un histograma de los absolute errors y un histograma de tiempos, con las medias y percentiles indicados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melanie/anaconda3/envs/fbvars/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/melanie/anaconda3/envs/fbvars/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm\n",
    "from SOURCE.CLASS_CODE_Image_Manager import Image_Manager\n",
    "from SOURCE.CLASS_CODE_Ad_Hoc_Optimizer import Ad_Hoc_Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "def angle_to_pi_pi( angle): # convert any angle to range (-pi,pi]\\n\",\n",
    "    angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\\n\",\n",
    "    return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle\n",
    "\n",
    "def run_benchmark_output_result_histograms_and_result_table( algorithm_lambda_list, algorithm_name_list,\n",
    "                                            references, problems, image_pair_names,\n",
    "                                            output_units='rad', ground_truths=None, GT_units=None,\n",
    "                                            GT_nature = 'phiCR',\n",
    "                                            experiment_name = None, output_path=None):\n",
    "    # GTs should be in [-pi, pi] or [-180, 180]\n",
    "    times = {}\n",
    "    predicted_delta_phiCRs = {}\n",
    "    conv = 180/np.pi if output_units=='deg' else 1\n",
    "    convGT = 180/np.pi if (output_units=='deg' and GT_units=='rad') else \\\n",
    "        np.pi/180 if (output_units=='rad' and GT_units=='deg') else 1\n",
    "    \n",
    "    for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "        if output_path is not None:\n",
    "            dir_for_alg = output_path+f\"/{alg_name}/\"\n",
    "            os.makedirs( dir_for_alg, exist_ok=True )\n",
    "        else:\n",
    "            dir_for_alg = None\n",
    "        predicted_delta_phiCRs[alg_name], times[alg_name] = algorithm(references, problems, dir_for_alg)\n",
    "        \n",
    "    json.dump({'image_pair_names':image_pair_names, 'predicted_delta_phiCRs':predicted_delta_phiCRs,\n",
    "              'times':times}, open( f\"{output_path}/RAW_results.json\", \"w\"))\n",
    "    # Rearrange the result to our desired Table and unit formats\n",
    "    image_ids = []\n",
    "    image_names = []\n",
    "    algorithm_names = []\n",
    "    delta_phiCRs = []\n",
    "    delta_pols = []\n",
    "    timess = []\n",
    "    GTs = []\n",
    "    abs_errors = []\n",
    "    correct_decimals = []\n",
    "    \n",
    "    for idx, image_pair_name in enumerate(image_pair_names):\n",
    "        image_ids.append(idx)\n",
    "        image_names.append(idx)\n",
    "        delta_phiCRs.append(idx)\n",
    "        for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "            algorithm_names.append(alg_name)\n",
    "            delta_phiCRs.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][idx]) ) \n",
    "            delta_pols.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][idx])/2.0 )\n",
    "            times.append(times[alg_name][idx])\n",
    "            if ground_truths is not None:\n",
    "                GTs.append(convGT*ground_truths[idx])\n",
    "                if GT_nature=='phiCR':\n",
    "                    abs_errors.append( np.abs(delta_phiCRs[-1]-convGT*ground_truths[idx]) )\n",
    "                else: # then GT is of polarization\n",
    "                    abs_errors.append( np.abs(delta_pols[-1]-convGT*ground_truths[idx]) )\n",
    "                correct_decimals.append() # beittu HISTOGRAMAGAZ batera zelan eitten zendun hau!\n",
    "    table_per_image = pd.DataFrame.from_dict({'ID':image_ids, 'Image_Pair_Name':image_names, 'Algorithm':algorithm_names,\n",
    "                                   'Predicted_Delta_PhiCRs':delta_phiCRs, 'Pred_Delta_Polarizt':delta_pols,\n",
    "                                   'Times':timess, f'Ground_Truth_{GT_nature}':GTs, 'Absolute Error':abs_errors})\n",
    "            \n",
    "    # table_per_alg = # cuando copies el bootstrap para hacer els histograms ba kompleteu tabla hau\n",
    "    # en prkipi deberia tener cols alg name, sample mean abs error, sample abs error stdv, sample abs error CI bootstrap\n",
    "    # Y unos percentiles de los abs errors. Kiza lo mismo tb en términos de decimales correctos? Sí a cuanto porciento\n",
    "    # de los samples se hizo con tantos decimales correctos, cuantos con tantos etc.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    return centered_image\n",
    "\n",
    "\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=self.device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=self.device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(self.device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX(images,  saturation_threshold, dtype=np.float32,\n",
    "                              iX_dev='cpu', out_dev='cpu', X=302): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX(images,  saturation_threshold, dtype=np.float32,\n",
    "                                     iX_dev='cpu', out_dev='cpu', X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX(images,  saturation_threshold, dtype=np.float32,\n",
    "                                      iX_dev='cpu', out_dev='cpu', X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    means = np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_max_and_iX(images, dtype=np.float32,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=302): # images expected to be [N_images, h, w]\n",
    "    images= images.astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_and_iX(images, dtype=np.float32,\n",
    "                     iX_dev='cpu', out_dev='cpu', X=302): # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=troch.float32, X=302): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=troch.float32, X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=troch.float32, X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    means=torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_max_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=troch.float32, X=302): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=troch.float32, X=302): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/torch.mean(images, axis=(-1,-2), keepdims=True), X, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) ROTATION ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_alg_kw_args = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.4, \n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC}\n",
    "rotation_fibo_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "rotation_quad_kw_args = {'precision_fibonacci':1e-10, 'max_it_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "\n",
    "rotation_preprocess_fct = lambda(images):  normalize_to_mean_and_iX(images)\n",
    "\n",
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_rotation_algorithm(references, problems, image_pair_names, preprocess_fct, search_algorithm, \n",
    "                       search_alg_kw_args, rotation_alg_kw_args, out_plot_path=None, rotation_algorithm=None):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "    if rotation_algorithm is None:\n",
    "        rotation_algorithm = Rotation_Algorithm(image_loader,\n",
    "            rotation_alg_kw_args['theta_min_Rot'], rotation_alg_kw_args['theta_max_Rot'], None,\n",
    "            rotation_alg_kw_args['initial_guess_delta_rad'], rotation_alg_kw_args['use_exact_gravicenter'], \n",
    "                                                initialize_it=False)\n",
    "    image_names = []\n",
    "    for mode in ['Ref', 'Pb']:\n",
    "        for image_pair_name in image_pair_names:\n",
    "            image_names.append(f\"{mode}__{image_pair_name}\")\n",
    "    # charge the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "    image_loader.import_converted_images_as_array(images, image_names)\n",
    "    # Execute the Rotation Algorithm:\n",
    "    rotation_algorithm.interpolation_flag=rotation_alg_kw_args['interpolation_flag']\n",
    "    rotation_algorithm.reInitialize(image_loader)\n",
    "    # run it\n",
    "    if search_algorithm=='quadratic':\n",
    "        rotation_algorithm.quadratic_fit_search(search_alg_kw_args['precision_quadratic'], \n",
    "                            search_alg_kw_args['max_it_quadratic'], search_alg_kw_args['cost_tolerance_quadratic'])\n",
    "    else: # 'fibo'\n",
    "        rotation_algorithm.fibonacci_ratio_search(search_alg_kw_args['precision_fibonacci'],\n",
    "                    search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])    \n",
    "    \n",
    "    if out_plot_path is not None:\n",
    "        rotation_algorithm.save_result_plots_fibonacci_or_quadratic(out_plot_path)\n",
    "    \n",
    "    for i in range(len(image_pair_names)):\n",
    "        predicted_deltaPhiCRs.append( \n",
    "            rotation_algorithm.angles.values()[i+len(image_pair_names)] - \\\n",
    "                                      rotation_algorithm.angles.values()[i] ) # pb - ref\n",
    "        times.append( rotation_algorithm.times.values()[i+len(image_pair_names)] + \\\n",
    "                                      rotation_algorithm.times.values()[i])\n",
    "    \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) MIRROR FLIP ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror_alg_kw_args = {'theta_min_Mir':0, 'theta_max_Mir':np.pi, 'initial_guess_delta_rad':0.4, \n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC}\n",
    "mirror_fibo_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "mirror_quad_kw_args = {'precision_fibonacci':1e-10, 'max_it_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "\n",
    "mirror_preprocess_fct = lambda images: normalize_to_mean_and_iX(images)\n",
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_mirror_flip_algorithm(references, problems, image_pair_names, preprocess_fct, search_algorithm, \n",
    "                       search_alg_kw_args, mirror_alg_kw_args, out_plot_path=None, mirror_algorithm=None):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "    if mirror_algorithm is None:\n",
    "        mirror_algorithm = Mirror_Flip_Algorithm(image_loader,\n",
    "            mirror_alg_kw_args['theta_min_Mir'], mirror_alg_kw_args['theta_max_Mir'], None,\n",
    "            mirror_alg_kw_args['initial_guess_delta_rad'], method=\"aff\", left_vs_right=True, \n",
    "            use_exact_gravicenter=mirror_alg_kw_args['use_exact_gravicenter'], initialize_it=False)\n",
    "\n",
    "    image_names = []\n",
    "    for mode in ['Ref', 'Pb']:\n",
    "        for image_pair_name in image_pair_names:\n",
    "            image_names.append(f\"{mode}__{image_pair_name}\")\n",
    "    # charge the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "    image_loader.import_converted_images_as_array(images, image_names)\n",
    "    # Execute the Rotation Algorithm:\n",
    "    mirror_algorithm.interpolation_flag=mirror_alg_kw_args['interpolation_flag']\n",
    "    mirror_algorithm.reInitialize(image_loader)\n",
    "    # run it\n",
    "    if search_algorithm=='quadratic':\n",
    "        mirror_algorithm.quadratic_fit_search(search_alg_kw_args['precision_quadratic'], \n",
    "                            search_alg_kw_args['max_it_quadratic'], search_alg_kw_args['cost_tolerance_quadratic'])\n",
    "    else: # 'fibo'\n",
    "        mirror_algorithm.fibonacci_ratio_search(search_alg_kw_args['precision_fibonacci'],\n",
    "                    search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])    \n",
    "    \n",
    "    if out_plot_path is not None:\n",
    "        mirror_algorithm.save_result_plots_fibonacci_or_quadratic(out_plot_path)\n",
    "    \n",
    "    for i in range(len(image_pair_names)):\n",
    "        predicted_deltaPhiCRs.append( \n",
    "            mirror_algorithm.angles.values()[i+len(image_pair_names)] - \\\n",
    "                                      mirror_algorithm.angles.values()[i] ) # pb - ref\n",
    "        times.append( mirror_algorithm.times.values()[i+len(image_pair_names)] + \\\n",
    "                                      mirror_algorithm.times.values()[i])\n",
    "    \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (C) Simulation Coordinate Descent using h5f library of D matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation_precomputed_R0_w0_Z_Dmatrices_optimize_phiCR():\n",
    "    def __init__(self,  ID_file_path, D_matrix_file_path, device, coordinate_descent_cycles,\n",
    "                 min_angle, max_angle, initial_guess_delta_rad, initial_guess_delta_R0,ñ\n",
    "                 preprocess_fct, similarity, R0_init_guess, w0_init_guess, Z_init_guess):\n",
    "        import json\n",
    "        self.D_matrix_file_path = D_matrix_file_path\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(ID_file_path)))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.R0s_ar = np.array(self.R0s, dtype=np.float64) # Convert them to float arrays\n",
    "        self.w0s_ar = np.array(self.w0s, dtype=np.float64)\n",
    "        self.Zs_ar = np.array(self.Z0s, dtype=np.float64)\n",
    "        self.device = device\n",
    "        if not hasattr(self, 'h5f_D_matrices'): # this was originally thought for multiprocess child threads to have the chance each to have an open copy of the hdf5 (which should be opened in the first iteration of the parallelized get, not here in the init, but well...)\n",
    "            self.open_hdf5()\n",
    "            self.phis = torch.from_numpy(self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(self.device) #[1,Nx,Ny]\n",
    "\n",
    "        # search function params?\n",
    "        self.cycles=coordinate_descent_cycles\n",
    "        self.min_Z=min(self.Zs)\n",
    "        self.max_Z=max(self.Zs)\n",
    "        self.min_phi=min_angle\n",
    "        self.max_phi=max_angle\n",
    "        self.min_radi=min(self.R0s)\n",
    "        self.max_radi=max(self.R0s)\n",
    "        self.min_w0=min(self.w0s)\n",
    "        self.max_w0=max(self.w0s)\n",
    "        self.initial_guess_delta_rad=initial_guess_delta_rad\n",
    "        self.initial_guess_delta_R0=initial_guess_delta_R0\n",
    "        \n",
    "        self.R0_precision=abs(self.R0s[1]-self.R0s[0])\n",
    "        self.w0_precision=abs(self.w0s[1]-self.w0s[0])\n",
    "        self.Z_precision=abs(self.Zs[1]-self.Zs[0])\n",
    "        # pa phiCR no porke es unbounded!\n",
    "        self.optimizer = Ad_Hoc_Optimizer(min_angle, max_angle, initial_guess_delta, self.evaluate_image_closest_angle)\n",
    "        self.choose_similarity_alg(similarity)\n",
    "        \n",
    "        self.times={}\n",
    "        self.radious_points={}\n",
    "        self.w0_points={}\n",
    "        self.Z_points={}\n",
    "        self.phi_points={}\n",
    "        # use the results from the gradient algorithm to initialize the best triplet?\n",
    "        self.R0_pix_best={}\n",
    "        self.w0_best={}\n",
    "        self.Z_best={}\n",
    "        self.phi_CR_best={}\n",
    "        self.last_cycle=coordinate_descent_cycles\n",
    "\n",
    "        self.best_radii={}\n",
    "        self.best_w0s={}\n",
    "        self.best_zs={}\n",
    "        self.best_angles={}\n",
    "        self.simulations_required={}\n",
    "        \n",
    "        self.similarity=similarity # the similarity metric to use as the objective function\n",
    "        self.preprocess_fct = preprocess_fct\n",
    "        self.last_R0=None\n",
    "        self.last_w0=None\n",
    "        self.last_Z=None\n",
    "        \n",
    "        self.R0_init_guess =R0_init_guess\n",
    "        self.w0_init_guess = w0_init_guess\n",
    "        self.Z_init_guess = Z_init_guess\n",
    "        \n",
    "        image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "        self.algorithm_M = Mirror_Flip_Algorithm(image_loader,\n",
    "            mirror_alg_kw_args['theta_min_Mir'], mirror_alg_kw_args['theta_max_Mir'], None,\n",
    "            mirror_alg_kw_args['initial_guess_delta_rad'], method=\"aff\", left_vs_right=True, \n",
    "            use_exact_gravicenter=mirror_alg_kw_args['use_exact_gravicenter'], initialize_it=False)\n",
    "        \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'h5f_D_matrices'):\n",
    "            self.h5f_D_matrices.close()\n",
    "            \n",
    "    def open_hdf5(self):\n",
    "        self.h5f_D_matrices = h5py.File( self.D_matrix_file_path, 'r')\n",
    "        #self.dataset = self.img_hdf5['dataset'] # if you want dataset.\n",
    "\n",
    "    def angle_to_pi_pi(self, angle): # convert any angle to range ()-pi,pi]\n",
    "        angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\n",
    "        return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle\n",
    "        \n",
    "    def closest_idx_in_ar(self, value, list_array):\n",
    "        return (np.abs(list_array-value)).argmin()\n",
    "        \n",
    "    def get_simulated_image(self, R0, w0, Z, phiCR):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[\n",
    "                f\"R0_{self.closest_idx_in_ar(R0, self.R0s_ar)}_w0_{self.closest_idx_in_ar(w0, self.w0s_ar)}_Z_{self.closest_idx_in_ar(Z0, self.Z0s)}\"][:]\n",
    "                                 ).unsqueeze(1).to(self.device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.FloatTensor(self.angle_to_pi_pi(phiCR)).to(self.device) #[num_phiCR, 1, 1]\n",
    "        images = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        return self.preprocess_fct(images, in_are_dev_float=True, device=self.device)\n",
    "\n",
    "    def choose_similarity_alg(self, similarity):\n",
    "        if similarity == 'mse': # mean square error\n",
    "            self.similarity_func = lambda im1, im2: torch.sum(torch.square(im1-im2))\n",
    "        elif similarity == 'mae': # mean absolute error\n",
    "            self.similarity_func = lambda im1, im2: torch.sum(np.abs(im1-im2))\n",
    "        # NOT TORCHIZISED!\n",
    "        elif similarity == 'ssim':\n",
    "            self.similarity_func = lambda im1, im2: -ism.ssim(im1, im2)\n",
    "        elif similarity == 'fsim':\n",
    "            self.similarity_func = lambda im1, im2: -ism.fsim(np.expand_dims(im1,2), np.expand_dims(im2,2))\n",
    "        elif similarity == 'issm':\n",
    "            self.similarity_func = lambda im1, im2: ism.issm(im1, im2)\n",
    "        elif similarity == 'sre':\n",
    "            self.similarity_func = lambda im1, im2: -ism.sre(np.expand_dims(im1,2), np.expand_dims(im2,2))\n",
    "        elif similarity == 'sam':\n",
    "            self.similarity_func = lambda im1, im2: -ism.sam(np.expand_dims(im1,2), np.expand_dims(im2,2))\n",
    "        elif similarity == 'uiq':\n",
    "            self.similarity_func = lambda im1, im2: -ism.uiq(np.expand_dims(im1,2), np.expand_dims(im2,2))\n",
    "        # ADD DL trained Similarity Metric!\n",
    "\n",
    "        \n",
    "    def reInitialize_and_input_images(self, images, images_names,\n",
    "                     preprocess_fct=None, coordinate_descent_cycles=None, similarity=None,\n",
    "                    R0_init_guess, w0_init_guess, Z_init_guess):       \n",
    "        self.images = self.preprocess_fct(images, in_are_dev_float=False, device=self.device)\n",
    "        self.image_names = image_names\n",
    "        self.times={}\n",
    "        self.radious_points={}\n",
    "        self.w0_points={}\n",
    "        self.Z_points={}\n",
    "        self.phi_points={}\n",
    "        self.R0_pix_best={}\n",
    "        self.w0_best={}\n",
    "        self.Z_best={}\n",
    "        self.phi_CR_best={}\n",
    "        self.last_cycle=coordinate_descent_cycles\n",
    "\n",
    "        self.best_radii={}\n",
    "        self.best_w0s={}\n",
    "        self.best_zs={}\n",
    "        self.best_angles={}\n",
    "        self.simulations_required={}\n",
    "        \n",
    "        self.last_R0=None\n",
    "        self.last_w0=None\n",
    "        self.last_Z=None\n",
    "\n",
    "        image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "        self.image_loader_for_M.import_converted_images_as_array( self.images.to('cpu').numpy(), self.image_names )\n",
    "        self.algorithm_M.reInitialize(image_loader_for_M)\n",
    "        \n",
    "        if similarity is not None:\n",
    "            self.similarity=similarity\n",
    "            self.choose_similarity_alg(similarity)\n",
    "        if preprocess_fct is not None:\n",
    "            self.preprocess_fct = preprocess_fct\n",
    "        if coordinate_descent_cycles is not None:\n",
    "            self.cycles=coordinate_descent_cycles\n",
    "        if R0_init_guess is not None:\n",
    "            self.R0_init_guess = R0_init_guess\n",
    "        if w0_init_guess is not None:\n",
    "            self.w0_init_guess = w0_init_guess\n",
    "        if Z_init_guess is not None:\n",
    "            self.Z_init_guess = Z_init_guess\n",
    "\n",
    "    def evaluate_simulation_phi(self, exp_image, angle, R0_best, Z_best, w0_best): # exp im expected to be [1,h,w]\n",
    "        return self.similarity(exp_image, self.get_simulated_image(R0_best, w0_best, Z_best, phiCR))\n",
    "\n",
    "    def evaluate_simulation_R0(self, exp_image, R0, angle_best, Z_best, w0_best):\n",
    "        return self.similarity(exp_image, self.get_simulated_image(R0, w0_best, Z_best, angle_best))\n",
    "\n",
    "\n",
    "    def evaluate_simulation_Z(self, exp_image, Z, angle_best, R0_best, w0_best):\n",
    "        return self.similarity(exp_image, self.get_simulated_image(R0_best, w0_best, Z, angle_best))\n",
    "\n",
    "\n",
    "    def evaluate_simulation_w0(self, exp_image, w0, angle_best, R0_best, Z_best):\n",
    "        return self.similarity(exp_image, self.get_simulated_image(R0_best, w0, Z_best, angle_best))\n",
    "\n",
    "\n",
    "    def fibonacci_ratio_search(self, precision_pix, maximum_points_R0, precision_phi,\n",
    "        maximum_points_phi, precision_Z, maximum_points_Z,  precision_w0, maximum_points_w0, cost_tol,\n",
    "        precision_M, maximum_points_M, cost_tol_M):\n",
    "        # We first find an estimation for phiCR using the mirror flip algorithm\n",
    "        self.algorithm_M.fibonacci_ratio_search(precision_M, maximum_points_M, cost_tol_M)\n",
    "        \n",
    "        # We now execute a sequence of linear optimizations for each coordinate for every cycle and image\n",
    "        for im, name in enumerate(self.image_names):\n",
    "            self.times[name]={}\n",
    "            self.radious_points[name]={}\n",
    "            self.Z_points[name]={}\n",
    "            self.w0_points[name]={}\n",
    "            self.phi_points[name]={}\n",
    "            # use the results from the gradient algorithm to initialize the best triplet\n",
    "            #self.R0_pix_best[name]=[1.65*abs(self.algorithm_G.optimals[f'Fibonacci_Search_{name}'])]\n",
    "            self.R0_pix_best[name]=[self.R0_init_guess]\n",
    "            self.Z_best[name]=[self.Z_init_guess]\n",
    "            self.w0_best[name]=[self.w0_init_guess]\n",
    "            # Initialize the phiCR with the result from the mirror flip agorithm\n",
    "            self.phi_CR_best[name]=[self.algorithm_M.angles[f'Fibonacci_Search_{name}']]\n",
    "            simulations=0\n",
    "            for cycle in range(self.cycles):\n",
    "                # Optimize Radious magnitude - the width of the croissant\n",
    "                (time_w0, self.w0_points[name][cycle], w0_best, w0_optimum,\n",
    "                 _)=self.w0_optimizer.fibonacci_ratio_search(\n",
    "                    precision_w0, maximum_points_w0, cost_tol,\n",
    "                    self.images_normFloat[im],\n",
    "                    (self.phi_CR_best[name][-1], self.R0_pix_best[name][-1], self.Z_best[name][-1]), self.w0_best[name][-1]\n",
    "                )\n",
    "\n",
    "                # Optimize Radious\n",
    "                (time_rad, self.radious_points[name][cycle], R0_pix_best, radi_optimum,\n",
    "                 _)=self.radious_optimizer.fibonacci_ratio_search(\n",
    "                    precision_pix, maximum_points_R0, cost_tol,\n",
    "                    self.images[im],\n",
    "                    (self.phi_CR_best[name][-1], self.Z_best[name][-1], w0_best), self.R0_pix_best[name][-1]\n",
    "                )\n",
    "\n",
    "                # Optimize Angle\n",
    "                (time_ang, self.phi_points[name][cycle], phi_CR_best, phi_optimum, _)=self.angle_optimizer.fibonacci_ratio_search(\n",
    "                    precision_phi, maximum_points_phi, cost_tol,\n",
    "                    self.images[im],\n",
    "                    (R0_pix_best, self.Z_best[name][-1], w0_best), self.phi_CR_best[name][-1]\n",
    "                )\n",
    "\n",
    "                # Optimize Z\n",
    "                if maximum_points_Z!=0:\n",
    "                    self.Z_optimizer.a=-2*np.sqrt(1/3)*w0_best\n",
    "                    self.Z_optimizer.b=-self.Z_optimizer.a\n",
    "                    (time_Z, self.Z_points[name][cycle], Z_best, Z_optimum,\n",
    "                        _)=self.Z_optimizer.fibonacci_ratio_search(\n",
    "                            precision_Z, maximum_points_Z, cost_tol,\n",
    "                            self.images[im],\n",
    "                            (phi_CR_best, R0_pix_best, w0_best), self.Z_best[name][-1]\n",
    "                        )\n",
    "                else: # dont optimize z\n",
    "                    time_Z=0\n",
    "                    Z_best=0\n",
    "                    Z_optimum=0\n",
    "                    self.Z_points[name][cycle]=np.array([[0,0,0]])\n",
    "\n",
    "\n",
    "                self.times[name][cycle]=time_rad+time_ang+time_Z+time_w0\n",
    "                self.R0_pix_best[name].append(R0_pix_best)\n",
    "                self.phi_CR_best[name].append(phi_CR_best)\n",
    "                self.w0_best[name].append(w0_best)\n",
    "                self.Z_best[name].append(Z_best)\n",
    "\n",
    "                simulations+=len(self.phi_points[name][cycle])+len(self.radious_points[name][cycle])+len(self.Z_points[name][cycle])+len(self.w0_points[name][cycle])\n",
    "\n",
    "                # check if convergence criterion is met\n",
    "                if((abs(Z_optimum-phi_optimum)<cost_tol and\n",
    "                        abs(phi_optimum-radi_optimum)<cost_tol and\n",
    "                            abs(radi_optimum-w0_optimum)<cost_tol)\n",
    "                        or (abs(self.R0_pix_best[name][-2]-R0_pix_best)<precision_pix and\n",
    "                        abs(self.phi_CR_best[name][-2]-phi_CR_best)<precision_phi and\n",
    "                        abs(self.Z_best[name][-2]-Z_best)<precision_Z) and\n",
    "                        abs(self.w0_best[name][-2]-w0_best<precision_w0)):\n",
    "                    self.last_cycle=cycle+1\n",
    "                    break\n",
    "            self.best_radii[name]=R0_pix_best\n",
    "            self.best_w0s[name]=w0_best\n",
    "            self.best_zs[name]=Z_best\n",
    "            self.best_angles[name]=self.angle_to_pi_pi(phi_CR_best)\n",
    "            self.simulations_required[name]=simulations\n",
    "            print(f\"Image {im} optimized!\")\n",
    "\n",
    "\n",
    "    def quadratic_fit_search(self, precision_pix, maximum_points_R0, precision_phi,\n",
    "        maximum_points_phi, precision_Z, maximum_points_Z, precision_w0, maximum_points_w0, cost_tol,\n",
    "        precision_M, maximum_points_M, cost_tol_M):\n",
    "        # We first find an estimation for R0 and phiCR using the gradient algorithm\n",
    "        self.algorithm_M.quadratic_fit_search(precision_M, maximum_points_M, cost_tol_M)\n",
    "\n",
    "        # We now execute a sequence of linear optimizations for each coordinate for every cycle\n",
    "        for im, name in enumerate(self.image_names):\n",
    "            self.times[name]={}\n",
    "            self.radious_points[name]={}\n",
    "            self.Z_points[name]={}\n",
    "            self.w0_points[name]={}\n",
    "            self.phi_points[name]={}\n",
    "            # use the results from the gradient algorithm to initialize the best triplet\n",
    "            #self.R0_pix_best[name]=[1.65*abs(self.algorithm_G.optimals[f'Fibonacci_Search_{name}'])]\n",
    "            self.R0_pix_best[name]=[self.R0_init_guess]\n",
    "            self.Z_best[name]=[self.Z_init_guess]\n",
    "            self.w0_best[name]=[self.w0_init_guess]\n",
    "            # Initialize the phiCR with the result from the mirror flip agorithm\n",
    "            self.phi_CR_best[name]=[self.algorithm_M.angles[f'Fibonacci_Search_{name}']]\n",
    "            simulations=0\n",
    "            for cycle in range(self.cycles):\n",
    "                # Optimize Radious magnitude - the width of the croissant\n",
    "                (time_w0, self.w0_points[name][cycle], w0_best, w0_optimum,\n",
    "                 _)=self.w0_optimizer.fibonacci_ratio_search(\n",
    "                    precision_w0, maximum_points_w0, cost_tol,\n",
    "                    self.images[im],\n",
    "                    (self.phi_CR_best[name][-1], self.R0_pix_best[name][-1], self.Z_best[name][-1]), self.w0_best[name][-1]\n",
    "                )\n",
    "\n",
    "                # Optimize Radious\n",
    "                (time_rad, self.radious_points[name][cycle], R0_pix_best, radi_optimum,\n",
    "                 _)=self.radious_optimizer.quadratic_fit_search(\n",
    "                    precision_pix, maximum_points_R0, cost_tol,\n",
    "                    self.images[im],\n",
    "                    (self.phi_CR_best[name][-1], self.Z_best[name][-1], w0_best), self.R0_pix_best[name][-1]\n",
    "                )\n",
    "\n",
    "                # Optimize Angle\n",
    "                (time_ang, self.phi_points[name][cycle], phi_CR_best, phi_optimum, _)=self.angle_optimizer.quadratic_fit_search(\n",
    "                    precision_phi, maximum_points_phi, cost_tol,\n",
    "                    self.images[im],\n",
    "                    (R0_pix_best, self.Z_best[name][-1], w0_best), self.phi_CR_best[name][-1]\n",
    "                )\n",
    "\n",
    "                # Optimize Z\n",
    "                if maximum_points_Z!=0:\n",
    "                    self.Z_optimizer.a=-2*np.sqrt(1/3)*R0_pix_best*self.simulator.dx\n",
    "                    self.Z_optimizer.b=-self.Z_optimizer.a\n",
    "                    (time_Z, self.Z_points[name][cycle], Z_best, Z_optimum,\n",
    "                        _)=self.Z_optimizer.quadratic_fit_search(\n",
    "                            precision_Z, maximum_points_Z, cost_tol,\n",
    "                            self.images[im],\n",
    "                            (phi_CR_best, R0_pix_best, w0_best), self.Z_best[name][-1]\n",
    "                        )\n",
    "                else: # dont optimize z\n",
    "                    time_Z=0\n",
    "                    Z_best=0\n",
    "                    Z_optimum=0\n",
    "                    self.Z_points[name][cycle]=np.array([[0,0,0]])\n",
    "\n",
    "                self.times[name][cycle]=time_rad+time_ang+time_Z+time_w0\n",
    "                self.R0_pix_best[name].append(R0_pix_best)\n",
    "                self.w0_best[name].append(w0_best)\n",
    "                self.phi_CR_best[name].append(phi_CR_best)\n",
    "                self.Z_best[name].append(Z_best)\n",
    "\n",
    "                simulations+=len(self.phi_points[name][cycle])+len(self.radious_points[name][cycle])+len(self.Z_points[name][cycle])+len(self.w0_points[name][cycle])\n",
    "\n",
    "                # check if convergence criterion is met\n",
    "                if((abs(Z_optimum-phi_optimum)<cost_tol and\n",
    "                        abs(phi_optimum-radi_optimum)<cost_tol and\n",
    "                            abs(radi_optimum-w0_optimum)<cost_tol)\n",
    "                        or (abs(self.R0_pix_best[name][-2]-R0_pix_best)<precision_pix and\n",
    "                        abs(self.phi_CR_best[name][-2]-phi_CR_best)<precision_phi and\n",
    "                        abs(self.Z_best[name][-2]-Z_best)<precision_Z) and\n",
    "                        abs(self.w0_best[name][-2]-w0_best<precision_w0)):\n",
    "                    self.last_cycle=cycle+1\n",
    "                    break\n",
    "            self.best_radii[name]=R0_pix_best\n",
    "            self.best_w0s[name]=w0_best\n",
    "            self.best_zs[name]=Z_best\n",
    "            self.best_angles[name]=self.angle_to_pi_pi(phi_CR_best)\n",
    "            self.simulations_required[name]=simulations\n",
    "            print(f\"Image {im} optimized!\")\n",
    "\n",
    "    def plot_best_found_ones(self, out_path):\n",
    "        os.makedirs(f\"{out_path}/Simulation_Coordinate_Descent_Algorithm/\", exist_ok=True)\n",
    "        fig = plt.figure(figsize=(2*4.5, len(self.image_names)*4.5))\n",
    "        axes=fig.subplots(len(self.image_names),2)\n",
    "        if len(axes.shape)==1:\n",
    "            axes=np.expand_dims(axes, 0)\n",
    "        for k, (name, optimal_angle) in enumerate(self.best_angles.items()):\n",
    "            axes[k, 0].imshow(self.images[k].to('cpu').numpy())        \n",
    "            axes[k, 1].imshow(self.get_simulated_image( R0=self.best_radii[name],\n",
    "                w0=self.best_w0s[name], Z=self.best_Zs[name], phiCR=self.best_angles[name]).to('cpu').numpy())\n",
    "            axes[k,0].set_title(f\"Experimental Image {name}\\nOptimal phiCR {optimal_angle}\")\n",
    "            axes[k,1].set_title(f\"Fitted Image: \\nR0={self.best_radii[name]}pix w0={self.best_w0s[name]}pix\\n Z={self.best_Zs[name]}pix phiCR={self.best_angles[name]}rad\")\n",
    "        fig.suptitle(\"Results of the Simulation Coordinate Descent Algorithm\")\n",
    "        plt.savefig(f\"{out_path}/Simulation_Coordinate_Descent_Algorithm/Net_Results.png\")\n",
    "        \n",
    "    def save_result_plots(self, out_path, meth_name):\n",
    "        os.makedirs(f\"{out_path}/Simulation_Coordinate_Descent_Algorithm/\", exist_ok=True)\n",
    "        self.algorithm_M.save_result_plots_fibonacci_or_quadratic(f\"{out_path}/Simulation_Coordinate_Descent_Algorithm/\")\n",
    "        fig = plt.figure(figsize=(4*10, 10*self.last_cycle))\n",
    "\n",
    "        for k, name in enumerate(self.phi_points.keys()):\n",
    "            axes = fig.subplots(self.last_cycle, 4)\n",
    "            if self.last_cycle==1:\n",
    "                axes=np.expand_dims(axes,0)\n",
    "            for cycle in range(self.last_cycle):\n",
    "                axes[cycle, 0].plot(self.w0_points[name][cycle][:,0], self.w0_points[name][cycle][:,1], 'o', label=f'w0 pixels descent fixing phiCR={self.phi_CR_best[name][cycle]}; R0 pix={self.R0_pix_best[name][cycle]}; Z={self.Z_best[name][cycle]}')\n",
    "                axes[cycle, 1].plot(self.radious_points[name][cycle][:,0], self.radious_points[name][cycle][:,1], 'o', label=f'R0 pixels descent fixing w0 pix ={self.w0_best[name][cycle+1]}; phiCR={self.phi_CR_best[name][cycle]}; Z={self.Z_best[name][cycle]}')\n",
    "                axes[cycle, 2].plot(self.phi_points[name][cycle][:,0], self.phi_points[name][cycle][:,1], 'o', label=f'phiCR descent fixing w0 pix ={self.w0_best[name][cycle+1]}; R0 pix={self.R0_pix_best[name][cycle+1]}; Z={self.Z_best[name][cycle]}')\n",
    "                axes[cycle, 3].plot(self.Z_points[name][cycle][:,0], self.Z_points[name][cycle][:,1], 'o', label=f'Z descent fixing w0 pix ={self.w0_best[name][cycle+1]}; R0 pix={self.R0_pix_best[name][cycle+1]}; phiCR={self.phi_CR_best[name][cycle+1]}')\n",
    "\n",
    "                axes[cycle, 0].set_xlabel(\"w0 (pixels)\")\n",
    "                axes[cycle, 1].set_xlabel(\"R0 (pixels)\")\n",
    "                axes[cycle, 2].set_xlabel(\"phi_CR (rad)\")\n",
    "                axes[cycle, 3].set_xlabel(\"Z (w0-s)\")\n",
    "                axes[cycle, 0].set_title(f\"Best of cycle={self.w0_best[name][cycle+1]}\\n Computed points={len(self.w0_points[name][cycle])}\")\n",
    "                axes[cycle, 1].set_title(f\"Best of cycle={self.R0_pix_best[name][cycle+1]}\\n Computed points={len(self.radious_points[name][cycle])}\")\n",
    "                axes[cycle, 2].set_title(f\"Best of cycle={self.phi_CR_best[name][cycle+1]}\\n Computed points={len(self.phi_points[name][cycle])}\")\n",
    "                axes[cycle, 3].set_title(f\"Best of cycle={self.Z_best[name][cycle+1]}\\n Computed points={len(self.Z_points[name][cycle])}\")\n",
    "\n",
    "                for i in range(4):\n",
    "                    axes[cycle, i].set_ylabel(\"sum(abs(simulated_image(phiCR, R0_pix, w0_pix, Z)-exp_image))\")\n",
    "                    axes[cycle, i].grid(True)\n",
    "                    axes[cycle, i].legend()\n",
    "\n",
    "                fig.suptitle(f\"{meth_name}  {name}\\nBest triplet: phiCR={self.best_angles[name]}rad; R0_pix={self.best_radii[name]}pix; w0={self.best_w0s[name]}(pix); Z={self.best_zs[name]}w0\")\n",
    "            plt.savefig(f\"{out_path}/Simulation_Coordinate_Descent_Algorithm/{meth_name}__{name}.png\")\n",
    "            fig.clf()\n",
    "            I=self.get_simulated_image( R0=self.best_radii[name],\n",
    "                w0=self.best_w0s[name], Z=self.best_Zs[name], phiCR=self.best_angles[name]).to('cpu').numpy()\n",
    "            I = (255*I/I.max())[0] #[h,w]\n",
    "            cv2.imwrite(f\"{out_path}/Simulation_Coordinate_Descent_Algorithm/iX_{X}_Left_Exp_[{name}]_Right_Simul_PolAngle_{self.best_angles[name]/2:.15f}_CRAngle_{self.best_angles[name]:.15f}_Z_{self.best_zs[name]}_R0_pix_{self.best_radii[name]}_w0_pix_{self.best_w0s[name]}.png\",\n",
    "                np.concatenate((I, self.images[k]/self.images[k].max()),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Encoder_Alone/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "\n",
    "simulation_alg_kw_args = {'ID_file_path':ID_file_path, 'D_matrix_file_path':D_matrix_file_path, 'device':device, \n",
    "                        'coordinate_descent_cycles':2, 'min_angle':-np.pi,\n",
    "                       'max_angle':np.pi,'initial_guess_delta_rad':0.1, 'initial_guess_delta_R0':1,\n",
    "                        'similarity':'mae','R0_init_guess':158.0, 'w0_init_guess':25.0, 'Z_init_guess':0.0\n",
    "                       }\n",
    "simulation_fibo_kw_args = {'precision_pix':1e-5, 'maximum_points_R0':10, 'precision_phi':1e-8,\n",
    "                        'maximum_points_phi':100, 'precision_Z':1e-2, 'maximum_points_Z':0, \n",
    "                         'precision_w0':1e-5, 'maximum_points_w0':10, 'cost_tol':1e-14, 'precision_M':1e-4,\n",
    "                        'maximum_points_M':100, 'cost_tol_M':1e-14}\n",
    "\n",
    "simulation_quad_kw_args = {'precision_pix':1e-5, 'maximum_points_R0':10, 'precision_phi':1e-8,\n",
    "                        'maximum_points_phi':100, 'precision_Z':1e-2, 'maximum_points_Z':0, \n",
    "                         'precision_w0':1e-5, 'maximum_points_w0':10, 'cost_tol':1e-14, 'precision_M':1e-4,\n",
    "                        'maximum_points_M':100, 'cost_tol_M':1e-14}\n",
    "\n",
    "simulation_preprocess_fct = lambda(images, in_are_dev_float, device): normalize_to_mean_saturate_to_max_and_iX_torch(\n",
    "                images,  in_are_dev_float,  device=device, saturation_threshold=0.1, dtype=troch.float32, X=302)\n",
    "\n",
    "# also, at least in this case, expected to be torch arrays!\n",
    "def run_simulation_algorithm(references, problems, image_pair_names, preprocess_fct, search_algorithm, \n",
    "                       search_alg_kw_args, rotation_alg_kw_args, out_plot_path=None, simulation_algorithm=None):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    if simulation_algorithm is None:\n",
    "        simulation_algorithm = Simulation_precomputed_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "            ID_file_path=simulation_alg_kw_args['ID_file_path'], \n",
    "            D_matrix_file_path=simulation_alg_kw_args['D_matrix_file_path'], device=simulation_alg_kw_args['device'],\n",
    "            coordinate_descent_cycles=simulation_alg_kw_args['coordinate_descent_cycles'],\n",
    "            min_angle=simulation_alg_kw_args['min_angle'], max_angle=simulation_alg_kw_args['max_angle'], \n",
    "            initial_guess_delta_rad=simulation_alg_kw_args['initial_guess_delta_rad'], \n",
    "            initial_guess_delta_R0=simulation_alg_kw_args['initial_guess_delta_R0'],\n",
    "            preprocess_fct=preprocess_fct, similarity=simulation_alg_kw_args['similarity'],\n",
    "            R0_init_guess=simulation_alg_kw_args['R0_init_guess'], w0_init_guess=simulation_alg_kw_args['w0_init_guess'], \n",
    "            Z_init_guess=simulation_alg_kw_args['Z_init_guess'] \n",
    "            )\n",
    "            \n",
    "    image_names = []\n",
    "    for mode in ['Ref', 'Pb']:\n",
    "        for image_pair_name in image_pair_names:\n",
    "            image_names.append(f\"{mode}__{image_pair_name}\")\n",
    "    # charge the image loader:\n",
    "    images = torch.cat((references, problems), dim=0)\n",
    "    # Execute the Rotation Algorithm:\n",
    "    simulation_algorithm.reInitialize_and_input_images( images, image_names,\n",
    "                     preprocess_fct=preprocess_fct, coordinate_descent_cycles=simulation_alg_kw_args['coordinate_descent_cycles'],\n",
    "                    similarity=simulation_alg_kw_args['similarity'],\n",
    "                R0_init_guess=simulation_alg_kw_args['R0_init_guess'],\n",
    "                w0_init_guess=simulation_alg_kw_args['w0_init_guess'],\n",
    "                Z_init_guess=simulation_alg_kw_args['Z_init_guess'])\n",
    "    # run it\n",
    "    if search_algorithm=='quadratic':\n",
    "        simulation_algorithm.quadratic_fit_search(precision_pix=search_alg_kw_args['precision_pix'],\n",
    "            maximum_points_R0=search_alg_kw_args['maximum_points_R0'], precision_phi=search_alg_kw_args['precision_phi'],\n",
    "            maximum_points_phi=search_alg_kw_args['maximum_points_phi'], precision_Z=search_alg_kw_args['precision_Z'], \n",
    "            maximum_points_Z=search_alg_kw_args['maximum_points_Z'],  precision_w0=search_alg_kw_args['precision_w0'],\n",
    "            maximum_points_w0=search_alg_kw_args['maximum_points_w0'], cost_tol=search_alg_kw_args['cost_tol'],\n",
    "            precision_M=search_alg_kw_args['precision_M'], maximum_points_M=search_alg_kw_args['maximum_points_M'],\n",
    "                                                  cost_tol_M=search_alg_kw_args['cost_tol_M'])\n",
    "        if out_plot_path is not None:\n",
    "            rotation_algorithm.save_result_plots(out_plot_path, 'Quadratic')\n",
    "    else: # 'fibo'\n",
    "        simulation_algorithm.fibonacci_ratio_search(precision_pix=search_alg_kw_args['precision_pix'],\n",
    "            maximum_points_R0=search_alg_kw_args['maximum_points_R0'], precision_phi=search_alg_kw_args['precision_phi'],\n",
    "            maximum_points_phi=search_alg_kw_args['maximum_points_phi'], precision_Z=search_alg_kw_args['precision_Z'], \n",
    "            maximum_points_Z=search_alg_kw_args['maximum_points_Z'],  precision_w0=search_alg_kw_args['precision_w0'],\n",
    "            maximum_points_w0=search_alg_kw_args['maximum_points_w0'], cost_tol=search_alg_kw_args['cost_tol'],\n",
    "            precision_M=search_alg_kw_args['precision_M'], maximum_points_M=search_alg_kw_args['maximum_points_M'],\n",
    "                                                  cost_tol_M=search_alg_kw_args['cost_tol_M'])    \n",
    "        if out_plot_path is not None:\n",
    "            rotation_algorithm.save_result_plots(out_plot_path, 'Fibonacci')\n",
    "\n",
    "    if out_plot_path is not None:\n",
    "        simulation_algorithm.plot_best_found_ones(out_plot_path)\n",
    "\n",
    "    \n",
    "    for i in range(len(image_pair_names)):\n",
    "        predicted_deltaPhiCRs.append( \n",
    "            simulation_algorithm.best_angles.values()[i+len(image_pair_names)] - \\\n",
    "                                      simulation_algorithm.best_angles.values()[i] ) # pb - ref\n",
    "        times.append( sum(simulation_algorithm.times.values()[i+len(image_pair_names)]) + \\\n",
    "                                      sum(simulation_algorithm.times.values()[i]))\n",
    "    \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (D) Naive Affine Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E) Fourier Space shift Rotation and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (F) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Using the Experimental+Simulated Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_type=np.uint16 if image_depth==16 else np.uint8\n",
    "max_intensity=65535 if image_depth==16 else 255\n",
    "np.random.seed(randomization_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Using a large simulated Noisy Image Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
