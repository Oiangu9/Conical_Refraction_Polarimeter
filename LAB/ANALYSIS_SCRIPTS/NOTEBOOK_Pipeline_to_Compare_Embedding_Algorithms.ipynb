{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "def restart_run_all():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                IPython.notebook.kernel.restart();\n",
    "                setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 1000)\n",
    "                \n",
    "            </script>\n",
    "        '''\n",
    "    ))\n",
    "\n",
    "import ctypes\n",
    "import gc\n",
    "\n",
    "def free():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "    \n",
    "def skip(line, cell=None):\n",
    "    '''Skips execution of the current line/cell if line evaluates to True.'''\n",
    "    if eval(line):\n",
    "        return\n",
    "\n",
    "    get_ipython().run_cell(cell) \n",
    "\n",
    "def load_ipython_extension(shell):\n",
    "    '''Registers the skip magic when the extension loads.'''\n",
    "    shell.register_magic_function(skip, 'line_cell')\n",
    "\n",
    "def unload_ipython_extension(shell):\n",
    "    '''Unregisters the skip magic when the extension unloads.'''\n",
    "    del shell.magics_manager.magics['cell']['skip']\n",
    "    \n",
    "    \n",
    "load_ipython_extension(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 6\n"
     ]
    }
   ],
   "source": [
    "pipe_name=\"Azken_Txampa\"\n",
    "\n",
    "\n",
    "try:\n",
    "    f = open(f\"META_BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_meta_block = int(f.read())\n",
    "    f.close()\n",
    "    f = open(f\"BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_block = int(f.read())\n",
    "    f.close()\n",
    "    f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_sub_block = int(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "except:\n",
    "    current_block = 1\n",
    "    current_sub_block = 1\n",
    "    current_meta_block = 1\n",
    "\n",
    "if current_meta_block>2:\n",
    "    hey\n",
    "    raise ValueError\n",
    "    \n",
    "print(current_meta_block, current_block, current_sub_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_meta_block==1: # use only experimental\n",
    "    dont_use_simulated = True\n",
    "    dont_use_experimental = False\n",
    "else: # use noisy or non noisy simulated! 2, 3 respectively\n",
    "    dont_use_simulated = False\n",
    "    dont_use_experimental = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import scipy\n",
    "import cv2\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm\n",
    "from SOURCE.CLASS_CODE_Image_Manager import Image_Manager\n",
    "from SOURCE.CLASS_CODE_Ad_Hoc_Optimizer import Ad_Hoc_Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from skimage.filters import threshold_local\n",
    "from styleframe import StyleFrame\n",
    "import sklearn as sk\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE TO COMPARE EMBEDDING AND SIMULATOR ALGORITHMS\n",
    "---\n",
    "---\n",
    "\n",
    "    def alg tal (image_refs, image_pbs, save_output_plots_path=None):\n",
    "        ...\n",
    "        return predicted_delta_phiCRs, times (de cada pairwise image pair ref pb -que están en los mismos indices claro)\n",
    "\n",
    "Ke guarde los plots ke se outputean si hace falta en ese path dado.\n",
    "\n",
    "Ta gero funkiño bat que coja algs, que coja image pairs y si acaso coja sus ground-truths como opctional argument, y que te outputee la tabla de imagen, algoritmos delta phicR, delta pol, times, GT, absolute errors.\n",
    "\n",
    "Ta gero bebai outputee pa cada algoritmo un histograma de los absolute errors y un histograma de tiempos, con las medias y percentiles indicados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm\n",
    "from SOURCE.CLASS_CODE_Image_Manager import Image_Manager\n",
    "from SOURCE.CLASS_CODE_Ad_Hoc_Optimizer import Ad_Hoc_Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from styleframe import StyleFrame\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_to_pi_pi( angle): # convert any angle to range (-pi,pi]\\n\",\n",
    "    angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\\n\",\n",
    "    return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle\n",
    "\n",
    "\n",
    "def compute_expectation_CI(empirical_pdf, boots_samples, confidence):\n",
    "    resamplings=np.random.choice(empirical_pdf, size=( boots_samples, empirical_pdf.shape[0]))\n",
    "    boot_means=np.mean(resamplings, axis=1)\n",
    "    boot_stds=np.std(resamplings, axis=1)\n",
    "    observed_mean=empirical_pdf.mean()\n",
    "    observed_std=empirical_pdf.std()\n",
    "    boots_t=(observed_mean-boot_means)*np.sqrt(empirical_pdf.shape[0])/boot_stds\n",
    "    boots_t_percentiles = np.percentile(boots_t, q=((100-confidence)/2, confidence+(100-confidence)/2))\n",
    "    return observed_mean+boots_t_percentiles*observed_std/np.sqrt(empirical_pdf.shape[0])\n",
    "\n",
    "\n",
    "def plot_histograms_for(category, variable, final_results_df, statistic_df, conf, output_path, bins_log=True):\n",
    "    categories=len(final_results_df.groupby([category])) # category sería algorithm\n",
    "                            # variable serían time, absolute error etc.\n",
    "    columns=1 if categories==1 else 2 if (categories==2 or categories==4) else 3\n",
    "    rows=categories//3+(categories%3!=0)\n",
    "\n",
    "    fig=plt.figure(figsize=(7*columns, 5*rows))\n",
    "    if bins_log:\n",
    "        bins_main_exponents=np.linspace(-8.5, -3.5, 32 ).tolist()\n",
    "        bins_main_exponents=[1]+bins_main_exponents+[-1,0]\n",
    "        #bins_main_exponents=[1,-8.5, -8, -7.5, -7, -6.5,-6,-5.5,-5,-4.5,-4,-3.5,-1,0]\n",
    "        bins_main=10**np.array(bins_main_exponents)\n",
    "        bins_main[0]=0\n",
    "    else:\n",
    "        bins_main=13\n",
    "    axs=[]\n",
    "    maxy=0\n",
    "    for i, (group_var_val, group_df) in enumerate(final_results_df.groupby([category])):\n",
    "        axs.append(fig.add_subplot(rows,columns, i+1))\n",
    "        ns, b, p = axs[-1].hist(group_df[variable], bins=bins_main,\n",
    "                        label=f\"{category}={group_var_val}\", \n",
    "                        rwidth=1, align='mid', edgecolor=\"k\", alpha=0.6) # range=(0,0.4)\n",
    "        if bins_log:\n",
    "            axs[-1].set_xscale('log')\n",
    "        axs[-1].grid(True)\n",
    "        axs[-1].axvline(x=statistic_df[variable][f'CI_{conf}_low'][group_var_val], color='m',\n",
    "                        linestyle='--', label=f'mean {conf} CI', alpha=0.6)\n",
    "        axs[-1].axvline(x=statistic_df[variable][f'CI_{conf}_up'][group_var_val], color='m', \n",
    "                        linestyle='--', alpha=0.6)\n",
    "        quantiles=np.percentile(group_df[variable], q=((100-conf)/2, conf+(100-conf)/2))\n",
    "        axs[-1].axvline(x=quantiles[0], color='r', linestyle='--', label=f'{conf} quantiles')\n",
    "        axs[-1].axvline(x=quantiles[1], color='r', linestyle='--')\n",
    "        axs[-1].set_title(f\"mu {conf}% CI:\\n ({statistic_df[variable][f'CI_{conf}_low'][group_var_val]}, \\\n",
    "                          {statistic_df[variable][f'CI_{conf}_up'][group_var_val]})\")\n",
    "        axs[-1].legend()\n",
    "        maxy = np.max(ns) if np.max(ns)>maxy else maxy\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(0,maxy)\n",
    "    #fig.supylabel('common_y')\n",
    "    fig.suptitle(f\"Histograms for {variable}\")\n",
    "    #fig.suptitle(f\"Histogrms for {variable} \\n\\n Experiment: {experiment_name}\\n\\n\\n The x axes represent the smallest absolute difference between the theoretical\\n angle difference and the found angle difference, among the employed algorithms\")\n",
    "\n",
    "    os.makedirs(f\"{output_path}/HISTOGRAMS/\", exist_ok=True)\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig(f\"{output_path}/HISTOGRAMS/Histogram_for_{variable}.png\", bbox_inches='tight')\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "times = {}\n",
    "predicted_delta_phiCRs = {}\n",
    "\n",
    "def run_benchmark_output_result_histograms_and_result_table( algorithm_lambda_list, algorithm_name_list,\n",
    "                                            references, problems, image_pair_names, generate_algorithm_plots,\n",
    "                                            generate_histograms, boots_samples=10000, confidence=95,\n",
    "                                            output_units='rad', ground_truths=None, GT_units=None,\n",
    "                                            GT_nature = 'phiCR',\n",
    "                                            experiment_name = None, output_path=None, batch_size=20):\n",
    "    if experiment_name is not None:\n",
    "        output_path = f\"{output_path}/{experiment_name}/\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "    # GTs should be in [-pi, pi] or [-180, 180]\n",
    "    global times\n",
    "    global predicted_delta_phiCRs\n",
    "    \n",
    "    conv = 180/np.pi if output_units=='deg' else 1\n",
    "    convGT = 180/np.pi if (output_units=='deg' and GT_units=='rad') else \\\n",
    "        np.pi/180 if (output_units=='rad' and GT_units=='deg') else 1\n",
    "    print(\"> Passing Images from each Algorithm...\")\n",
    "    for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "        if output_path is not None and generate_algorithm_plots:\n",
    "            dir_for_alg = output_path+f\"/{alg_name}/\"\n",
    "            os.makedirs( dir_for_alg, exist_ok=True )\n",
    "        else:\n",
    "            dir_for_alg = None\n",
    "        \n",
    "        predicted_delta_phiCRs[alg_name]={}\n",
    "        times[alg_name]={}\n",
    "        #try: # por si por ejemplo ransac no encuentra ningun consenso y salta un error\n",
    "        for j in range(0, references.shape[0], batch_size):\n",
    "\n",
    "            batch_predicted_delta_phiCRs, batch_times =  algorithm(\n",
    "                    references[j:(j+batch_size)], problems[j:(j+batch_size)], \n",
    "                    image_pair_names[j:(j+batch_size)], dir_for_alg)\n",
    "            predicted_delta_phiCRs[alg_name].update(batch_predicted_delta_phiCRs)\n",
    "            times[alg_name].update(batch_times)\n",
    "            free()\n",
    "        '''\n",
    "        except:\n",
    "            for imn in image_pair_names:\n",
    "                predicted_delta_phiCRs[alg_name][imn]=0\n",
    "                times[alg_name][imn]=0\n",
    "        '''\n",
    "        \n",
    "        print(f\" - Algorithm {alg_name} done!\")\n",
    "        try: # for the Carles algorithm to receive different arguments with a lambda function, en fin\n",
    "            global k\n",
    "            k+=1\n",
    "        except:\n",
    "            pass\n",
    "        free()\n",
    "        \n",
    "    print(\"\\n> Rearranging results in Tables and outputting to Excels...\")\n",
    "    if output_path is not None:\n",
    "        json.dump({'image_pair_names':image_pair_names, 'predicted_delta_phiCRs':predicted_delta_phiCRs,\n",
    "              'times':times}, open( f\"{output_path}/RAW_results.json\", \"w\"))\n",
    "    # Rearrange the result to our desired Table and unit formats\n",
    "    image_ids = []\n",
    "    image_names = []\n",
    "    algorithm_names = []\n",
    "    delta_phiCRs = []\n",
    "    delta_pols = []\n",
    "    timess = []\n",
    "    GTs = []\n",
    "    abs_errors = []\n",
    "    free()\n",
    "    switch_dif = 90 if output_units=='deg' else np.pi/2\n",
    "    max_diff = 2*switch_dif\n",
    "    # if abs dif is bigger than 90 then the true error is 180-that number for its the smallest plane difference in angle!\n",
    "    for idx, image_pair_name in enumerate(image_pair_names):\n",
    "        for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "            image_ids.append(idx)\n",
    "            algorithm_names.append(alg_name)\n",
    "            image_names.append(image_pair_name)\n",
    "            delta_phiCRs.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][image_pair_name]) ) \n",
    "            delta_pols.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][image_pair_name])/2.0 )\n",
    "            timess.append(times[alg_name][image_pair_name])\n",
    "            if ground_truths is not None:\n",
    "                GTs.append(convGT*ground_truths[idx])\n",
    "                if GT_nature=='phiCR':\n",
    "                    abs_errors.append( np.abs(delta_phiCRs[-1]-convGT*ground_truths[idx]) )\n",
    "                else: # then GT is of polarization\n",
    "                    abs_dif = np.abs(delta_pols[-1]-convGT*ground_truths[idx])\n",
    "                    if abs_dif>switch_dif:\n",
    "                        abs_er = max_diff - abs_dif\n",
    "                    else:\n",
    "                        abs_er = abs_dif\n",
    "                    abs_errors.append( abs_er )\n",
    "                #correct_decimals.append() # beittu HISTOGRAMAGAZ batera zelan eitten zendun hau!\n",
    "    table_per_image = pd.DataFrame.from_dict({'ID':image_ids, 'Image_Pair_Name':image_names, 'Algorithm':algorithm_names,\n",
    "                                   'Predicted_Delta_PhiCRs':delta_phiCRs, 'Pred_Delta_Polarizt':delta_pols,\n",
    "                                   'Times':timess, f'Ground_Truth_{GT_nature}':GTs, 'Absolute_Error':abs_errors})\n",
    "    if output_path is not None:\n",
    "        table_per_image.to_pickle( f\"{output_path}/Table_Per_Image_All.pkl\")\n",
    "    print(\" - Table per images done!\")    \n",
    "    free()\n",
    "\n",
    "    # Group by algorithm and generate statistics by analyte (times, absolute_errors etc.)\n",
    "    groups = table_per_image.groupby('Algorithm')\n",
    "    stdv = groups[['Absolute_Error', 'Times']].std().fillna(0.0)\n",
    "    means = groups[['Absolute_Error', 'Times']].mean()\n",
    "    # Compute confidence intervals using bootstrap\n",
    "    CIs_time = {}\n",
    "    CIs_abs_er = {}\n",
    "    for alg_name, df in table_per_image.groupby('Algorithm'):\n",
    "        CIs_time[alg_name] = compute_expectation_CI(df['Times'],boots_samples, confidence)\n",
    "        CIs_abs_er[alg_name] = compute_expectation_CI(df['Absolute_Error'], boots_samples, confidence)\n",
    "        free()\n",
    "    CIs_time_df = pd.DataFrame(index=CIs_time.keys(), data=CIs_time.values(), columns=[f'CI_{confidence}_l', f'CI_{confidence}_u'])\n",
    "    CIs_abs_er_df = pd.DataFrame(index=CIs_abs_er.keys(), data=CIs_abs_er.values(), columns=[f'CI_{confidence}_l', f'CI_{confidence}_u'])\n",
    "    \n",
    "    ae = pd.concat([means['Absolute_Error'], stdv['Absolute_Error'],\n",
    "                    CIs_abs_er_df[f'CI_{confidence}_l'], CIs_abs_er_df[f'CI_{confidence}_u']],\n",
    "                   keys=['Mean', 'Standard_Dev', f'CI_{confidence}_low', f'CI_{confidence}_up'],axis=1)\n",
    "    ts = pd.concat([means['Times'], stdv['Times'],\n",
    "                    CIs_time_df[f'CI_{confidence}_l'], CIs_time_df[f'CI_{confidence}_u']],                   \n",
    "                   keys=['Mean', 'Standard_Dev', f'CI_{confidence}_low', f'CI_{confidence}_up'],axis=1)\n",
    "    table_per_alg = pd.concat([ae, ts], keys=['Absolute_Error', 'Times'], axis=1)    \n",
    "    free()\n",
    "\n",
    "    if output_path is not None:\n",
    "        table_per_image.to_pickle( f\"{output_path}/Table_Per_Algorithm_Statistics.pkl\")\n",
    "        print(\" - Table per algorithm done!\")    \n",
    "        if generate_histograms:\n",
    "            print(\"\\n> Generating histograms...\")\n",
    "            plot_histograms_for('Algorithm', 'Absolute_Error', table_per_image, table_per_alg, confidence, output_path, bins_log=False)\n",
    "            plot_histograms_for('Algorithm', 'Times', table_per_image, table_per_alg, confidence, output_path, bins_log=False)\n",
    "            print(\"DONE!\")\n",
    "    return table_per_image, table_per_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    return centered_image\n",
    "\n",
    "\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                              iX_dev='cpu', out_dev='cpu', X=302): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                                     iX_dev='cpu', out_dev='cpu', X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                                      iX_dev='cpu', out_dev='cpu', X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    means = np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_max_and_iX(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=302): # images expected to be [N_images, h, w]\n",
    "    images= images.astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_and_iX(images, dtype=np.float64,\n",
    "                     iX_dev='cpu', out_dev='cpu', X=302): # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def sigmoid_lut_and_iX( images, center=0.5, slope_squeezeness=0.085, max_val=255, dtype=np.float64, X=302 ):\n",
    "    lut = max_val/(1+np.exp(-slope_squeezeness*(np.arange(max_val+1)-center*max_val)))\n",
    "    images = (lut[ images ]).astype(dtype)\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=302): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.abmax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=302):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    means=torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_max_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=torch.float32, X=302): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=torch.float32, X=302): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/torch.mean(images, axis=(-1,-2), keepdims=True), X, device)\n",
    "\n",
    "\n",
    "def sigmoid_lut_using_numpy_normalize_and_iX( images, in_are_dev, device, center=0.5, \n",
    "                       slope_squeezeness=0.085, max_val_lut_process=255, lut_process_dtype=torch.uint8,\n",
    "                       output_dtype=torch.float64, X=302 ):\n",
    "    if not in_are_dev:\n",
    "        images = images.to(device)\n",
    "    images = (max_val_lut_process*(images.type(torch.float64)/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)))\n",
    "                 ).type(lut_process_dtype)\n",
    "    \n",
    "    lut = (max_val_lut_process/(1+np.exp(-slope_squeezeness*(np.arange(max_val_lut_process+1)-\n",
    "                                                               center*max_val_lut_process))))\n",
    "    images = torch.from_numpy(lut[ images.to('cpu').numpy() ]).to(device).type(output_dtype)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "# Ojo! se usan los valores float del lut como valores de la imagen! (no los cuantizados!)\n",
    "\n",
    "def sigmoid_no_lut_normalize_and_iX( images, in_are_dev_float, device, center=0.7, \n",
    "                       slope_squeezeness=50, dtype=torch.float64, X=302 ):\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)    \n",
    "    images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "    images = 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "    return compute_raws_to_centered_iXs_torch(images, X, device) # we need not noramlize them again if center if sigmoid chosen with sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (G) Metric/Embedding como look-up table (aka KNN) for SKLEARN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#args_sk_KNN = {'n_neighbors':3, 'weights':'distance', 'algorithm':'auto', 'leaf_size':50, 'p':2,\n",
    "#               'metric':'minkowski', 'n_jobs':n_jobs}\n",
    "\n",
    "class KNN_Regressor():\n",
    "    def __init__(self, embedder_func, args_sk_KNN):\n",
    "        # ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\n",
    "        # ‘uniform’, ‘distance’\n",
    "        self.embedder_func = embedder_func\n",
    "        self.KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "                    weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "                    leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "                    metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, X, y, already_embedded_X=False): # X [N_samples, dim_feats], y [N_samples] # y can be to regression floats!\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X) # [N_samples, dim_feats]\n",
    "        self.KNN = self.KNN.fit(X, y)\n",
    "        self.fitted = True\n",
    "    \n",
    "    def score(self, X, y, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.score(X,y)\n",
    "        \n",
    "    def predict(self, X, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.predict(X)\n",
    "    \n",
    "class Sklearn_embedder():\n",
    "    def __init__(self, embedder, preprocess_fct):\n",
    "        self.preprocess_fct = preprocess_fct\n",
    "        self.embedder = embedder\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.embedder.transform( self.preprocess_fct(X) )\n",
    "    \n",
    "pre_process_name = \"normalize_to_max_and_iX\"\n",
    "\n",
    "import torch\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images\n",
    "\n",
    "import gc\n",
    "def normalize_to_max_and_iX_input_output_flatten(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=302, batch_size=100): # images expected to be [N_images, h, w]\n",
    "    out = np.zeros((images.shape[0], (X*2+1)**2), dtype=np.float64)\n",
    "    images= images.astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = images.reshape(-1, X*2+1, X*2+1)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        out[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch( torch.from_numpy(images[j:(j+batch_size)]).to(device), X, device).to('cpu').numpy().reshape(len(out[j:(j+batch_size)]), -1)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    return out\n",
    "\n",
    "\n",
    "preprocess_fct = normalize_to_max_and_iX_input_output_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sklearn as sk\n",
    "import sklearn.neighbors\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import umap\n",
    "import pickle\n",
    "from time import time\n",
    "#exp_emb='Noisy_Dataset_Embedders'\n",
    "#knn_embedder_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{exp_emb}/\"\n",
    "\n",
    "#f_name = f\"PCA_KNN_n_images_600_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_3_seed_666_date_14_06_2022_20h43m1655232227.sav\"\n",
    "#preprocess_and_embed =  Está dentro del knn_alg incluido!\n",
    "#trained_knn_alg = pickle.load((open(knn_embedder_stuff_path+f_name, 'rb')))\n",
    "\n",
    "def run_knn_on_embedding_space(references, problems, image_pair_names,   \n",
    "                       trained_knn_alg): # if as embedder one gives a pre_process_fct, it will work the same way\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "\n",
    "    t=time()\n",
    "    \n",
    "    ref = trained_knn_alg.predict( references.reshape(references.shape[0],-1), already_embedded_X=False )\n",
    "    pb = trained_knn_alg.predict( problems.reshape(problems.shape[0],-1), already_embedded_X=False )\n",
    "    angles = pb-ref\n",
    "    \n",
    "    t = time()-t\n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = t/len(references)\n",
    "        \n",
    "    return predicted_deltaPhiCRs, times    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (G.2) Metric/Embedding como look-up table (aka KNN) for Triplet loss embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "'''\n",
    "\n",
    "class Proximity_Metric_Based_On_Simple_Encoder(nn.Module):\n",
    "    def __init__(self, X=302, feats_1=15, feats_2=20, feats_3=20, feats_4=20,\n",
    "                 prop1=3, prop2=2, prop3=1, av_pool1_div=4, conv4_feat_size=15, av_pool2_div=10, \n",
    "                 out_fc_1=10, out_fc_2=10,\n",
    "                 dropout_p1=0.2, dropout_p2=0.1\n",
    "                ): \n",
    "        # propj is such that the_ image getting out from stage j is propj/prop_{j-1}-ths of the previous (with j=0 being 5)\n",
    "        # clearly, prop_{j-1}>prop_{j}>...\n",
    "        # 2X+1 will be assumed to be divisible by 5\n",
    "        assert((2*X+1)%5==0)\n",
    "        assert(prop1>prop2)\n",
    "        assert(prop2>prop3)\n",
    "        assert((int((prop3*(2*X+1)/5)/av_pool1_div)-conv4_feat_size)>0)\n",
    "        \n",
    "        \n",
    "        super(Proximity_Metric_Based_On_Simple_Encoder, self).__init__()\n",
    "        # in is [epoch_size, 1, 2X+1, 2X+1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=feats_1, \n",
    "                               kernel_size = int((2*X+1)/5*(5-prop1)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        self.conv2 = nn.Conv2d(in_channels=feats_1, out_channels=feats_2, \n",
    "                               kernel_size = int((2*X+1)/5*(prop1-prop2)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_2, prop2*(prop1*(2X+1)/5)/prop1, prop2*(prop1*(2X+1)/5)/prop1]\n",
    "        # that is [epoch_size, feats_2, prop2*(2X+1)/5), prop2*(2X+1)/5)]\n",
    "        self.conv3 = nn.Conv2d(in_channels=feats_2, out_channels=feats_3, \n",
    "                               kernel_size = int((2*X+1)/5*(prop2-prop3)+1), bias=True)\n",
    "        # out conv3 is [epoch_size, feats_3, prop3*(2X+1)/5), prop3*(2X+1)/5)]\n",
    "\n",
    "        self.avPool1 = nn.AvgPool2d(kernel_size= int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=feats_3, out_channels=feats_4, \n",
    "                              kernel_size= int((prop3*(2*X+1)/5)/av_pool1_div+1)-conv4_feat_size+1, bias=True)\n",
    "        # [epoch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        \n",
    "        self.avPool2 = nn.AvgPool2d(kernel_size= int(conv4_feat_size*(1-1/av_pool2_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_4, conv4_feat_size/av_pool2_div+1, conv4_feat_size/av_pool2_div+1]\n",
    "        \n",
    "        #self.in_fc = int(feats_4*(conv4_feat_size/av_pool2_div+1)**2)\n",
    "        self.in_fc = feats_4*((((((2*X+1-int((2*X+1)/5*(5-prop1)+1)+1)\n",
    "                                  -int((2*X+1)/5*(prop1-prop2)+1)+1)\n",
    "                                 -int((2*X+1)/5*(prop2-prop3)+1)+1)\n",
    "                                -int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) -1+1)\n",
    "                               -int((prop3*(2*X+1)/5)/av_pool1_div+1)+conv4_feat_size-1+1)\n",
    "                              -int(conv4_feat_size*(1-1/av_pool2_div)) -1+1)**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc, out_features=out_fc_1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc_1, out_features=out_fc_2, bias=True)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1, inplace=False)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=feats_2)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=feats_4)\n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        \n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, out_fc_2]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Proximity_Metric_Based_On_Corrector(nn.Module):\n",
    "    def __init__(self, S0=2*302+1, S1=2*290+1, S2=2*250+1, S3=2*200+1, S4 = 2*10+1,\n",
    "                 S5 = 2*1+1, S6 =2,\n",
    "                 feats_S1=10, feats_S2=10, feats_S3=20, feats_S4=20, feats_S5 = 20,\n",
    "                 out_fc1=100, out_fc2=10,\n",
    "                 feats_S6 = 25,\n",
    "                 dropout_p=0.1\n",
    "                ): \n",
    "       \n",
    "        super(Proximity_Metric_Based_On_Corrector, self).__init__()\n",
    "        self.Ss = [S0, S1, S2, S3, S4, S5, S6]\n",
    "        self.feats = [1, feats_S1, feats_S2, feats_S3, feats_S4, feats_S5, feats_S6]\n",
    "        self.out_fc1 = out_fc1\n",
    "        self.out_fc2 = out_fc2\n",
    "        # in is [batch_size, 1, S0, S0]\n",
    "        self.conv_S01 = nn.Conv2d(in_channels=1, out_channels=feats_S1, \n",
    "                               kernel_size = S0-S1+1, bias=True) \n",
    "        # out conv_S01 [batch_size, feats_S1, S1, S1]\n",
    "        self.conv_S12 = nn.Conv2d(in_channels=feats_S1, out_channels=feats_S2, \n",
    "                               kernel_size = S1-S2+1, bias=True) \n",
    "        # out conv_S12 [batch_size, feats_S2, S2, S2]\n",
    "        self.conv_S23 = nn.Conv2d(in_channels=feats_S2, out_channels=feats_S3, \n",
    "                               kernel_size = S2-S3+1, bias=True) \n",
    "        # out conv_S23 [batch_size, feats_S3, S3, S3]\n",
    "        \n",
    "        self.conv_S33 = nn.Conv2d(in_channels=feats_S3, out_channels=feats_S3, \n",
    "                               kernel_size = 1, bias=True) \n",
    "        # out conv_S33 [batch_size, feats_S3, S3, S3]\n",
    "        \n",
    "        self.conv_S34 = nn.Conv2d(in_channels=feats_S3, out_channels=feats_S4, \n",
    "                               kernel_size = S3-S4+1, bias=True) \n",
    "        # out conv_S34 [batch_size, feats_S4, S4, S4]\n",
    "        \n",
    "        self.conv_S45 = nn.Conv2d(in_channels=feats_S4, out_channels=feats_S5, \n",
    "                               kernel_size = S4-S5+1, bias=True) \n",
    "        # out conv_S45 [batch_size, feats_S5, S5, S5]\n",
    "        self.conv_S56 = nn.Conv2d(in_channels=feats_S5, out_channels=feats_S6, \n",
    "                               kernel_size = S5-S6+1, bias=True) \n",
    "        # out conv_S56 [batch_size, feats_S6, S6, S6]\n",
    "        \n",
    "        self.in_fc1 = S6*S6*feats_S6\n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc1, out_features=out_fc1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc1, out_features=out_fc2, bias=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_p, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=feats_S3)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(num_features=out_fc1)\n",
    "        \n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        # Conv layers\n",
    "        x = self.relu(self.conv_S01(x)) # [batch_size, feats_S1, S1, S1]\n",
    "        x = self.dropout( self.relu(self.conv_S12(x)) ) # [batch_size, feats_S2, S2, S2]\n",
    "        x = self.relu(self.conv_S23(x)) # [batch_size, feats_S3, S3, S3]\n",
    "        x = self.batchNorm1(self.relu(self.conv_S33(x)))\n",
    "        x = self.relu(self.conv_S34(x))\n",
    "        x = self.relu(self.conv_S45(x))\n",
    "        x = self.relu(self.conv_S56(x))\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc1)\n",
    "        x = self.dropout( self.relu(self.batchNorm2(self.fc1(self.dropout(x)))) )\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                    'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                    'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "'''\n",
    "class Triplet_NN_embedder(): # INPUT DATA IS ASSUMED TO BE NUMPY\n",
    "    def __init__(self, args_NN_embedder, checkpoint_path, device, batch_size=50,\n",
    "                 encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\"):\n",
    "        self.device = device\n",
    "        self.output_to = output_to\n",
    "        self.args_NN_embedder = args_NN_embedder\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.iX = args_NN_embedder['X']\n",
    "        self.out_dim = args_NN_embedder['out_fc2']\n",
    "        if encoder_or_denoiser_based==\"encoder\":\n",
    "            self.model = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_embedder['X'], \n",
    "                feats_1=args_NN_embedder['feats_1'], feats_2=args_NN_embedder['feats_2'], \n",
    "                feats_3=args_NN_embedder['feats_3'], feats_4=args_NN_embedder['feats_4'],\n",
    "                 prop1=args_NN_embedder['prop1'], prop2=args_NN_embedder['prop2'], prop3=args_NN_embedder['prop3'], \n",
    "                av_pool1_div=args_NN_embedder['av_pool1_div'], conv4_feat_size=args_NN_embedder['conv4_feat_size'], \n",
    "                av_pool2_div=args_NN_embedder['av_pool2_div'], \n",
    "                 out_fc_1=args_NN_embedder['out_fc_1'], out_fc_2=args_NN_embedder['out_fc2'],\n",
    "                 dropout_p1=args_NN_embedder['dropout_p1'], dropout_p2=args_NN_embedder['dropout_p2'] )\n",
    "        else:\n",
    "            self.model = Proximity_Metric_Based_On_Corrector(S0=S0, S1=S1, S2=S2, S3=S3, S4=S4, S5=S5, S6=S6,\n",
    "                 feats_S1=feats_S1, feats_S2=feats_S2, feats_S3=feats_S3, feats_S4=feats_S4,\n",
    "                 feats_S5=feats_S5, feats_S6=feats_S6,\n",
    "                 out_fc1=out_fc1, out_fc2=out_fc2,\n",
    "                 dropout_p=dropout_p ) \n",
    "        \n",
    "        self.preprocess = lambda X: (torch.tensor(X.reshape(X.shape[0],self.iX*2+1,self.iX*2+1)).to(device)) if len(X.shape)<3 else (torch.tensor(X).to(device))\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # move model to gpu if available\n",
    "        self.model.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.model.eval()\n",
    "    \n",
    "    @torch.no_grad() \n",
    "    def __call__(self, X):\n",
    "        self.model.eval()\n",
    "        if self.output_to==\"numpy\":\n",
    "            Xout = np.zeros((X.shape[0], self.out_dim), dtype=np.float64)\n",
    "            for j in range(0, X.shape[0], self.batch_size):\n",
    "                Xout[j:(j+self.batch_size)] = self.model(self.preprocess(X[j:(j+self.batch_size)])).detach().to('cpu').numpy()\n",
    "            return Xout\n",
    "        else:\n",
    "            return self.model(self.preprocess(X))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "\n",
    "exp_name_nn = \"Noisy_Dataset_Embedders\"\n",
    "\n",
    "triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=saved_NN_path+f\"/NNs/{check_file}\", \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")\n",
    "\n",
    "knn_embedder_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{exp_name_nn}/\"\n",
    "f_name_knn = f'Triplet_CNN_KNN_n_images_600_emb_dims_10_seed_666_date_14_06_2022_20h38m15s.sav'\n",
    "'''\n",
    "#trained_knn_alg_triplet = pickle.load((open(knn_embedder_stuff_path+f_name_knn, 'rb')))\n",
    "\n",
    "#trained_knn_alg_triplet.embedder_func = triplet_embedder\n",
    "\n",
    "def run_knn_on_embedding_space(references, problems, image_pair_names,   \n",
    "                       trained_knn_alg): # if as embedder one gives a pre_process_fct, it will work the same way\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "\n",
    "    t=time()\n",
    "    \n",
    "    ref = trained_knn_alg.predict( references, already_embedded_X=False )\n",
    "    pb = trained_knn_alg.predict( problems, already_embedded_X=False )\n",
    "    angles = pb-ref\n",
    "    \n",
    "    t = time()-t\n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = t/len(references)\n",
    "        \n",
    "    return predicted_deltaPhiCRs, times    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (K.1) Simulation Fit using h5f library of D matrices gravicenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_by( image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "def given_axis_angle_greater_minus_lower( angle, image, center, rows):\n",
    "    # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "    # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "    mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "    return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un embedder aqui solo tiene sentido si ha estado fed con ground truth poarization angles\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(references, problems, image_pair_names, \n",
    "                                            preprocess_fct, simulation_fit_kw_args, embedder=None):\n",
    "    s = Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR( preprocess_fct, simulation_fit_kw_args, embedder=embedder)\n",
    "    return s.get_angles_times(references, problems, image_pair_names)\n",
    "\n",
    "class Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR():\n",
    "    \n",
    "    def rotate_image_by(  self, image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "\n",
    "    def get_Carles_metric( self, center_h_w, im,  interpolation_flag):\n",
    "        im_pi_im = self.rotate_image_by(im, np.pi, center_h_w,interpolation_flag)+im\n",
    "        return np.mean(np.abs(im_pi_im-rotate_image_by(im_pi_im, np.pi/2, center_h_w,interpolation_flag)))\n",
    "\n",
    "\n",
    "    def initial_Blazquez_estimation( self,  im, center, options_Blaz, rows_prec ):\n",
    "        get_metric = lambda c_h_w : self.get_Carles_metric(c_h_w, im=im, interpolation_flag=cv2.INTER_CUBIC)\n",
    "        res = scipy.optimize.minimize(get_metric, center, method='Nelder-Mead',\n",
    "                                            bounds=((0,im.shape[0]),(0, im.shape[0])),\n",
    "                                            tol=None, options=options_Blaz)\n",
    "        geom_center = res.x\n",
    "        angle = np.arctan2(geom_center[0]-center[0], geom_center[1]-center[1] )\n",
    "        angle = self.get_polarization_angle( angle, im, center, rows_prec)\n",
    "        max_pix_in_prof = np.argmax(im[ int(geom_center[0]),:])\n",
    "        R0 = np.abs(max_pix_in_prof-geom_center[1])-3\n",
    "\n",
    "        try:\n",
    "            if max_pix_in_prof>geom_center[1]:\n",
    "                tol = im[ int(geom_center[0]),::-1]>0.4\n",
    "            else:\n",
    "                tol = im[ int(geom_center[0]),:]>0.4\n",
    "            init = np.argwhere(tol)[0,0]\n",
    "        except:\n",
    "            try:\n",
    "                if max_pix_in_prof>geom_center[1]:\n",
    "                    tol = im[ int(geom_center[0]),::-1]>0.3\n",
    "                else:\n",
    "                    tol = im[ int(geom_center[0]),:]>0.3\n",
    "                init = np.argwhere(tol)[0,0]\n",
    "            except:\n",
    "                try:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.2\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.2\n",
    "                    init = np.argwhere(tol)[0,0]\n",
    "                except:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.1\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.1\n",
    "                    if np.sum(tol)!=0:\n",
    "                        init = np.argwhere(tol)[0,0]\n",
    "                    else:\n",
    "                        return -angle, R0, 22\n",
    "                    \n",
    "        w0 = np.argwhere(np.logical_not(tol[init:]))[0,0]\n",
    "        #print(f\"phi{-angle} R0{R0} w0{w0}\")\n",
    "        return -angle, R0, w0\n",
    "\n",
    "    def get_simulated_image( self, R0, w0, Z, phiCR):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phiCR)]).to(device) #[num_phiCR, 1, 1]\n",
    "        images = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        return self.preprocess_fct(images, in_are_dev_float=True)[0] # only one image\n",
    "    \n",
    "    def closest_in_ar_periodic(  self, value, list_array, delta):\n",
    "        idxs = (np.round((value-min(list_array))/delta)%len(list_array)).astype(int)\n",
    "        return list_array[ idxs ]\n",
    "    \n",
    "    def plot_found_and_ref( self, im_exp, R0, w0, Z, phi):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phi)]).to(device) #[num_phiCR, 1, 1]\n",
    "        im_sim = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        im_sim = self.process(im_sim, in_are_dev_float=True)[0].to('cpu').numpy()\n",
    "        fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "        ax[0].imshow(im_exp)\n",
    "        ax[0].set_title(\"Experimental Image\")\n",
    "        ax[1].imshow(im_sim)\n",
    "        ax[1].set_title(f\"Found optimal\\nR0={R0} w0={w0} Z={Z}\\n phi={phi}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def compute_metric(self, R0_w0_Z_phi, exp_image):\n",
    "        #self.plot_found_and_ref(exp_image.to('cpu').numpy(),R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3])\n",
    "        return self.similarity_func( exp_image, \n",
    "                        self.get_simulated_image(R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3]) )\n",
    "    \n",
    "    def closest_idx_in_ar(self, value, list_array): # hay que meterle una periodicidad como con los angulos porke los algs de optimizacion están pensados para que así sea\n",
    "        return (np.abs(list_array-value)).argmin()\n",
    "\n",
    "    def plot(self, guess, pb):\n",
    "        im = torch.cat((guess, pb))\n",
    "        plt.imshow(im.to('cpu').numpy())\n",
    "        plt.show()\n",
    "\n",
    "    def given_axis_angle_greater_minus_lower(self, angle, image, center, rows):\n",
    "        # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "        # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "        mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "        return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "    def get_polarization_angle(self, angle, image, center, rows):\n",
    "        \"\"\"\n",
    "        All the mirror methods have the problem that we only get the\n",
    "        correct angle up to an angle pi. In order to know which is the\n",
    "        angle to the maximum of the ring (and not the minimum) a final\n",
    "        subtle check is required.\n",
    "        \"\"\"\n",
    "        #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "        if angle==0 or abs(angle)==np.pi:\n",
    "            angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "        diff=given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center, rows)\n",
    "\n",
    "        if diff<0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "            return angle+np.pi if angle<0 else angle\n",
    "        else:\n",
    "            return angle-np.pi if angle>0 else angle\n",
    "\n",
    "    \n",
    "    def __init__(self, preprocess_fct, simulation_fit_kw_args, embedder=None):\n",
    "    \n",
    "        if embedder is None:\n",
    "            self.process = preprocess_fct\n",
    "            self.preprocess_fct = preprocess_fct\n",
    "        else:\n",
    "            self.process = preprocess_fct\n",
    "            self.preprocess_fct = lambda im, in_are_dev_float : self.embedder(self.process( im, in_are_dev_float ))\n",
    "        self.simulation_fit_kw_args = simulation_fit_kw_args\n",
    "        self.embedder = embedder\n",
    "\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(simulation_fit_kw_args['ID_file_path'])))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.R0s_ar = np.array(self.R0s, dtype=np.float64) # Convert them to float arrays\n",
    "        self.w0s_ar = np.array(self.w0s, dtype=np.float64)\n",
    "        self.Zs_ar = np.array(self.Zs, dtype=np.float64)\n",
    "\n",
    "        self.h5f_D_matrices = h5py.File( simulation_fit_kw_args['D_matrix_file_path'], 'r')\n",
    "        self.phis = torch.from_numpy( self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(device) #[1,Nx,Ny]\n",
    "\n",
    "        self.min_Z=min(self.Zs_ar)\n",
    "        self.max_Z=max(self.Zs_ar)\n",
    "        self.min_phi=-np.pi\n",
    "        self.max_phi=np.pi\n",
    "        self.min_radi=min(self.R0s_ar)\n",
    "        self.max_radi=max(self.R0s_ar)\n",
    "        self.min_w0=min(self.w0s_ar)\n",
    "        self.max_w0=max(self.w0s_ar)\n",
    "        #print((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi))\n",
    "\n",
    "        self.last_R0=None\n",
    "        self.last_w0=None\n",
    "        self.last_Z=None\n",
    "        self.R0_precision=abs(self.R0s_ar[1]-self.R0s_ar[0])\n",
    "        self.w0_precision=abs(self.w0s_ar[1]-self.w0s_ar[0])\n",
    "        self.Z_precision=abs(self.Zs_ar[1]-self.Zs_ar[0])\n",
    "        self.similarity_func=simulation_fit_kw_args['similarity_alg']\n",
    "\n",
    "\n",
    "    \n",
    "    def get_angles_times(self, references, problems, image_pair_names):\n",
    "        predicted_deltaPhiCRs={}\n",
    "        times={}\n",
    "\n",
    "        if self.preprocess_fct is not None:\n",
    "            images_t = self.preprocess_fct( torch.from_numpy(np.concatenate((references, problems), axis=0)), in_are_dev_float=False )\n",
    "        else:\n",
    "            images_t = torch.from_numpy( np.concatenate((references, problems), axis=0) )\n",
    "\n",
    "        references_t = images_t[:references.shape[0]]\n",
    "        problems_t = images_t[references.shape[0]:]\n",
    "\n",
    "        if self.simulation_fit_kw_args['use_exact_gravicenter']:\n",
    "            centers_pbs = self.simulation_fit_kw_args['gravicenter_alg'](torch.tensor(problems).to(device)) #[N_pbs, 2] in numpy but input in torch\n",
    "            centers_refs = self.simulation_fit_kw_args['gravicenter_alg'](torch.tensor(references).to(device))\n",
    "        else:\n",
    "            centers_pbs = np.repeat(np.array([[self.simulation_fit_kw_args['X'], \n",
    "                                              self.simulation_fit_kw_args['X']]]), \n",
    "                                   len(problems), axis=0)\n",
    "            centers_refs = np.repeat(np.array([[self.simulation_fit_kw_args['X'], \n",
    "                                              self.simulation_fit_kw_args['X']]]), \n",
    "                                   len(references), axis=0)\n",
    "\n",
    "        rows_prec = np.broadcast_to( np.arange(references.shape[1]), (references.shape[1],references.shape[1])).swapaxes(0,1) #[h,w]\n",
    "        \n",
    "        if self.embedder is None:\n",
    "            references = references_t.to('cpu').numpy()\n",
    "            problems = problems_t.to('cpu').numpy()\n",
    "        else:\n",
    "            references = self.process( torch.from_numpy(references), in_are_dev_float=False).to('cpu').numpy()\n",
    "            problems = self.process( torch.from_numpy(problems), in_are_dev_float=False).to('cpu').numpy()\n",
    "        \n",
    "        # Blazquez algorithm estimation of phiCR, R0 (and even w0)\n",
    "        options_Blaz={'maxiter':self.simulation_fit_kw_args['max_it_Blaz'],\n",
    "                 'maxfev': self.simulation_fit_kw_args['max_evals_Blaz'], \n",
    "                 'xatol':self.simulation_fit_kw_args['abs_tol_Blaz'],\n",
    "                 'fatol':self.simulation_fit_kw_args['rel_tol_Blaz']}\n",
    "\n",
    "        for ref_im, pb_im, ref_im_t, pb_im_t, cent_ref, cent_pb, imagep_n in zip(references, problems, references_t, problems_t, centers_refs, centers_pbs, image_pair_names):\n",
    "            t0=time()\n",
    "            \n",
    "            Z_guess = 0\n",
    "            phi_guess, R0_guess, w0_guess = self.initial_Blazquez_estimation( ref_im, cent_ref, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_ref = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "            \n",
    "            phi_guess, R0_guess, w0_guess = self.initial_Blazquez_estimation( pb_im, cent_pb, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_pb = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "\n",
    "            to_opt_ref = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=ref_im_t )\n",
    "            to_opt_pb = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=pb_im_t)\n",
    "\n",
    "            if self.simulation_fit_kw_args['method']=='Bayesian':\n",
    "                res = skopt.gp_minimize(to_opt_ref, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_ref],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                #self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "                res = skopt.gp_minimize(to_opt_pb, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_pb],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                #self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            else:\n",
    "                options={'maxiter':self.simulation_fit_kw_args['max_it'],\n",
    "                    'maxfev': self.simulation_fit_kw_args['max_evals']}\n",
    "\n",
    "                if self.simulation_fit_kw_args['method']=='Nelder-Mead':\n",
    "                    options['xatol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['fatol']=self.simulation_fit_kw_args['rel_tol']\n",
    "                elif self.simulation_fit_kw_args['method']=='Powell':\n",
    "                    options['xtol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['ftol']=self.simulation_fit_kw_args['rel_tol']\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_ref, init_guess_ref, method=self.simulation_fit_kw_args['method'],\n",
    "                         bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                #self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_pb, init_guess_pb, method=self.simulation_fit_kw_args['method'],\n",
    "                                bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                #self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            found = angle_to_pi_pi(opt_R0w0ZphiCR_pb[-1])-angle_to_pi_pi(opt_R0w0ZphiCR_ref[-1])\n",
    "\n",
    "            predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "            times[imagep_n] = time()-t0\n",
    "\n",
    "        self.h5f_D_matrices.close()      \n",
    "        return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (K.2) Simulation Fit using h5f library of D matrices geometric center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "\n",
    "# to max noisy and iX\n",
    "def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "    images = images.astype(np.float64)\n",
    "    free()\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "        images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "                      ), X=302, device=device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_geom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64, saturation_threshold=1):\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    return torch.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "\n",
    "\n",
    "# Un embedder aqui solo tiene sentido si ha estado fed con ground truth poarization angles\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(references, problems, image_pair_names, \n",
    "                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args, embedder=None, \n",
    "                                ):\n",
    "    s = Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center( \n",
    "        pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args, embedder=embedder)\n",
    "    return s.get_angles_times(references, problems, image_pair_names)\n",
    "\n",
    "class Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center():\n",
    "    \n",
    "    def center_in_center_torch(self, images, centers): # For a piling of images and centers\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                      device=device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(centers).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-X\n",
    "        unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(centers.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images\n",
    "    \n",
    "    def rotate_image_by(  self, image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "\n",
    "    def get_Carles_metric( self, center_h_w, im,  interpolation_flag):\n",
    "        im_pi_im = self.rotate_image_by(im, np.pi, center_h_w,interpolation_flag)+im\n",
    "        return np.mean(np.abs(im_pi_im-rotate_image_by(im_pi_im, np.pi/2, center_h_w,interpolation_flag)))\n",
    "\n",
    "\n",
    "    def initial_Blazquez_estimation( self,  im, center, options_Blaz, rows_prec ):\n",
    "        get_metric = lambda c_h_w : self.get_Carles_metric(c_h_w, im=im, interpolation_flag=cv2.INTER_CUBIC)\n",
    "        res = scipy.optimize.minimize(get_metric, center, method='Nelder-Mead',\n",
    "                                            bounds=((0,im.shape[0]),(0, im.shape[0])),\n",
    "                                            tol=None, options=options_Blaz)\n",
    "        geom_center = res.x\n",
    "        angle = np.arctan2(geom_center[0]-center[0], geom_center[1]-center[1] )\n",
    "        angle = self.get_polarization_angle( angle, im, center, rows_prec)\n",
    "        max_pix_in_prof = np.argmax(im[ int(geom_center[0]),:])\n",
    "        R0 = np.abs(max_pix_in_prof-geom_center[1])-3\n",
    "        try:\n",
    "            if max_pix_in_prof>geom_center[1]:\n",
    "                tol = im[ int(geom_center[0]),::-1]>0.4\n",
    "            else:\n",
    "                tol = im[ int(geom_center[0]),:]>0.4\n",
    "            init = np.argwhere(tol)[0,0]\n",
    "        except:\n",
    "            try:\n",
    "                if max_pix_in_prof>geom_center[1]:\n",
    "                    tol = im[ int(geom_center[0]),::-1]>0.3\n",
    "                else:\n",
    "                    tol = im[ int(geom_center[0]),:]>0.3\n",
    "                init = np.argwhere(tol)[0,0]\n",
    "            except:\n",
    "                try:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.2\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.2\n",
    "                    init = np.argwhere(tol)[0,0]\n",
    "                except:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.1\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.1\n",
    "                    if np.sum(tol)!=0:\n",
    "                        init = np.argwhere(tol)[0,0]\n",
    "                    else:\n",
    "                        return -angle, R0, 22        \n",
    "        w0 = np.argwhere(np.logical_not(tol[init:]))[0,0]\n",
    "        #print(f\"phi{-angle} R0{R0} w0{w0}\")\n",
    "        return -angle, R0, w0, geom_center\n",
    "\n",
    "    def get_simulated_image( self, R0, w0, Z, phiCR):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phiCR)]).to(device) #[num_phiCR, 1, 1]\n",
    "        images = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        images = self.postgeom_preprocess_fct(images, in_are_dev_float=True)[0] # only one image\n",
    "        return torch.nn.functional.pad(images, (32,32,32,32), mode='constant', value=0)\n",
    "    \n",
    "    def closest_in_ar_periodic(  self, value, list_array, delta):\n",
    "        idxs = (np.round((value-min(list_array))/delta)%len(list_array)).astype(int)\n",
    "        return list_array[ idxs ]\n",
    "    \n",
    "    def plot_found_and_ref( self, im_exp, R0, w0, Z, phi):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phi)]).to(device) #[num_phiCR, 1, 1]\n",
    "        im_sim = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        im_sim = torch.nn.functional.pad(\n",
    "            self.postgeom_preprocess_fct(im_sim, in_are_dev_float=True)[0],\n",
    "            (32,32,32,32), mode='constant', value=0).to('cpu').numpy()\n",
    "        fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "        ax[0].imshow(im_exp)\n",
    "        ax[0].set_title(\"Experimental Image\")\n",
    "        ax[1].imshow(im_sim)\n",
    "        ax[1].set_title(f\"Found optimal\\nR0={R0} w0={w0} Z={Z}\\n phi={phi}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def compute_metric(self, R0_w0_Z_phi, exp_image):\n",
    "        #self.plot_found_and_ref(exp_image.to('cpu').numpy(),R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3])\n",
    "        return self.similarity_func( exp_image, \n",
    "                        self.get_simulated_image(R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3]) )\n",
    "    \n",
    "    def closest_idx_in_ar(self, value, list_array): # hay que meterle una periodicidad como con los angulos porke los algs de optimizacion están pensados para que así sea\n",
    "        return (np.abs(list_array-value)).argmin()\n",
    "\n",
    "    def plot(self, guess, pb):\n",
    "        im = torch.cat((guess, pb))\n",
    "        plt.imshow(im.to('cpu').numpy())\n",
    "        plt.show()\n",
    "\n",
    "    def given_axis_angle_greater_minus_lower(self, angle, image, center, rows):\n",
    "        # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "        # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "        mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "        return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "    def get_polarization_angle(self, angle, image, center, rows):\n",
    "        \"\"\"\n",
    "        All the mirror methods have the problem that we only get the\n",
    "        correct angle up to an angle pi. In order to know which is the\n",
    "        angle to the maximum of the ring (and not the minimum) a final\n",
    "        subtle check is required.\n",
    "        \"\"\"\n",
    "        #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "        if angle==0 or abs(angle)==np.pi:\n",
    "            angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "        diff=given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center, rows)\n",
    "\n",
    "        if diff<0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "            return angle+np.pi if angle<0 else angle\n",
    "        else:\n",
    "            return angle-np.pi if angle>0 else angle\n",
    "\n",
    "    \n",
    "    def __init__(self, pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args, embedder=None, preprocess_simulated=None):\n",
    "\n",
    "        if embedder is None:\n",
    "            self.process = preprocess_fct\n",
    "            self.pregeom_preprocess_fct = pregeom_preprocess_fct\n",
    "            self.postgeom_preprocess_fct = postgeom_preprocess_fct\n",
    "        else:\n",
    "            self.process = postgeom_preprocess_fct\n",
    "            self.postgeom_preprocess_fct = lambda im, in_are_dev_float : self.embedder(self.process( im, in_are_dev_float ))\n",
    "            self.pregeom_preprocess_fct = pregeom_preprocess_fct\n",
    "        self.simulation_fit_kw_args = simulation_fit_kw_args\n",
    "        self.embedder = embedder\n",
    "        \n",
    "        self.X = simulation_fit_kw_args['X']\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(simulation_fit_kw_args['ID_file_path'])))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.R0s_ar = np.array(self.R0s, dtype=np.float64) # Convert them to float arrays\n",
    "        self.w0s_ar = np.array(self.w0s, dtype=np.float64)\n",
    "        self.Zs_ar = np.array(self.Zs, dtype=np.float64)\n",
    "\n",
    "        self.h5f_D_matrices = h5py.File( simulation_fit_kw_args['D_matrix_file_path'], 'r')\n",
    "        self.phis = torch.from_numpy( self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(device) #[1,Nx,Ny]\n",
    "\n",
    "        self.min_Z=min(self.Zs_ar)\n",
    "        self.max_Z=max(self.Zs_ar)\n",
    "        self.min_phi=-np.pi\n",
    "        self.max_phi=np.pi\n",
    "        self.min_radi=min(self.R0s_ar)\n",
    "        self.max_radi=max(self.R0s_ar)\n",
    "        self.min_w0=min(self.w0s_ar)\n",
    "        self.max_w0=max(self.w0s_ar)\n",
    "        #print((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi))\n",
    "\n",
    "        self.last_R0=None\n",
    "        self.last_w0=None\n",
    "        self.last_Z=None\n",
    "        self.R0_precision=abs(self.R0s_ar[1]-self.R0s_ar[0])\n",
    "        self.w0_precision=abs(self.w0s_ar[1]-self.w0s_ar[0])\n",
    "        self.Z_precision=abs(self.Zs_ar[1]-self.Zs_ar[0])\n",
    "        self.similarity_func=simulation_fit_kw_args['similarity_alg']\n",
    "\n",
    "\n",
    "    \n",
    "    def get_angles_times(self, references, problems, image_pair_names):\n",
    "        predicted_deltaPhiCRs={}\n",
    "        times={}\n",
    "\n",
    "        if self.pregeom_preprocess_fct is not None:\n",
    "            images_t = self.pregeom_preprocess_fct( torch.from_numpy(np.concatenate((references, problems), axis=0)), \n",
    "                                           in_are_dev_float=False )\n",
    "        else:\n",
    "            images_t = torch.from_numpy( np.concatenate((references, problems), axis=0) ).to(device)\n",
    "\n",
    "        gcenters_t = compute_intensity_gravity_centers_torch( images_t) #[N_pbs, 2] in numpy but input in torch\n",
    "        images_t = self.center_in_center_torch(images_t, gcenters_t) # center in gravicentrum!\n",
    "\n",
    "        references_t = images_t[:references.shape[0]]\n",
    "        problems_t = images_t[references.shape[0]:]\n",
    "        centers_refs = gcenters_t[:references.shape[0]].to('cpu').numpy()\n",
    "        centers_pbs = gcenters_t[references.shape[0]:].to('cpu').numpy()\n",
    "\n",
    "        rows_prec = np.broadcast_to( np.arange(references.shape[-1]), (references.shape[-1],references.shape[-1])).swapaxes(0,1) #[h,w]\n",
    "        \n",
    "        if self.embedder is None:\n",
    "            references = references_t.to('cpu').numpy()\n",
    "            problems = problems_t.to('cpu').numpy()\n",
    "        else:\n",
    "            references = self.process( torch.from_numpy(references), in_are_dev_float=False).to('cpu').numpy()\n",
    "            problems = self.process( torch.from_numpy(problems), in_are_dev_float=False).to('cpu').numpy()\n",
    "        \n",
    "        # Blazquez algorithm estimation of phiCR, R0 (and even w0)\n",
    "        options_Blaz={'maxiter':self.simulation_fit_kw_args['max_it_Blaz'],\n",
    "                 'maxfev': self.simulation_fit_kw_args['max_evals_Blaz'], \n",
    "                 'xatol':self.simulation_fit_kw_args['abs_tol_Blaz'],\n",
    "                 'fatol':self.simulation_fit_kw_args['rel_tol_Blaz']}\n",
    "\n",
    "        for ref_im, pb_im, ref_im_t, pb_im_t, cent_ref, cent_pb, imagep_n in zip(references, problems, references_t, problems_t, centers_refs, centers_pbs, image_pair_names):\n",
    "            t0=time()\n",
    "            \n",
    "            Z_guess = 0\n",
    "            phi_guess, R0_guess, w0_guess, geom_center_ref = self.initial_Blazquez_estimation( ref_im, cent_ref, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_ref = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "            \n",
    "            \n",
    "            phi_guess, R0_guess, w0_guess, geom_center_pb = self.initial_Blazquez_estimation( pb_im, cent_pb, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_pb = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "\n",
    "            #ref_im = self.center_in_center(ref_im, geom_center_ref)\n",
    "            #pb_im = self.center_in_center(pb_im, geom_center_pb)\n",
    "            ref_im_t, pb_im_t = self.center_in_center_torch(torch.stack((ref_im_t, pb_im_t), dim=0),\n",
    "                                        torch.tensor([[geom_center_ref[0],geom_center_ref[1]],\n",
    "                                                    [geom_center_pb[0],geom_center_pb[1]]], device=device))\n",
    "\n",
    "            ref_im_t = self.postgeom_preprocess_fct(ref_im_t, True)\n",
    "            pb_im_t = self.postgeom_preprocess_fct(pb_im_t, True)\n",
    "            \n",
    "            ref_im = ref_im_t.to('cpu').numpy()\n",
    "            pb_im = pb_im_t.to('cpu').numpy()\n",
    "            \n",
    "            to_opt_ref = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=ref_im_t )\n",
    "            to_opt_pb = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=pb_im_t)\n",
    "\n",
    "            if self.simulation_fit_kw_args['method']=='Bayesian':\n",
    "                res = skopt.gp_minimize(to_opt_ref, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_ref],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                #self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "                res = skopt.gp_minimize(to_opt_pb, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_pb],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                #self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            else:\n",
    "                options={'maxiter':self.simulation_fit_kw_args['max_it'],\n",
    "                    'maxfev': self.simulation_fit_kw_args['max_evals']}\n",
    "\n",
    "                if self.simulation_fit_kw_args['method']=='Nelder-Mead':\n",
    "                    options['xatol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['fatol']=self.simulation_fit_kw_args['rel_tol']\n",
    "                elif self.simulation_fit_kw_args['method']=='Powell':\n",
    "                    options['xtol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['ftol']=self.simulation_fit_kw_args['rel_tol']\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_ref, init_guess_ref, method=self.simulation_fit_kw_args['method'],\n",
    "                         bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                #self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_pb, init_guess_pb, method=self.simulation_fit_kw_args['method'],\n",
    "                                bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                #self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            found = angle_to_pi_pi(opt_R0w0ZphiCR_pb[-1])-angle_to_pi_pi(opt_R0w0ZphiCR_ref[-1])\n",
    "\n",
    "            predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "            times[imagep_n] = time()-t0\n",
    "\n",
    "        self.h5f_D_matrices.close()      \n",
    "        return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Using the Experimental+Simulated Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip $dont_use_experimental\n",
    "# General pipeline settings\n",
    "output_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}/\"\n",
    "#output_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/OUTPUT/Feel_the_pipeline/\"\n",
    "output_units = 'deg'\n",
    "confidence = 90\n",
    "boots_samples = 10000\n",
    "X=302\n",
    "dtype = np.float64\n",
    "dtype_torch = torch.float64\n",
    "n_jobs=10\n",
    "\n",
    "# Get the Images to Test\n",
    "images_path = \"../EXPERIMENTAL/TEST_IMAGES/\"\n",
    "#images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "references_names = ['Reference__100', 'sin_los_dos_solo_tubo']#,'antes_de_la_estandar', 'antes_de_la_estandar', 'antes_de_la_estandar', 'antes_de_la_estandar',\n",
    "                   #'IM_43_phiCR_-1.57120680809021','IM_40871_phiCR_-2.4470927715301514','IM_52929_phiCR_0.9714600443840027','IM_53018_phiCR_-2.2813968658447266',\n",
    "                   #'IM_53019_phiCR_-2.679948091506958', 'IM_6_phiCR_-1.7562638521194458', 'IM_73_phiCR_1.33404541015625']\n",
    "respective_pb_names = ['90__100',  'antes_de_la_estandar']#,'con_los_dos', 'sin_el_negativo','sin_el_positivo','sin_los_dos_solo_tubo',\n",
    "                       #'IM_44_phiCR_2.6544740200042725', 'IM_40870_phiCR_-0.6731816530227661', 'IM_52928_phiCR_0.6789670586585999', 'IM_53017_phiCR_0.659442126750946',\n",
    "                       #'IM_53018_phiCR_-2.2813968658447266', 'IM_5_phiCR_-2.6049387454986572', 'IM_72_phiCR_-2.946422576904297']\n",
    "\n",
    "image_pair_names = []\n",
    "sam_im = cv2.imread( f\"{images_path}/{references_names[0]}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "references = np.zeros((len(references_names), sam_im.shape[0], sam_im.shape[1]), dtype=dtype)\n",
    "problems = np.zeros((len(references_names), sam_im.shape[0], sam_im.shape[1]), dtype=dtype)\n",
    "for k, (refn, pbn) in enumerate(zip(references_names, respective_pb_names)):\n",
    "    image_pair_names.append(f\"REF_{refn}_PB_{pbn}\")\n",
    "    references[k] = cv2.imread( f\"{images_path}/{refn}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    problems[k] = cv2.imread( f\"{images_path}/{pbn}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get their pb-ref ground truths\n",
    "ground_truths = np.array([90, 0,-4.4, -13.85, 9.45, 0.0,\n",
    "            angle_to_pi_pi(2.6544740200042725+1.57120680809021)*180/np.pi/2, angle_to_pi_pi(-0.6731816530227661+2.4470927715301514)*180/np.pi/2, angle_to_pi_pi(0.6789670586585999-0.9714600443840027)*180/np.pi/2, angle_to_pi_pi(0.659442126750946+2.2813968658447266)*180/np.pi/2,angle_to_pi_pi(-2.2813968658447266+2.679948091506958)*180/np.pi/2, angle_to_pi_pi(-2.6049387454986572+1.7562638521194458)*180/np.pi/2, angle_to_pi_pi(-2.946422576904297-1.33404541015625)*180/np.pi/2 \n",
    "                        ])\n",
    "GT_units = 'deg'\n",
    "GT_nature = 'pol'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip $dont_use_experimental\n",
    "\n",
    "table_per_alg={}\n",
    "table_per_image={}\n",
    "exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']# , 'Normalize_to_average', 'Sigmoid de parametros tal y cual']\n",
    "\n",
    "\n",
    "algorithm_lambda_list=[]\n",
    "algorithm_name_list = []\n",
    "\n",
    "from skimage import morphology\n",
    "\n",
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "emb_dims=10\n",
    "random_seed=666\n",
    "\n",
    "if current_block==1: # Experimental Embedder+KNN Regressor\n",
    "    \n",
    "    def normalize_to_max_and_iX_input_output_flatten_knn(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=302, batch_size=100): # images expected to be [N_images, h, w]\n",
    "        out = np.zeros((images.shape[0], (2*X+1)**2), dtype=np.float64)\n",
    "        images= images.reshape(-1, X*2+1, X*2+1).astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            out[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch( torch.from_numpy(images[j:(j+batch_size)]).to(device), X, device).to('cpu').numpy().reshape(len(out[j:(j+batch_size)]), -1)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        return out\n",
    "    \n",
    "    if current_sub_block<9: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "    elif current_sub_block>8:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        \n",
    "\n",
    "    if current_sub_block==1 or current_sub_block==9:\n",
    "        # PCA -> Existe la incremental PCA por si es massa grande el dataset!\n",
    "        args = {'exp':'PCA','emb_dims':emb_dims, \"whiten\":True}\n",
    "        embedder = sk.decomposition.PCA(n_components=args['emb_dims'], whiten=args['whiten'], random_state=random_seed)\n",
    "        \n",
    "        if current_sub_block==1: # noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "\n",
    "    elif current_sub_block==2 or current_sub_block==10:\n",
    "        # KPCA\n",
    "        args = {'exp':'KPCA_rbf', 'emb_dims':emb_dims, 'kernel':'rbf', 'fit_inverse':True, 'max_iter':100}\n",
    "        # kernels: linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘cosine’, ‘precomputed’\n",
    "        embedder = sk.decomposition.KernelPCA(n_components=args['emb_dims'], kernel=args['kernel'], \n",
    "                        fit_inverse_transform=args['fit_inverse'], max_iter=args['max_iter'], \n",
    "                                random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==2: # noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_18h24m1657038277.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_18h24m1657038277.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_10h39m1657096748.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_10h39m1657096748.sav\"\n",
    "            \n",
    "    elif current_sub_block==3 or current_sub_block==11:\n",
    "        # LLE \n",
    "        args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 200, \"emb_dims\": emb_dims, 'max_iter':100}\n",
    "        # Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "        embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "                      n_components=args['emb_dims'], max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==3: # noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "        elif current_sub_block==11: # non-noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==4 or current_sub_block==12:\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==4: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==12: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "        \n",
    "    elif current_sub_block==5 or current_sub_block==13:\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==13: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==14:\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==14: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "\n",
    "    elif current_sub_block==7 or current_sub_block==15:\n",
    "        args = {'exp':'RAW'}\n",
    "        embedder = lambda X : X\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "        elif current_sub_block==15: # non-noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "        \n",
    "\n",
    "    \n",
    "    text = \"noisy\" if current_sub_block<9 else \"non_noisy\"\n",
    "    if current_sub_block<8 or (current_sub_block>8 and current_sub_block<16): # scikit learn embedders\n",
    "        #preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_name_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "        if args['exp']=='RAW':\n",
    "            trained_knn_alg.embedder_func.embedder.transform=trained_knn_alg.embedder_func.embedder\n",
    "            \n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_KNN_{args['exp']}_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "    \n",
    "    if current_sub_block==8 or current_sub_block==16:\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "        args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                            'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                            'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "        checkpoint = torch.load(saved_NN_path+f\"/NNs/{check_file}\")\n",
    "        triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=saved_NN_path+'/NNs/'+check_file, \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")\n",
    "        \n",
    "        if current_sub_block==8:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_08_07_2022_10h31m45s.sav\"\n",
    "        elif current_sub_block==16:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_07_07_2022_16h49m21s.sav\"\n",
    "        \n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_path_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func = triplet_embedder\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "\n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_Triplet_CNN_KNN_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "        free()\n",
    "     \n",
    "    \n",
    "elif current_block==2 or current_block==3: # Simulation Gravicenter or Geometric center\n",
    "    ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/STRUCTURE_Grid_R0_115_w0_115_Z_3.json\"\n",
    "    D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/SIMULATIONS/Dataset_R0_115_w0_115_Z_3.h5\"\n",
    "\n",
    "    simulation_fit_kw_args_NM = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Nelder-Mead',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "\n",
    "    simulation_fit_kw_args_P = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Powell',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "    \n",
    "    #text_DS = \"Noisy\" if current_block==2 else \"Non_Noisy\"\n",
    "    geomgrav = \"Grav\" if current_block==2 else \"Geom\"\n",
    "    run_alg = run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR if current_block==2 else run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center\n",
    "    if current_sub_block==1: # to max\n",
    "        # to max noisy and iX\n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                                  X=302, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "                ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        if current_meta_block<3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Exper_Searc_P\",\n",
    "            ]\n",
    "        elif current_meta_block==3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_P\",\n",
    "            ]\n",
    "        \n",
    "          \n",
    "    elif current_sub_block==2: # to mean\n",
    "        # to max then to mean noisy and iX\n",
    "                               \n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                    images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=302, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "\n",
    "    elif current_sub_block==3: # sigmoid luts\n",
    "        \n",
    "        if current_block==2:\n",
    "            def preprocess_fct(images, in_are_dev_float, center,\n",
    "                    slope_squeezeness, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "                                                          , 302, device)\n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35), \n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35),\n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, center=0.1,\n",
    "                    slope_squeezeness=35, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block>3:\n",
    "        # to max noisy and iX\n",
    "        def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "            if not in_are_dev_float:\n",
    "                images = images.type(dtype).to(device)\n",
    "                free()\n",
    "            return compute_raws_to_centered_iXs_torch(\n",
    "                        images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                              X=302, device=device)\n",
    "        \n",
    "    if current_sub_block==4: # Triplet embedder\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "\n",
    "        checkpoint_path=saved_NN_path+f\"/NNs/{check_file}\"\n",
    "\n",
    "\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                          'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                          'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "\n",
    "        triplet_embedder_simulator = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_encoder['X'], \n",
    "                        feats_1=args_NN_encoder['feats_1'], feats_2=args_NN_encoder['feats_2'], \n",
    "                        feats_3=args_NN_encoder['feats_3'], feats_4=args_NN_encoder['feats_4'],\n",
    "                         prop1=args_NN_encoder['prop1'], prop2=args_NN_encoder['prop2'], prop3=args_NN_encoder['prop3'], \n",
    "                        av_pool1_div=args_NN_encoder['av_pool1_div'], conv4_feat_size=args_NN_encoder['conv4_feat_size'], \n",
    "                        av_pool2_div=args_NN_encoder['av_pool2_div'], \n",
    "                         out_fc_1=args_NN_encoder['out_fc_1'], out_fc_2=args_NN_encoder['out_fc2'],\n",
    "                         dropout_p1=args_NN_encoder['dropout_p1'], dropout_p2=args_NN_encoder['dropout_p2'] )\n",
    "        triplet_embedder_simulator.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        triplet_embedder_simulator.load_state_dict(checkpoint['model'])\n",
    "        triplet_embedder_simulator.eval()\n",
    "        \n",
    "\n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=triplet_embedder_simulator),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=triplet_embedder_simulator)\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block<8: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"noisy\"\n",
    "        \n",
    "    elif current_sub_block>7:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"non_noisy\"\n",
    "       \n",
    "    if current_sub_block==5 or current_sub_block==8: # NCA embedder\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==8: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==9: # UMAP embedder\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "                \n",
    "    elif current_sub_block==7 or current_sub_block==10: # ISOMAP embedder\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "    \n",
    "    if current_sub_block>4:\n",
    "        preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        \n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) ),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) )\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "else:\n",
    "    raise ValueError\n",
    "   \n",
    "   \n",
    "\n",
    "print(algorithm_name_list)\n",
    "\n",
    "# List the Algorithms to test\n",
    "for exp_name in exp_names:\n",
    "    table_per_image[exp_name], table_per_alg[exp_name] = run_benchmark_output_result_histograms_and_result_table( \\\n",
    "            algorithm_lambda_list=algorithm_lambda_list, algorithm_name_list=algorithm_name_list,\\\n",
    "            references=references, problems=problems, image_pair_names=image_pair_names,\\\n",
    "            generate_algorithm_plots=False,\\\n",
    "            generate_histograms=False, boots_samples=boots_samples, confidence=confidence,\\\n",
    "            output_units=output_units, ground_truths=ground_truths, GT_units=GT_units,\\\n",
    "            GT_nature = GT_nature,\\\n",
    "            experiment_name = exp_name, \\\n",
    "            output_path=output_path)\n",
    "    free()\n",
    "    \n",
    "# Benetan gordeta dauzelez df danak, al da exekuteu hau bukaeran tras hacerle un input a todos los df-s\n",
    "# Generate Excel files!\n",
    "# Excel for algorithms\n",
    "writer = StyleFrame.ExcelWriter(f'{output_path}/{exp_names[0]}/EXCEL_Results_per_Algorithm.xlsx')\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(pd.DataFrame({'Absolute Error':['Absolute_Error']})).to_excel(writer, sheet_name=exp_name, startcol=1)\n",
    "    StyleFrame(pd.DataFrame({'Times':['Times']})).to_excel(writer, sheet_name=exp_name, startcol=5)\n",
    "    sf = StyleFrame(pd.DataFrame(table_per_alg[exp_name].index.get_level_values(0)))\n",
    "    sf.set_column_width(columns=[1], width=55.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1)\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Absolute_Error'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.5)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1, startcol=1, float_format=\"%.5f\")\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Times'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name,  startrow=1, startcol=5, float_format=\"%.5f\")\n",
    "writer.save()\n",
    "\n",
    "free()\n",
    "# Excel for images\n",
    "writer = StyleFrame.ExcelWriter(f\"{output_path}/{exp_names[0]}/EXCEL_Results_per_Image.xlsx\")\n",
    "StyleFrame.A_FACTOR=10\n",
    "StyleFrame.P_FACTOR=0.9\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(table_per_image[exp_name]).set_row_height(1,50).to_excel(writer, best_fit=list(table_per_image[exp_name].columns), sheet_name=exp_name, index=False,  float_format=\"%.8f\")\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip $dont_use_experimental\n",
    "table_per_alg[exp_names[0]] # menos precision en fibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_experimental\n",
    "table_per_image[exp_names[0]][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Using a large simulated Noisy Image Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "# General pipeline settings\n",
    "output_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}\"\n",
    "output_units = 'deg'\n",
    "confidence = 90\n",
    "boots_samples = 10000\n",
    "X=302\n",
    "dtype = np.float64\n",
    "dtype_torch = torch.float64\n",
    "n_jobs=10\n",
    "\n",
    "\n",
    "num_image_pairs_test = 500\n",
    "\n",
    "\n",
    "\n",
    "if current_meta_block==2:\n",
    "    use_noisy = True\n",
    "elif current_meta_block==3:\n",
    "    use_noisy=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label\n",
    "    \n",
    "# Noisy Test set!\n",
    "GT_file_path_test_noisy = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_noisy =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST\"\n",
    "\n",
    "# Non-Noisy Test set!\n",
    "GT_file_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST\"\n",
    "\n",
    "\n",
    "random_seed = 666\n",
    "\n",
    "if use_noisy:\n",
    "    test_data = ImageDataset(GT_file_path_test_noisy, images_dir_path_test_noisy)\n",
    "else:\n",
    "    test_data = ImageDataset(GT_file_path_test_non_noisy, images_dir_path_test_non_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "np.random.seed(random_seed)\n",
    "random_indices_refs = np.random.choice(range(len(test_data)), num_image_pairs_test, replace=False)\n",
    "\n",
    "X21 = test_data[0][0].shape[1]\n",
    "X_references = np.zeros( (num_image_pairs_test, X21, X21), dtype=np.float32)\n",
    "y_references = np.zeros( (num_image_pairs_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_refs):\n",
    "    im, lab = test_data[idx]\n",
    "    X_references[j, :,:] = im[0]\n",
    "    y_references[j] = lab\n",
    "\n",
    "random_indices_pbs = np.random.choice(range(len(test_data)), num_image_pairs_test, replace=False)\n",
    "\n",
    "X_problems = np.zeros( (num_image_pairs_test, X21, X21), dtype=np.float32)\n",
    "y_problems = np.zeros( (num_image_pairs_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_pbs):\n",
    "    im, lab = test_data[idx]\n",
    "    X_problems[j, :,:] = im[0]\n",
    "    y_problems[j] = lab\n",
    "    \n",
    "image_pair_names = [f'REF_{ref_idx}_PB_{pb_idx}' for ref_idx, pb_idx in zip(random_indices_refs, random_indices_pbs)]\n",
    "\n",
    "ground_truths = y_problems-y_references\n",
    "ground_truths = np.array([angle_to_pi_pi(phi) for phi in ground_truths])/2\n",
    "\n",
    "del y_problems\n",
    "del y_references\n",
    "free()\n",
    "\n",
    "GT_units = 'rad'\n",
    "GT_nature = 'pol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simulation_Grav_Prepr_UMAP_Trained_wnoisy_DS_Noisy_Searc_NM', 'Simulation_Grav_Prepr_UMAP_Trained_wnoisy_DS_Noisy_Searc_P']\n",
      "> Passing Images from each Algorithm...\n"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_simulated\n",
    "\n",
    "table_per_alg={}\n",
    "table_per_image={}\n",
    "exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']# , 'Normalize_to_average', 'Sigmoid de parametros tal y cual']\n",
    "\n",
    "\n",
    "algorithm_lambda_list=[]\n",
    "algorithm_name_list = []\n",
    "\n",
    "from skimage import morphology\n",
    "\n",
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "emb_dims=10\n",
    "\n",
    "\n",
    "if current_block==1: # Experimental Embedder+KNN Regressor\n",
    "    def normalize_to_max_and_iX_input_output_flatten_knn(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=302, batch_size=100): # images expected to be [N_images, h, w]\n",
    "        out = np.zeros((images.shape[0], (2*X+1)**2), dtype=np.float64)\n",
    "        images= images.reshape(-1, X*2+1, X*2+1).astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            out[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch( torch.from_numpy(images[j:(j+batch_size)]).to(device), X, device).to('cpu').numpy().reshape(len(out[j:(j+batch_size)]), -1)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        return out\n",
    "    \n",
    "    if current_sub_block<9: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "    elif current_sub_block>8:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        \n",
    "\n",
    "    if current_sub_block==1 or current_sub_block==9:\n",
    "        # PCA -> Existe la incremental PCA por si es massa grande el dataset!\n",
    "        args = {'exp':'PCA','emb_dims':emb_dims, \"whiten\":True}\n",
    "        embedder = sk.decomposition.PCA(n_components=args['emb_dims'], whiten=args['whiten'], random_state=random_seed)\n",
    "        \n",
    "        if current_sub_block==1: # noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "    elif current_sub_block==2 or current_sub_block==10:\n",
    "        # KPCA\n",
    "        args = {'exp':'KPCA_rbf', 'emb_dims':emb_dims, 'kernel':'rbf', 'fit_inverse':True, 'max_iter':100}\n",
    "        # kernels: linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "        embedder = sk.decomposition.KernelPCA(n_components=args['emb_dims'], kernel=args['kernel'], \n",
    "                        fit_inverse_transform=args['fit_inverse'], max_iter=args['max_iter'], \n",
    "                                random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==2: # noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_19h47m1657907266.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_19h47m1657907266.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_14h39m1657888747.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_14h39m1657888747.sav\"\n",
    "            \n",
    "    elif current_sub_block==3 or current_sub_block==11:\n",
    "        # LLE \n",
    "        args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 200, \"emb_dims\": emb_dims, 'max_iter':100}\n",
    "        # Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "        embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "                      n_components=args['emb_dims'], max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==3: # noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "        elif current_sub_block==11: # non-noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==4 or current_sub_block==12:\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==4: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==12: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "        \n",
    "    elif current_sub_block==5 or current_sub_block==13:\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==13: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "                \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==14:\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==14: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "\n",
    "    elif current_sub_block==7 or current_sub_block==15:\n",
    "        args = {'exp':'RAW'}\n",
    "        embedder = lambda X : X\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "        elif current_sub_block==15: # non-noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "        \n",
    "    \n",
    "    text = \"noisy\" if current_sub_block<9 else \"non_noisy\"\n",
    "    if current_sub_block<8 or (current_sub_block>8 and current_sub_block<16): # scikit learn embedders\n",
    "        preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_name_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "        if args['exp']=='RAW':\n",
    "            trained_knn_alg.embedder_func.embedder.transform=trained_knn_alg.embedder_func.embedder\n",
    "            \n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_KNN_{args['exp']}_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "    \n",
    "    if current_sub_block==8 or current_sub_block==16:\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "        args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                            'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                            'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "        checkpoint = torch.load(saved_NN_path+f\"/NNs/{check_file}\")\n",
    "        triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=saved_NN_path+'/NNs/'+check_file, \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")\n",
    "        \n",
    "        if current_sub_block==8:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_08_07_2022_10h31m45s.sav\"\n",
    "        elif current_sub_block==16:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_07_07_2022_16h49m21s.sav\"\n",
    "        \n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_path_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func = triplet_embedder\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "\n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_Triplet_CNN_KNN_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "        free()\n",
    "     \n",
    "    \n",
    "elif current_block==2 or current_block==3: # Simulation Gravicenter or Geometric center\n",
    "    ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/STRUCTURE_Grid_R0_115_w0_115_Z_3.json\"\n",
    "    D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/SIMULATIONS/Dataset_R0_115_w0_115_Z_3.h5\"\n",
    "\n",
    "    simulation_fit_kw_args_NM = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Nelder-Mead',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "\n",
    "    simulation_fit_kw_args_P = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Powell',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "    \n",
    "    #text_DS = \"Noisy\" if current_block==2 else \"Non_Noisy\"\n",
    "    geomgrav = \"Grav\" if current_block==2 else \"Geom\"\n",
    "    run_alg = run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR if current_block==2 else run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center\n",
    "    if current_sub_block==1: # to max\n",
    "        # to max noisy and iX\n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                                  X=302, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "                ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        if current_meta_block<3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Noisy_Searc_P\",\n",
    "            ]\n",
    "        elif current_meta_block==3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_P\",\n",
    "            ]\n",
    "        \n",
    "          \n",
    "    elif current_sub_block==2: # to mean\n",
    "        # to max then to mean noisy and iX\n",
    "                               \n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                    images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=302, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "\n",
    "    elif current_sub_block==3: # sigmoid luts\n",
    "        \n",
    "        if current_block==2:\n",
    "            def preprocess_fct(images, in_are_dev_float, center,\n",
    "                    slope_squeezeness, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "                                                          , 302, device)\n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35), \n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35),\n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, center=0.1,\n",
    "                    slope_squeezeness=35, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block>3:\n",
    "        # to max noisy and iX\n",
    "        def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "            if not in_are_dev_float:\n",
    "                images = images.type(dtype).to(device)\n",
    "                free()\n",
    "            return compute_raws_to_centered_iXs_torch(\n",
    "                        images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                              X=302, device=device)\n",
    "        \n",
    "    if current_sub_block==4: # Triplet embedder\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "\n",
    "        checkpoint_path=saved_NN_path+f\"/NNs/{check_file}\"\n",
    "\n",
    "\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                          'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                          'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "\n",
    "        triplet_embedder_simulator = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_encoder['X'], \n",
    "                        feats_1=args_NN_encoder['feats_1'], feats_2=args_NN_encoder['feats_2'], \n",
    "                        feats_3=args_NN_encoder['feats_3'], feats_4=args_NN_encoder['feats_4'],\n",
    "                         prop1=args_NN_encoder['prop1'], prop2=args_NN_encoder['prop2'], prop3=args_NN_encoder['prop3'], \n",
    "                        av_pool1_div=args_NN_encoder['av_pool1_div'], conv4_feat_size=args_NN_encoder['conv4_feat_size'], \n",
    "                        av_pool2_div=args_NN_encoder['av_pool2_div'], \n",
    "                         out_fc_1=args_NN_encoder['out_fc_1'], out_fc_2=args_NN_encoder['out_fc2'],\n",
    "                         dropout_p1=args_NN_encoder['dropout_p1'], dropout_p2=args_NN_encoder['dropout_p2'] )\n",
    "        triplet_embedder_simulator.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        triplet_embedder_simulator.load_state_dict(checkpoint['model'])\n",
    "        triplet_embedder_simulator.eval()\n",
    "        \n",
    "\n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=triplet_embedder_simulator),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=triplet_embedder_simulator)\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block<8: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"noisy\"\n",
    "        \n",
    "    elif current_sub_block>7:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"non_noisy\"\n",
    "       \n",
    "    if current_sub_block==5 or current_sub_block==8: # NCA embedder\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==8: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==9: # UMAP embedder\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==7 or current_sub_block==10: # ISOMAP embedder\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "    \n",
    "    if current_sub_block>4:\n",
    "        preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) ),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) ),\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "else:\n",
    "    raise ValueError\n",
    "   \n",
    "   \n",
    "\n",
    "print(algorithm_name_list)\n",
    "\n",
    "# List the Algorithms to test\n",
    "for exp_name in exp_names:\n",
    "    table_per_image[exp_name], table_per_alg[exp_name] = run_benchmark_output_result_histograms_and_result_table(\\\n",
    "        algorithm_lambda_list=algorithm_lambda_list, algorithm_name_list=algorithm_name_list,\\\n",
    "         references=X_references, problems=X_problems, image_pair_names=image_pair_names,\\\n",
    "        generate_algorithm_plots=False,\\\n",
    "        generate_histograms=True, boots_samples=boots_samples, confidence=confidence,\\\n",
    "        output_units=output_units, ground_truths=ground_truths, GT_units=GT_units,\\\n",
    "        GT_nature = GT_nature,\\\n",
    "        experiment_name = exp_name, \\\n",
    "        output_path=output_path)\n",
    "    free()\n",
    "    \n",
    "    \n",
    "# Benetan gordeta dauzelez df danak, al da exekuteu hau bukaeran tras hacerle un input a todos los df-s\n",
    "# Generate Excel files!\n",
    "# Excel for algorithms\n",
    "writer = StyleFrame.ExcelWriter(f'{output_path}/{exp_names[0]}/EXCEL_Results_per_Algorithm.xlsx')\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(pd.DataFrame({'Absolute Error':['Absolute_Error']})).to_excel(writer, sheet_name=exp_name, startcol=1)\n",
    "    StyleFrame(pd.DataFrame({'Times':['Times']})).to_excel(writer, sheet_name=exp_name, startcol=5)\n",
    "    sf = StyleFrame(pd.DataFrame(table_per_alg[exp_name].index.get_level_values(0)))\n",
    "    sf.set_column_width(columns=[1], width=55.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1)\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Absolute_Error'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.5)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1, startcol=1, float_format=\"%.5f\")\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Times'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name,  startrow=1, startcol=5, float_format=\"%.5f\")\n",
    "writer.save()\n",
    "\n",
    "free()\n",
    "# Excel for images\n",
    "writer = StyleFrame.ExcelWriter(f\"{output_path}/{exp_names[0]}/EXCEL_Results_per_Image.xlsx\")\n",
    "StyleFrame.A_FACTOR=10\n",
    "StyleFrame.P_FACTOR=0.9\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(table_per_image[exp_name]).set_row_height(1,50).to_excel(writer, best_fit=list(table_per_image[exp_name].columns), sheet_name=exp_name, index=False,  float_format=\"%.8f\")\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "table_per_alg[exp_names[0]] # menos precision en fibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "table_per_image[exp_names[0]][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update State Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_meta_block))\n",
    "f.close()\n",
    "f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_block))\n",
    "f.close()\n",
    "f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_sub_block))\n",
    "f.close()\n",
    "\n",
    "import os\n",
    "if current_meta_block==1: # experimental\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<16: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "        if current_sub_block<10: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block<10: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "\n",
    "elif current_meta_block==2: # noisy simulated\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<16: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "        if current_sub_block<10: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block<10: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            \n",
    "elif current_meta_block==3: # experimental\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<16: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "        f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "        f.write(\"3\")\n",
    "        f.close()\n",
    "        f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "        f.write(\"1\")\n",
    "        f.close()\n",
    "\n",
    "    if current_block==3: # solo un subblock tb\n",
    "        raise ValueError\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "            \n",
    "restart_run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
