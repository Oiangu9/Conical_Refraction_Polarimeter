{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE TO COMPARE NON EMBEDDING NOR SIMULATOR ALGORITHMS\n",
    "### (I) Block: testing the pre-processing\n",
    "\n",
    "For preprocessing and Dataset in:\n",
    "- a) to max noisy\n",
    "- b) to mean noisy\n",
    "- c) Saturate at 0.05 noisy\n",
    "- d) Sigmoid lut noisy\n",
    "    - d.1 to d.12 : center in 0.1, 0.3, 0.5, 0.7\n",
    "- e) Opening\n",
    "- f) Local binarization\n",
    "        - goiko bixek con diferentes sizes para el elemento estructurante\n",
    "- e) to max non-noisy\n",
    "For each one run in a single RAM session the pipe of algorithms:\n",
    "- Rotation alg. (lanczos and cubic)\n",
    "- Mirror (lanczos and cubic)\n",
    "- Naive Relative Affine Rotation\n",
    "- Relative Rot Phase Correlation Polar Plot\n",
    "- Histogram Intra-Class variance\n",
    "- Gravicenter Regression\n",
    "\n",
    "### (II) Block: Blazquez and Cosine Square Fit\n",
    "\n",
    "(a) By preprocesisng just with to max noisy, in a single RAM session:\n",
    "- Cost function w in 0, 0.999, 1\n",
    "- Con cost w=1 and Ransac or no ransac (params for ransac aldatute)\n",
    "- Con gravicenter-geometric center or fitted coeff\n",
    "- Each with Powell and NM\n",
    "\n",
    "(b) The same for noisy in a new RAM session.\n",
    "\n",
    "### (III) Block: \n",
    "\n",
    "Each DS-NN pair in a different RAM session:\n",
    "(a) Noisy + CNN simple\n",
    "(b) Non-Noisy + CNN simple\n",
    "(c) Noisy + CNN+fc\n",
    "(d) Non-Noisy + CNN+fc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "def restart_run_all():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                IPython.notebook.kernel.restart();\n",
    "                setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 1000)\n",
    "                \n",
    "            </script>\n",
    "        '''\n",
    "    ))\n",
    "\n",
    "import ctypes\n",
    "import gc\n",
    "\n",
    "def free():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "    \n",
    "def skip(line, cell=None):\n",
    "    '''Skips execution of the current line/cell if line evaluates to True.'''\n",
    "    if eval(line):\n",
    "        return\n",
    "\n",
    "    get_ipython().run_cell(cell) \n",
    "\n",
    "def load_ipython_extension(shell):\n",
    "    '''Registers the skip magic when the extension loads.'''\n",
    "    shell.register_magic_function(skip, 'line_cell')\n",
    "\n",
    "def unload_ipython_extension(shell):\n",
    "    '''Unregisters the skip magic when the extension unloads.'''\n",
    "    del shell.magics_manager.magics['cell']['skip']\n",
    "    \n",
    "    \n",
    "load_ipython_extension(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 11\n"
     ]
    }
   ],
   "source": [
    "pipe=1\n",
    "if pipe==1:\n",
    "    pipe_name = \"Proof_of_concept\"\n",
    "    X=150\n",
    "elif pipe==2:\n",
    "    pipe_name = \"HeNe\"\n",
    "    X=302\n",
    "elif pipe==3:\n",
    "    pipe_name = \"LED_small_rho\"\n",
    "    X=422\n",
    "elif pipe==4:\n",
    "    pipe_name = \"LED_big_rho\"\n",
    "    X=402\n",
    "    \n",
    "\n",
    "try:\n",
    "    f = open(f\"META_BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_meta_block = int(f.read())\n",
    "    f.close()\n",
    "    f = open(f\"BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_block = int(f.read())\n",
    "    f.close()\n",
    "    f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_sub_block = int(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "except:\n",
    "    current_block = 1\n",
    "    current_sub_block = 1\n",
    "    current_meta_block = 1\n",
    "\n",
    "if current_block>2:\n",
    "    stopie\n",
    "    \n",
    "if current_meta_block>2:\n",
    "    hey\n",
    "    raise ValueError\n",
    "    \n",
    "print(current_meta_block, current_block, current_sub_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_meta_block==1: # use only experimental\n",
    "    dont_use_simulated = True\n",
    "    dont_use_experimental = False\n",
    "else: # use noisy or non noisy simulated! 2, 3 respectively\n",
    "    dont_use_simulated = False\n",
    "    dont_use_experimental = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm\n",
    "from SOURCE.CLASS_CODE_Image_Manager import Image_Manager\n",
    "from SOURCE.CLASS_CODE_Ad_Hoc_Optimizer import Ad_Hoc_Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from skimage.filters import threshold_local\n",
    "from styleframe import StyleFrame\n",
    "import sklearn as sk\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_to_pi_pi( angle): # convert any angle to range (-pi,pi]\\n\",\n",
    "    angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\\n\",\n",
    "    return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle\n",
    "\n",
    "\n",
    "def compute_expectation_CI(empirical_pdf, boots_samples, confidence):\n",
    "    resamplings=np.random.choice(empirical_pdf, size=( boots_samples, empirical_pdf.shape[0]))\n",
    "    boot_means=np.mean(resamplings, axis=1)\n",
    "    boot_stds=np.std(resamplings, axis=1)\n",
    "    observed_mean=empirical_pdf.mean()\n",
    "    observed_std=empirical_pdf.std()\n",
    "    boots_t=(observed_mean-boot_means)*np.sqrt(empirical_pdf.shape[0])/boot_stds\n",
    "    boots_t_percentiles = np.percentile(boots_t, q=((100-confidence)/2, confidence+(100-confidence)/2))\n",
    "    return observed_mean+boots_t_percentiles*observed_std/np.sqrt(empirical_pdf.shape[0])\n",
    "\n",
    "\n",
    "def plot_histograms_for(category, variable, final_results_df, statistic_df, conf, output_path, bins_log=True):\n",
    "    categories=len(final_results_df.groupby([category])) # category sería algorithm\n",
    "                            # variable serían time, absolute error etc.\n",
    "    columns=1 if categories==1 else 2 if (categories==2 or categories==4) else 3\n",
    "    rows=categories//3+(categories%3!=0)\n",
    "\n",
    "    fig=plt.figure(figsize=(7*columns, 5*rows))\n",
    "    if bins_log:\n",
    "        bins_main_exponents=np.linspace(-8.5, -3.5, 32 ).tolist()\n",
    "        bins_main_exponents=[1]+bins_main_exponents+[-1,0]\n",
    "        #bins_main_exponents=[1,-8.5, -8, -7.5, -7, -6.5,-6,-5.5,-5,-4.5,-4,-3.5,-1,0]\n",
    "        bins_main=10**np.array(bins_main_exponents)\n",
    "        bins_main[0]=0\n",
    "    else:\n",
    "        bins_main=13\n",
    "    axs=[]\n",
    "    maxy=0\n",
    "    for i, (group_var_val, group_df) in enumerate(final_results_df.groupby([category])):\n",
    "        axs.append(fig.add_subplot(rows,columns, i+1))\n",
    "        ns, b, p = axs[-1].hist(group_df[variable], bins=bins_main,\n",
    "                        label=f\"{category}={group_var_val}\", \n",
    "                        rwidth=1, align='mid', edgecolor=\"k\", alpha=0.6) # range=(0,0.4)\n",
    "        if bins_log:\n",
    "            axs[-1].set_xscale('log')\n",
    "        axs[-1].grid(True)\n",
    "        axs[-1].axvline(x=statistic_df[variable][f'CI_{conf}_low'][group_var_val], color='m',\n",
    "                        linestyle='--', label=f'mean {conf} CI', alpha=0.6)\n",
    "        axs[-1].axvline(x=statistic_df[variable][f'CI_{conf}_up'][group_var_val], color='m', \n",
    "                        linestyle='--', alpha=0.6)\n",
    "        quantiles=np.percentile(group_df[variable], q=((100-conf)/2, conf+(100-conf)/2))\n",
    "        axs[-1].axvline(x=quantiles[0], color='r', linestyle='--', label=f'{conf} quantiles')\n",
    "        axs[-1].axvline(x=quantiles[1], color='r', linestyle='--')\n",
    "        axs[-1].set_title(f\"mu {conf}% CI:\\n ({statistic_df[variable][f'CI_{conf}_low'][group_var_val]}, \\\n",
    "                          {statistic_df[variable][f'CI_{conf}_up'][group_var_val]})\")\n",
    "        axs[-1].legend()\n",
    "        maxy = np.max(ns) if np.max(ns)>maxy else maxy\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(0,maxy)\n",
    "    #fig.supylabel('common_y')\n",
    "    fig.suptitle(f\"Histograms for {variable}\")\n",
    "    #fig.suptitle(f\"Histogrms for {variable} \\n\\n Experiment: {experiment_name}\\n\\n\\n The x axes represent the smallest absolute difference between the theoretical\\n angle difference and the found angle difference, among the employed algorithms\")\n",
    "\n",
    "    os.makedirs(f\"{output_path}/HISTOGRAMS/\", exist_ok=True)\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig(f\"{output_path}/HISTOGRAMS/Histogram_for_{variable}.png\", bbox_inches='tight')\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "times = {}\n",
    "predicted_delta_phiCRs = {}\n",
    "\n",
    "def run_benchmark_output_result_histograms_and_result_table( algorithm_lambda_list, algorithm_name_list,\n",
    "                                            references, problems, image_pair_names, generate_algorithm_plots,\n",
    "                                            generate_histograms, boots_samples=10000, confidence=95,\n",
    "                                            output_units='rad', ground_truths=None, GT_units=None,\n",
    "                                            GT_nature = 'phiCR',\n",
    "                                            experiment_name = None, output_path=None, batch_size=50):\n",
    "    if experiment_name is not None:\n",
    "        output_path = f\"{output_path}/{experiment_name}/\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "    # GTs should be in [-pi, pi] or [-180, 180]\n",
    "    global times\n",
    "    global predicted_delta_phiCRs\n",
    "    \n",
    "    conv = 180/np.pi if output_units=='deg' else 1\n",
    "    convGT = 180/np.pi if (output_units=='deg' and GT_units=='rad') else \\\n",
    "        np.pi/180 if (output_units=='rad' and GT_units=='deg') else 1\n",
    "    print(\"> Passing Images from each Algorithm...\")\n",
    "    for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "        if output_path is not None and generate_algorithm_plots:\n",
    "            dir_for_alg = output_path+f\"/{alg_name}/\"\n",
    "            os.makedirs( dir_for_alg, exist_ok=True )\n",
    "        else:\n",
    "            dir_for_alg = None\n",
    "        \n",
    "        predicted_delta_phiCRs[alg_name]={}\n",
    "        times[alg_name]={}\n",
    "        # por si por ejemplo ransac no encuentra ningun consenso y salta un error\n",
    "        for j in range(0, references.shape[0], batch_size):\n",
    "\n",
    "            batch_predicted_delta_phiCRs, batch_times =  algorithm(\n",
    "                    references[j:(j+batch_size)], problems[j:(j+batch_size)], \n",
    "                    image_pair_names[j:(j+batch_size)], dir_for_alg)\n",
    "            predicted_delta_phiCRs[alg_name].update(batch_predicted_delta_phiCRs)\n",
    "            times[alg_name].update(batch_times)\n",
    "            free()\n",
    "        '''\n",
    "        except:\n",
    "            for imn in image_pair_names:\n",
    "                predicted_delta_phiCRs[alg_name][imn]=0\n",
    "                times[alg_name][imn]=0\n",
    "        '''\n",
    "        \n",
    "        print(f\" - Algorithm {alg_name} done!\")\n",
    "        try: # for the Carles algorithm to receive different arguments with a lambda function, en fin\n",
    "            global k\n",
    "            k+=1\n",
    "        except:\n",
    "            pass\n",
    "        free()\n",
    "        \n",
    "    print(\"\\n> Rearranging results in Tables and outputting to Excels...\")\n",
    "    if output_path is not None:\n",
    "        json.dump({'image_pair_names':image_pair_names, 'predicted_delta_phiCRs':predicted_delta_phiCRs,\n",
    "              'times':times}, open( f\"{output_path}/RAW_results.json\", \"w\"))\n",
    "    # Rearrange the result to our desired Table and unit formats\n",
    "    image_ids = []\n",
    "    image_names = []\n",
    "    algorithm_names = []\n",
    "    delta_phiCRs = []\n",
    "    delta_pols = []\n",
    "    timess = []\n",
    "    GTs = []\n",
    "    abs_errors = []\n",
    "    free()\n",
    "    switch_dif = 90 if output_units=='deg' else np.pi/2\n",
    "    max_diff = 2*switch_dif\n",
    "    # if abs dif is bigger than 90 then the true error is 180-that number for its the smallest plane difference in angle!\n",
    "    for idx, image_pair_name in enumerate(image_pair_names):\n",
    "        for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "            image_ids.append(idx)\n",
    "            algorithm_names.append(alg_name)\n",
    "            image_names.append(image_pair_name)\n",
    "            delta_phiCRs.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][image_pair_name]) ) \n",
    "            delta_pols.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][image_pair_name])/2.0 )\n",
    "            timess.append(times[alg_name][image_pair_name])\n",
    "            if ground_truths is not None:\n",
    "                GTs.append(convGT*ground_truths[idx])\n",
    "                if GT_nature=='phiCR':\n",
    "                    abs_errors.append( np.abs(delta_phiCRs[-1]-convGT*ground_truths[idx]) )\n",
    "                else: # then GT is of polarization\n",
    "                    abs_dif = np.abs(delta_pols[-1]-convGT*ground_truths[idx])\n",
    "                    if abs_dif>switch_dif:\n",
    "                        abs_er = max_diff - abs_dif\n",
    "                    else:\n",
    "                        abs_er = abs_dif\n",
    "                    abs_errors.append( abs_er )\n",
    "                #correct_decimals.append() # beittu HISTOGRAMAGAZ batera zelan eitten zendun hau!\n",
    "    table_per_image = pd.DataFrame.from_dict({'ID':image_ids, 'Image_Pair_Name':image_names, 'Algorithm':algorithm_names,\n",
    "                                   'Predicted_Delta_PhiCRs':delta_phiCRs, 'Pred_Delta_Polarizt':delta_pols,\n",
    "                                   'Times':timess, f'Ground_Truth_{GT_nature}':GTs, 'Absolute_Error':abs_errors})\n",
    "    if output_path is not None:\n",
    "        table_per_image.to_pickle( f\"{output_path}/Table_Per_Image_All.pkl\")\n",
    "    print(\" - Table per images done!\")    \n",
    "    free()\n",
    "\n",
    "    # Group by algorithm and generate statistics by analyte (times, absolute_errors etc.)\n",
    "    groups = table_per_image.groupby('Algorithm')\n",
    "    stdv = groups[['Absolute_Error', 'Times']].std().fillna(0.0)\n",
    "    means = groups[['Absolute_Error', 'Times']].mean()\n",
    "    # Compute confidence intervals using bootstrap\n",
    "    CIs_time = {}\n",
    "    CIs_abs_er = {}\n",
    "    for alg_name, df in table_per_image.groupby('Algorithm'):\n",
    "        CIs_time[alg_name] = compute_expectation_CI(df['Times'],boots_samples, confidence)\n",
    "        CIs_abs_er[alg_name] = compute_expectation_CI(df['Absolute_Error'], boots_samples, confidence)\n",
    "        free()\n",
    "    CIs_time_df = pd.DataFrame(index=CIs_time.keys(), data=CIs_time.values(), columns=[f'CI_{confidence}_l', f'CI_{confidence}_u'])\n",
    "    CIs_abs_er_df = pd.DataFrame(index=CIs_abs_er.keys(), data=CIs_abs_er.values(), columns=[f'CI_{confidence}_l', f'CI_{confidence}_u'])\n",
    "    \n",
    "    ae = pd.concat([means['Absolute_Error'], stdv['Absolute_Error'],\n",
    "                    CIs_abs_er_df[f'CI_{confidence}_l'], CIs_abs_er_df[f'CI_{confidence}_u']],\n",
    "                   keys=['Mean', 'Standard_Dev', f'CI_{confidence}_low', f'CI_{confidence}_up'],axis=1)\n",
    "    ts = pd.concat([means['Times'], stdv['Times'],\n",
    "                    CIs_time_df[f'CI_{confidence}_l'], CIs_time_df[f'CI_{confidence}_u']],                   \n",
    "                   keys=['Mean', 'Standard_Dev', f'CI_{confidence}_low', f'CI_{confidence}_up'],axis=1)\n",
    "    table_per_alg = pd.concat([ae, ts], keys=['Absolute_Error', 'Times'], axis=1)    \n",
    "    free()\n",
    "\n",
    "    if output_path is not None:\n",
    "        table_per_image.to_pickle( f\"{output_path}/Table_Per_Algorithm_Statistics.pkl\")\n",
    "        print(\" - Table per algorithm done!\")    \n",
    "        if generate_histograms:\n",
    "            print(\"\\n> Generating histograms...\")\n",
    "            plot_histograms_for('Algorithm', 'Absolute_Error', table_per_image, table_per_alg, confidence, output_path, bins_log=False)\n",
    "            plot_histograms_for('Algorithm', 'Times', table_per_image, table_per_alg, confidence, output_path, bins_log=False)\n",
    "            print(\"DONE!\")\n",
    "    return table_per_image, table_per_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    return centered_image\n",
    "\n",
    "\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                              iX_dev='cpu', out_dev='cpu', X=X): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                                     iX_dev='cpu', out_dev='cpu', X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                                      iX_dev='cpu', out_dev='cpu', X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    means = np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_max_and_iX(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=X): # images expected to be [N_images, h, w]\n",
    "    images= images.astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_and_iX(images, dtype=np.float64,\n",
    "                     iX_dev='cpu', out_dev='cpu', X=X): # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def sigmoid_lut_and_iX( images, center=0.5, slope_squeezeness=0.085, max_val=255, dtype=np.float64, X=X ):\n",
    "    lut = max_val/(1+np.exp(-slope_squeezeness*(np.arange(max_val+1)-center*max_val)))\n",
    "    images = (lut[ images ]).astype(dtype)\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=X): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.abmax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    means=torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_max_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=torch.float32, X=X): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=torch.float32, X=X): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/torch.mean(images, axis=(-1,-2), keepdims=True), X, device)\n",
    "\n",
    "\n",
    "def sigmoid_lut_using_numpy_normalize_and_iX( images, in_are_dev, device, center=0.5, \n",
    "                       slope_squeezeness=0.085, max_val_lut_process=255, lut_process_dtype=torch.uint8,\n",
    "                       output_dtype=torch.float64, X=X ):\n",
    "    if not in_are_dev:\n",
    "        images = images.to(device)\n",
    "    images = (max_val_lut_process*(images.type(torch.float64)/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)))\n",
    "                 ).type(lut_process_dtype)\n",
    "    \n",
    "    lut = (max_val_lut_process/(1+np.exp(-slope_squeezeness*(np.arange(max_val_lut_process+1)-\n",
    "                                                               center*max_val_lut_process))))\n",
    "    images = torch.from_numpy(lut[ images.to('cpu').numpy() ]).to(device).type(output_dtype)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "# Ojo! se usan los valores float del lut como valores de la imagen! (no los cuantizados!)\n",
    "\n",
    "def sigmoid_no_lut_normalize_and_iX( images, in_are_dev_float, device, center=0.7, \n",
    "                       slope_squeezeness=50, dtype=torch.float64, X=X ):\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)    \n",
    "    images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "    images = 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "    return compute_raws_to_centered_iXs_torch(images, X, device) # we need not noramlize them again if center if sigmoid chosen with sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) ROTATION ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_rotation_algorithm(references, problems, image_pair_names, preprocess_fct, search_algorithm, \n",
    "                       search_alg_kw_args, rotation_alg_kw_args, out_plot_path=None, rotation_algorithm=None):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "    if rotation_algorithm is None:\n",
    "        rotation_algorithm = Rotation_Algorithm(image_loader,\n",
    "            rotation_alg_kw_args['theta_min_Rot'], rotation_alg_kw_args['theta_max_Rot'], \n",
    "            rotation_alg_kw_args['interpolation_flag'],\n",
    "            rotation_alg_kw_args['initial_guess_delta_rad'], rotation_alg_kw_args['use_exact_gravicenter'], \n",
    "                                                initialize_it=False)\n",
    "    image_names = []\n",
    "    for mode in ['Ref', 'Pb']:\n",
    "        for image_pair_name in image_pair_names:\n",
    "            image_names.append(f\"{mode}__{image_pair_name}\")\n",
    "    # charge the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "    free()\n",
    "\n",
    "    image_loader.import_converted_images_as_array(images, image_names)\n",
    "    # Execute the Rotation Algorithm:\n",
    "    rotation_algorithm.interpolation_flag=rotation_alg_kw_args['interpolation_flag']\n",
    "    rotation_algorithm.reInitialize(image_loader)\n",
    " \n",
    "    free()\n",
    "\n",
    "    # run it\n",
    "    if search_algorithm=='quadratic':\n",
    "        rotation_algorithm.quadratic_fit_search(search_alg_kw_args['precision_quadratic'], \n",
    "                            search_alg_kw_args['max_it_quadratic'], search_alg_kw_args['cost_tolerance_quadratic'])\n",
    "    else: # 'fibo'\n",
    "        rotation_algorithm.fibonacci_ratio_search(search_alg_kw_args['precision_fibonacci'],\n",
    "                    search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])    \n",
    "    if out_plot_path is not None:\n",
    "        rotation_algorithm.save_result_plots_fibonacci_or_quadratic(out_plot_path)\n",
    "\n",
    "    angles = list(rotation_algorithm.angles.values())\n",
    "    ts = list(rotation_algorithm.times.values())\n",
    "    \n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i+len(image_pair_names)]) - angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = ts[i+len(image_pair_names)] + ts[i]\n",
    "            \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) MIRROR FLIP ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_mirror_flip_algorithm(references, problems, image_pair_names, preprocess_fct, search_algorithm, \n",
    "                       search_alg_kw_args, mirror_alg_kw_args, out_plot_path=None, mirror_algorithm=None):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    image_loader = Image_Manager(mode=X, interpolation_flag=None)\n",
    "    if mirror_algorithm is None:\n",
    "        mirror_algorithm = Mirror_Flip_Algorithm(image_loader,\n",
    "            mirror_alg_kw_args['theta_min_Mir'], mirror_alg_kw_args['theta_max_Mir'], \n",
    "            mirror_alg_kw_args['interpolation_flag'],\n",
    "            mirror_alg_kw_args['initial_guess_delta_rad'], method=\"aff\", left_vs_right=True, \n",
    "            use_exact_gravicenter=mirror_alg_kw_args['use_exact_gravicenter'], initialize_it=False)\n",
    "\n",
    "    image_names = []\n",
    "    for mode in ['Ref', 'Pb']:\n",
    "        for image_pair_name in image_pair_names:\n",
    "            image_names.append(f\"{mode}__{image_pair_name}\")\n",
    "    # charge the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "    free()\n",
    "\n",
    "    image_loader.import_converted_images_as_array(images, image_names)\n",
    "    # Execute the Rotation Algorithm:\n",
    "    mirror_algorithm.interpolation_flag=mirror_alg_kw_args['interpolation_flag']\n",
    "    mirror_algorithm.reInitialize(image_loader)\n",
    "    # run it\n",
    "    if search_algorithm=='quadratic':\n",
    "        mirror_algorithm.quadratic_fit_search(search_alg_kw_args['precision_quadratic'], \n",
    "                            search_alg_kw_args['max_it_quadratic'], search_alg_kw_args['cost_tolerance_quadratic'])\n",
    "    else: # 'fibo'\n",
    "        mirror_algorithm.fibonacci_ratio_search(search_alg_kw_args['precision_fibonacci'],\n",
    "                    search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])    \n",
    "    free()\n",
    "\n",
    "    if out_plot_path is not None:\n",
    "        mirror_algorithm.save_result_plots_fibonacci_or_quadratic(out_plot_path)\n",
    "    \n",
    "    angles = list(mirror_algorithm.angles.values())\n",
    "    ts = list(mirror_algorithm.times.values())\n",
    "    \n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i+len(image_pair_names)]) - angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = ts[i+len(image_pair_names)] + ts[i]\n",
    "    \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (D) Naive Affine Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Affine_Rotation():\n",
    "    def __init__(self, X, min_angle, max_angle, interpolation_flag, initial_guess_delta, use_exact_gravicenter):\n",
    "        #Polarization_Obtention_Algorithm.__init__(self,image_loader, use_exact_gravicenter)\n",
    "        #self.original_images = image_loader\n",
    "        self.mode = X\n",
    "        self.use_exact_gravicenter=use_exact_gravicenter\n",
    "        self.angles={}\n",
    "        self.precisions={}\n",
    "        \n",
    "        self.interpolation_flag = interpolation_flag\n",
    "        self.min_angle = min_angle\n",
    "        self.max_angle = max_angle\n",
    "        self.initial_guess_delta = initial_guess_delta\n",
    "        self.computed_points={}\n",
    "        self.optimums={}\n",
    "        self.optimals={}\n",
    "        self.times={}\n",
    "        self.cols=np.broadcast_to( np.arange(self.mode*2+1), (self.mode*2+1,self.mode*2+1)) #[h,w]\n",
    "        self.optimizer = Ad_Hoc_Optimizer(min_angle, max_angle, initial_guess_delta, self.evaluate_image_rotation)\n",
    "        \n",
    "    def reInitialize_and_input_images(self, ref_images, pb_images, image_pair_names):     \n",
    "        # Reference image in position k is the reference for the problem image in position k\n",
    "        # both arrays will be [N_im, H,W]            \n",
    "        self.reference_images = ref_images\n",
    "        self.problem_images = pb_images\n",
    "        self.image_pair_names = image_pair_names\n",
    "        \n",
    "        self.angles={}\n",
    "        self.precisions={}\n",
    "        self.computed_points={}\n",
    "        self.optimums={}\n",
    "        self.optimals={}\n",
    "        self.times={}\n",
    "        self.cols=np.broadcast_to( np.arange(self.mode*2+1), (self.mode*2+1,self.mode*2+1)) #[h,w]\n",
    "        \n",
    "        if self.use_exact_gravicenter: # GRAVICENTRUM KALKULEU!\n",
    "            self.grav_ref = self.compute_intensity_gravity_centers(ref_images) #[N_images, 2(h,w)]\n",
    "            self.grav_pb = self.compute_intensity_gravity_centers(pb_images)\n",
    "        else:\n",
    "            # gravicenter the same for all\n",
    "            self.grav=np.array(2*[self.mode])+0.5\n",
    "\n",
    "    def angle_to_pi_pi(self, angle): # convert any angle to range ()-pi,pi]\n",
    "        angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\n",
    "        return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle\n",
    "\n",
    "    \n",
    "    def compute_intensity_gravity_centers(self, images):\n",
    "        \"\"\"\n",
    "            Expects input images to be an array of dimensions [N_images, h, w].\n",
    "            It will return an array of gravity centers [N_images, 2(h,w)] in pixel coordinates\n",
    "            Remember that pixel coordinates are set equal to numpy indices, so they being at 0\n",
    "        \"\"\"\n",
    "        # image wise total intensity and marginalized inensities for weighted sum\n",
    "        # (preserves axis 0, where images are stacked)\n",
    "        intensity_in_w = np.sum(images, axis=1) # weights for x [N_imgs, raw_width]\n",
    "        intensity_in_h = np.sum(images, axis=2) # weights for y [N_imgs, raw_height]\n",
    "        total_intensity = intensity_in_h.sum(axis=1)\n",
    "\n",
    "        # Compute mass center for intensity (in each image axis)\n",
    "        # [N_images, 2] (h_center,w_center)\n",
    "        return np.nan_to_num( np.stack(\n",
    "            (np.dot(intensity_in_h, np.arange(images.shape[-2]))/total_intensity,\n",
    "             np.dot(intensity_in_w, np.arange(images.shape[-1]))/total_intensity)\n",
    "            ).transpose() )\n",
    "\n",
    "    def rotate_image_by(self, image_array, angle, center):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=self.interpolation_flag).astype(image_array.dtype)\n",
    "     \n",
    "    def translate_image_and_rotate_by(self, image_array, angle, rotation_center, translation):\n",
    "        \"\"\"\n",
    "        first translation then rotation about that special center is done\n",
    "        rotation_center is expected to be a point [h,w]\n",
    "        the translation is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64(\n",
    "                [[a, b, translation[1]*a+translation[0]*b+rotation_center[1]*(1-a)-rotation_center[0]*b],\n",
    "                 [-b, a, -translation[1]*b+translation[0]*a+rotation_center[1]*b+rotation_center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=self.interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "\n",
    "    def evaluate_image_rotation(self, reference_image, angle, image_to_rotate, center_ref, center_pb):\n",
    "        return np.sum(np.abs(self.translate_image_and_rotate_by(\n",
    "                                image_to_rotate, angle, center_ref, center_ref-center_pb)\n",
    "                             -reference_image))\n",
    "\n",
    "\n",
    "    def given_axis_angle_greater_minus_lower(self, angle, image, center):\n",
    "        # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "        # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "        mask=np.less(self.cols.swapaxes(0,1), np.tan(-angle)*(self.cols-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "            # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "        return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "    def get_polarization_angle(self, angle, image, center):\n",
    "        \"\"\"\n",
    "        All the mirror methods have the problem that we only get the\n",
    "        correct angle up to an angle pi. In order to know which is the\n",
    "        angle to the maximum of the ring (and not the minimum) a final\n",
    "        subtle check is required.\n",
    "        \"\"\"\n",
    "        #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "        if angle==0 or abs(angle)==np.pi:\n",
    "            angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "        diff=self.given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center)\n",
    "\n",
    "        if diff>0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "            return angle+np.pi if angle<0 else angle\n",
    "        else:\n",
    "            return angle-np.pi if angle>0 else angle\n",
    "\n",
    "    def brute_force_search(self, angle_steps, zoom_ratios):\n",
    "        \"\"\"\n",
    "        What does this exactly do\n",
    "\n",
    "        Arguments\n",
    "        --------\n",
    "        - angle_steps (list): A list of the different angle steps to take in each of the sweeps.\n",
    "            Expected N, where N is the number of sweeps that will be performed. The first one is\n",
    "            expected to be the coarsest grain and they should be ordered from big to smallest.\n",
    "            The last step in the list will define the precision of the found minimum. The angle\n",
    "            steps are expected to be in (0, 2pi)\n",
    "\n",
    "        - zoom_ratios (list): A list of the interval reductions that will be held after each sweep\n",
    "            around the current best candidate for the minimum. There should be N-1 elements and\n",
    "            they should be numbers in (0,1].\n",
    "\n",
    "        \"\"\"\n",
    "        zoom_ratios.append(1) #to avoid out of index in the last iteration\n",
    "        for im, image_pair_name in enumerate(self.image_pair_names):\n",
    "            name=f\"Brute_Force_{image_pair_name}\"\n",
    "            (self.times[name],\n",
    "            self.computed_points[name],\n",
    "            self.optimals[name],\n",
    "            self.optimums[name],\n",
    "            self.precisions[name]) = self.optimizer.brute_force_search(\n",
    "                    angle_steps, zoom_ratios,\n",
    "                    self.reference_images[im], (self.problem_images[im],\n",
    "                    self.grav_ref[im] if self.use_exact_gravicenter else self.grav,\n",
    "                    self.grav_pb[im] if self.use_exact_gravicenter else self.grav\n",
    "                            ))\n",
    "            self.optimals[name][f\"Stage_{len(angle_steps)-1}\"] =self.angle_to_pi_pi(self.optimals[name][f\"Stage_{len(angle_steps)-1}\"])\n",
    "            self.angles[name]=-self.get_polarization_angle(self.optimals[name][f\"Stage_{len(angle_steps)-1}\"], self.images_float[im],\n",
    "                self.grav[im] if self.use_exact_gravicenter else self.grav\n",
    "            )\n",
    "\n",
    "\n",
    "    def fibonacci_ratio_search(self, precision, maximum_points, cost_tol):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        --------\n",
    "        - precision (float): Half the length of the interval achieved in the last step. It will be\n",
    "            the absolute error to which we compute the minimum of the funtion. Note however that\n",
    "            the precision will have a minimum depending on the image quality and the minimum\n",
    "            rotation arithmetics. Noise or discretization can induce plateaus in the minimum.\n",
    "            Therefore, if at some point the three points have the same cost function the algorithm\n",
    "            will stop: the cost function has arrived to the plateau. In that case the precision will\n",
    "            be outputed accordingly.\n",
    "\n",
    "        - maximum_points (int): Maximum number of points to use in the minimum search. It is also\n",
    "            the number of times to make an interval reduction.\n",
    "\n",
    "        - cost_tol (float): Maximum relative difference between the cost function active points\n",
    "            tolerated before convergence assumption.\n",
    "        \"\"\"\n",
    "\n",
    "        for im, image_pair_name in enumerate(self.image_pair_names):\n",
    "            name=f\"Fibonacci_Search_{image_pair_name}\"\n",
    "            (self.times[name],\n",
    "            self.computed_points[name],\n",
    "            optimal,\n",
    "            self.optimums[name],\n",
    "            self.precisions[name])=         self.optimizer.fibonacci_ratio_search(\n",
    "                    precision, maximum_points, cost_tol,\n",
    "                    self.reference_images[im], (self.problem_images[im],\n",
    "                    self.grav_ref[im] if self.use_exact_gravicenter else self.grav,\n",
    "                    self.grav_pb[im] if self.use_exact_gravicenter else self.grav\n",
    "                                                                   ))\n",
    "            self.optimals[name]=self.angle_to_pi_pi(optimal)\n",
    "            #self.angles[name]=self.get_polarization_angle(self.optimals[name]/2, self.images_float[im],\n",
    "            #    self.grav[im] if self.use_exact_gravicenter else self.grav)\n",
    "            self.angles[name]=-self.optimals[name]\n",
    "\n",
    "    def quadratic_fit_search(self, precision, max_iterations, cost_tol):\n",
    "        \"\"\"\n",
    "        Quadratic\n",
    "\n",
    "        Arguments\n",
    "        --------\n",
    "        - precision (float): Half the length of the interval achieved in the last step. It will be\n",
    "            the absolute error to which we compute the minimum of the funtion. Note however that\n",
    "            the precision will have a minimum depending on the image quality and the minimum\n",
    "            rotation arithmetics. Noise or discretization can induce plateaus in the minimum.\n",
    "            Therefore, if at some point the three points have the same cost function the algorithm\n",
    "            will stop: the cost function has arrived to the plateau. In that case the precision will\n",
    "            be outputed accordingly.\n",
    "\n",
    "        - max_iterations (int): Number of maximum iterations of quadratic function fit and\n",
    "            minimization to tolerate.\n",
    "\n",
    "        - cost_tol (float): Maximum relative difference between the cost function active points\n",
    "            tolerated before convergence assumption.\n",
    "\n",
    "        \"\"\"\n",
    "        for im, image_pair_name in enumerate(self.image_pair_names):\n",
    "            name=f\"Quadratic_Search_{image_pair_name}\"\n",
    "            (self.times[name],\n",
    "            self.computed_points[name],\n",
    "            optimal,\n",
    "            self.optimums[name],\n",
    "            self.precisions[name])=self.optimizer.quadratic_fit_search(\n",
    "                precision, max_iterations, cost_tol,\n",
    "                self.reference_images[im], (self.problem_images[im],\n",
    "                    self.grav_ref[im] if self.use_exact_gravicenter else self.grav,\n",
    "                    self.grav_pb[im] if self.use_exact_gravicenter else self.grav))\n",
    "            self.optimals[name]=self.angle_to_pi_pi(optimal)\n",
    "            #self.angles[name]=self.get_polarization_angle(self.optimals[name]/2, self.images_float[im],\n",
    "            #    self.grav[im] if self.use_exact_gravicenter else self.grav)\n",
    "            self.angles[name] = -self.optimals[name]\n",
    "\n",
    "    def save_result_plots_fibonacci_or_quadratic(self, output_path):\n",
    "        \"\"\"\n",
    "        Save the resulting explored points in cost function vs angle, together with the info\n",
    "        about the optimization.\n",
    "        \"\"\"\n",
    "        os.makedirs(f\"{output_path}/Rotation_Algorithm/\", exist_ok=True)\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        for name, computed_points in self.computed_points.items():\n",
    "            ax.plot(computed_points[:,0], computed_points[:,1], 'o', label=name)\n",
    "            ax.set_title(f\"Polarization Angle = {self.angles[name]}+-{self.precisions[name]/2} rad\\nOptimal={self.optimals[name]}+-{self.precisions[name]} rad\\nComputed Points={len(computed_points)} . Time Required={self.times[name]}s\")\n",
    "            ax.set_xlabel(\"Angle (rad)\")\n",
    "            ax.set_ylabel(\"|Rotated-Original|\")\n",
    "            #ax.set_yscale('log')\n",
    "            ax.grid(True)\n",
    "            plt.savefig(f\"{output_path}/Rotation_Algorithm/{name}.png\")\n",
    "            ax.clear()\n",
    "\n",
    "    def save_result_plots_brute_force(self, output_path):\n",
    "        os.makedirs(f\"{output_path}/Rotation_Algorithm/\", exist_ok=True)\n",
    "        fig, axes = plt.subplots(len(next(iter(self.times.values())).values()), 1, figsize=(10,15))\n",
    "        fig.tight_layout(pad=5.0)\n",
    "        for name, computed_points in self.computed_points.items():\n",
    "            for stage, ax in enumerate(axes):\n",
    "                ax.clear()\n",
    "                ax.plot(computed_points[f\"Stage_{stage}\"][:,0],\n",
    "                    computed_points[f\"Stage_{stage}\"][:,1], 'o', markersize=2,\n",
    "                    label=f\"{name}_Stage_{stage}\")\n",
    "                ax.set_title(f\"STAGE {stage}: Optimal angle={self.optimals[name][f'Stage_{stage}']}+-{self.precisions[name][f'Stage_{stage}']} rad\\nComputed Points={len(computed_points[f'Stage_{stage}'])}. Time Required={self.times[name][f'Stage_{stage}']}s\")\n",
    "                ax.set_xlabel(\"Angle (rad)\")\n",
    "                ax.set_ylabel(\"|Rotated-Original|\")\n",
    "                #ax.set_yscale('log')\n",
    "                ax.grid(True)\n",
    "            fig.suptitle(f\"Polarization angle=Polarization Angle={self.angles[name]}+-{self.precisions[name][f'Stage_{len(axes)-1}']/2} rad\")\n",
    "            plt.savefig(f\"{output_path}/Rotation_Algorithm/{name}.png\")\n",
    "            self.precisions[name]=self.precisions[name][f'Stage_{stage}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_naive_affine_rotation_algorithm(references, problems, image_pair_names, preprocess_fct, search_algorithm, \n",
    "                       search_alg_kw_args, rotation_alg_kw_args, out_plot_path=None, rotation_algorithm=None):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    if rotation_algorithm is None:\n",
    "        rotation_algorithm = Naive_Affine_Rotation( rotation_alg_kw_args['X'],\n",
    "            rotation_alg_kw_args['theta_min_Rot'], rotation_alg_kw_args['theta_max_Rot'], \n",
    "            rotation_alg_kw_args['interpolation_flag'],\n",
    "            rotation_alg_kw_args['initial_guess_delta_rad'], rotation_alg_kw_args['use_exact_gravicenter'])\n",
    "        \n",
    "    # charge the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "\n",
    "    references = images[:references.shape[0]]\n",
    "    problems = images[references.shape[0]:]\n",
    "    # Execute the Rotation Algorithm:\n",
    "\n",
    "    rotation_algorithm.reInitialize_and_input_images(references, problems, image_pair_names)\n",
    "    # run it\n",
    "    if search_algorithm=='quadratic':\n",
    "        rotation_algorithm.quadratic_fit_search(search_alg_kw_args['precision_quadratic'], \n",
    "                            search_alg_kw_args['max_it_quadratic'], search_alg_kw_args['cost_tolerance_quadratic'])\n",
    "    else: # 'fibo'\n",
    "        rotation_algorithm.fibonacci_ratio_search(search_alg_kw_args['precision_fibonacci'],\n",
    "                    search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])    \n",
    "    if out_plot_path is not None:\n",
    "        rotation_algorithm.save_result_plots_fibonacci_or_quadratic(out_plot_path)\n",
    "    \n",
    "    angles = list(rotation_algorithm.angles.values())\n",
    "    ts = list(rotation_algorithm.times.values())\n",
    "    \n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = ts[i]\n",
    "            \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E) Fourier Space Phase Correlation for Polar Coordinate Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from skimage.transform import warp_polar\n",
    "from time import time\n",
    "\n",
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_polar_fourier_phase_correlation(references, problems, image_pair_names, preprocess_fct, \n",
    "                            get_grav_fct, polar_fourier_alg_kw_args):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "     \n",
    "    # preprocess the images the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "\n",
    "    references = images[:references.shape[0]]\n",
    "    problems = images[references.shape[0]:]\n",
    "    # Execute the Rotation Algorithm:\n",
    "\n",
    "    if polar_fourier_alg_kw_args['use_exact_gravicenter']:\n",
    "        centers_pbs = get_grav_fct(problems) #[N_pbs, 2]\n",
    "        centers_refs = get_grav_fct(references)\n",
    "    else:\n",
    "        centers_pbs = np.repeat(np.array([[polar_fourier_alg_kw_args['X'], \n",
    "                                          polar_fourier_alg_kw_args['X']]]), \n",
    "                               len(problems), axis=0)\n",
    "        centers_refs = np.repeat(np.array([[polar_fourier_alg_kw_args['X'], \n",
    "                                          polar_fourier_alg_kw_args['X']]]), \n",
    "                               len(references), axis=0)\n",
    "    \n",
    "    if  type(references)==torch.Tensor or type(problems)==torch.Tensor:\n",
    "        references = references.to('cpu').numpy()\n",
    "        problems = problems.to('cpu').numpy()\n",
    "\n",
    "    \n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    # run it\n",
    "    for ref_im, pb_im, cent_ref, cent_pb, imagep_n in zip(references, problems, centers_refs, centers_pbs, image_pair_names):\n",
    "        t0=time()\n",
    "        im_ref_polar = warp_polar(ref_im, center=cent_ref, \n",
    "                    output_shape=(polar_fourier_alg_kw_args['theta_N'],\n",
    "                                  polar_fourier_alg_kw_args['rad_N']), \n",
    "                    radius=polar_fourier_alg_kw_args['max_rad'],\n",
    "                    scaling=polar_fourier_alg_kw_args['rad_scaling'],\n",
    "                    order=polar_fourier_alg_kw_args['interpolation_order'])\n",
    "        im_pb_polar = warp_polar(pb_im, center=cent_pb, \n",
    "                    output_shape=(polar_fourier_alg_kw_args['theta_N'],\n",
    "                                  polar_fourier_alg_kw_args['rad_N']), \n",
    "                    radius=polar_fourier_alg_kw_args['max_rad'],\n",
    "                    scaling=polar_fourier_alg_kw_args['rad_scaling'],\n",
    "                    order=polar_fourier_alg_kw_args['interpolation_order'])\n",
    "        shifts, error, phasediff = phase_cross_correlation(im_ref_polar, im_pb_polar, normalization='phase',\n",
    "                    upsample_factor=polar_fourier_alg_kw_args['desired_theta_accur']/polar_fourier_alg_kw_args['theta_N'],\n",
    "                                    space='real')\n",
    "        found = shifts[0]/polar_fourier_alg_kw_args['theta_N']*2*np.pi\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "        times[imagep_n] = time()-t0\n",
    "\n",
    "            \n",
    "    return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (F.1) CNN pelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from time import time\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Simple_Encoder(nn.Module):\n",
    "    def __init__(self, X=302, feats_1=15, feats_2=20, feats_3=20, feats_4=20,\n",
    "                 prop1=3, prop2=2, prop3=1, av_pool1_div=4, conv4_feat_size=15, av_pool2_div=10, \n",
    "                 out_fc_1=10,\n",
    "                 dropout_p1=0.2, dropout_p2=0.1\n",
    "                ): \n",
    "        # propj is such that the_ image getting out from stage j is propj/prop_{j-1}-ths of the previous (with j=0 being 5)\n",
    "        # clearly, prop_{j-1}>prop_{j}>...\n",
    "        # 2X+1 will be assumed to be divisible by 5\n",
    "        assert((2*X+1)%5==0)\n",
    "        assert(prop1>prop2)\n",
    "        assert(prop2>prop3)\n",
    "        assert((int((prop3*(2*X+1)/5)/av_pool1_div)-conv4_feat_size)>0)\n",
    "        \n",
    "        \n",
    "        super(Simple_Encoder, self).__init__()\n",
    "        # in is [epoch_size, 1, 2X+1, 2X+1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=feats_1, \n",
    "                               kernel_size = int((2*X+1)/5*(5-prop1)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        self.conv2 = nn.Conv2d(in_channels=feats_1, out_channels=feats_2, \n",
    "                               kernel_size = int((2*X+1)/5*(prop1-prop2)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_2, prop2*(prop1*(2X+1)/5)/prop1, prop2*(prop1*(2X+1)/5)/prop1]\n",
    "        # that is [epoch_size, feats_2, prop2*(2X+1)/5), prop2*(2X+1)/5)]\n",
    "        self.conv3 = nn.Conv2d(in_channels=feats_2, out_channels=feats_3, \n",
    "                               kernel_size = int((2*X+1)/5*(prop2-prop3)+1), bias=True)\n",
    "        # out conv3 is [epoch_size, feats_3, prop3*(2X+1)/5), prop3*(2X+1)/5)]\n",
    "\n",
    "        self.avPool1 = nn.AvgPool2d(kernel_size= int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=feats_3, out_channels=feats_4, \n",
    "                              kernel_size= int((prop3*(2*X+1)/5)/av_pool1_div+1)-conv4_feat_size+1, bias=True)\n",
    "        # [epoch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        \n",
    "        self.avPool2 = nn.AvgPool2d(kernel_size= int(conv4_feat_size*(1-1/av_pool2_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_4, conv4_feat_size/av_pool2_div+1, conv4_feat_size/av_pool2_div+1]\n",
    "        \n",
    "        #self.in_fc = int(feats_4*(conv4_feat_size/av_pool2_div+1)**2)\n",
    "        self.in_fc = feats_4*((((((2*X+1-int((2*X+1)/5*(5-prop1)+1)+1)\n",
    "                                  -int((2*X+1)/5*(prop1-prop2)+1)+1)\n",
    "                                 -int((2*X+1)/5*(prop2-prop3)+1)+1)\n",
    "                                -int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) -1+1)\n",
    "                               -int((prop3*(2*X+1)/5)/av_pool1_div+1)+conv4_feat_size-1+1)\n",
    "                              -int(conv4_feat_size*(1-1/av_pool2_div)) -1+1)**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc, out_features=out_fc_1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc_1, out_features=1, bias=True)        \n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1, inplace=False)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2, inplace=False)\n",
    "        self.relu = torch.nn.functional.relu\n",
    "\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=feats_2)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=feats_4)\n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        \n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, 1]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def print_shapes(self, batch_size=10, X=302):\n",
    "        x = torch.ones((batch_size, 1, 2*X+1, 2*X+1)).to(device)\n",
    "        print(f\"Initial shape {x.shape}\")\n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        print(f\"Post Conv1+relu shape {x.shape}\")\n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "        print(f\"Post drop1+Conv2+relu+batchnorm shape {x.shape}\")\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "        print(f\"Post drop2+Conv3+relu shape {x.shape}\")\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        print(f\"Post Av Pool1 shape {x.shape}\")\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        print(f\"Post drop2+Conv4+batchnorm shape {x.shape}\")\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "        print(f\"Post Av. Pool2 shape {x.shape}\")\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "        print(f\"Post Pre-fc shape {x.shape}\")\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, 1]\n",
    "        print(f\"Post fc1+relu+fc2 shape {x.shape}\")\n",
    "\n",
    "\n",
    "    def load_my_state_dict(self, state_dict):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                print(f\"Params NOT in own state: {name}\")\n",
    "                continue\n",
    "            if isinstance(param, nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            print(f\"Params YES in own state: {name} shape on external {param.shape} shape on own {own_state[name].shape}\")\n",
    "            if param.shape==own_state[name].shape:\n",
    "                own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_angle_predictor_model(model, references, problems, image_pair_names,   \n",
    "                       device=device, X=302, batch_size=50): # if as embedder one gives a pre_process_fct, it will work the same way\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    t=time()\n",
    "    model.eval()\n",
    "    ref_angs = np.zeros((references.shape[0]), dtype=np.float64)\n",
    "    pbs_angs = np.zeros((references.shape[0]), dtype=np.float64)\n",
    "    references = references.astype(dtype)/np.expand_dims( np.amax(references, axis=(-2,-1) ), (-2,-1) )\n",
    "    problems = problems.astype(dtype)/np.expand_dims( np.amax(problems, axis=(-2,-1) ), (-2,-1) )\n",
    "    for j in range(0, references.shape[0], batch_size):\n",
    "        ref_angs[j:(j+batch_size)] = model( compute_raws_to_centered_iXs_torch( torch.from_numpy(problems[j:(j+batch_size)]).to(device), X, device) ).to('cpu').numpy()[:,0]\n",
    "        pbs_angs[j:(j+batch_size)] = model(compute_raws_to_centered_iXs_torch( torch.from_numpy(references[j:(j+batch_size)]).to(device), X, device) ).to('cpu').numpy()[:,0]\n",
    "        free() \n",
    "    t = time()-t\n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = ref_angs[i]-pbs_angs[i] # pb - ref\n",
    "        times[imagep_n] = t/len(references)\n",
    "        \n",
    "    return predicted_deltaPhiCRs, times    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (F.2) CNN+many fc layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from time import time\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Simple_Encoder_fc(nn.Module):\n",
    "    def __init__(self, X=302, feats_1=15, feats_2=20, feats_3=20, feats_4=20,\n",
    "                 prop1=3, prop2=2, prop3=1, av_pool1_div=4, conv4_feat_size=15, av_pool2_div=10, \n",
    "                 out_fc_1=10,\n",
    "                 dropout_p1=0.2, dropout_p2=0.1\n",
    "                ): \n",
    "        # propj is such that the_ image getting out from stage j is propj/prop_{j-1}-ths of the previous (with j=0 being 5)\n",
    "        # clearly, prop_{j-1}>prop_{j}>...\n",
    "        # 2X+1 will be assumed to be divisible by 5\n",
    "        assert((2*X+1)%5==0)\n",
    "        assert(prop1>prop2)\n",
    "        assert(prop2>prop3)\n",
    "        assert((int((prop3*(2*X+1)/5)/av_pool1_div)-conv4_feat_size)>0)\n",
    "        \n",
    "        \n",
    "        super(Simple_Encoder_fc, self).__init__()\n",
    "        # in is [epoch_size, 1, 2X+1, 2X+1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=feats_1, \n",
    "                               kernel_size = int((2*X+1)/5*(5-prop1)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        self.conv2 = nn.Conv2d(in_channels=feats_1, out_channels=feats_2, \n",
    "                               kernel_size = int((2*X+1)/5*(prop1-prop2)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_2, prop2*(prop1*(2X+1)/5)/prop1, prop2*(prop1*(2X+1)/5)/prop1]\n",
    "        # that is [epoch_size, feats_2, prop2*(2X+1)/5), prop2*(2X+1)/5)]\n",
    "        self.conv3 = nn.Conv2d(in_channels=feats_2, out_channels=feats_3, \n",
    "                               kernel_size = int((2*X+1)/5*(prop2-prop3)+1), bias=True)\n",
    "        # out conv3 is [epoch_size, feats_3, prop3*(2X+1)/5), prop3*(2X+1)/5)]\n",
    "\n",
    "        self.avPool1 = nn.AvgPool2d(kernel_size= int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=feats_3, out_channels=feats_4, \n",
    "                              kernel_size= int((prop3*(2*X+1)/5)/av_pool1_div+1)-conv4_feat_size+1, bias=True)\n",
    "        # [epoch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        \n",
    "        self.avPool2 = nn.AvgPool2d(kernel_size= int(conv4_feat_size*(1-1/av_pool2_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_4, conv4_feat_size/av_pool2_div+1, conv4_feat_size/av_pool2_div+1]\n",
    "        \n",
    "        #self.in_fc = int(feats_4*(conv4_feat_size/av_pool2_div+1)**2)\n",
    "        self.in_fc = feats_4*((((((2*X+1-int((2*X+1)/5*(5-prop1)+1)+1)\n",
    "                                  -int((2*X+1)/5*(prop1-prop2)+1)+1)\n",
    "                                 -int((2*X+1)/5*(prop2-prop3)+1)+1)\n",
    "                                -int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) -1+1)\n",
    "                               -int((prop3*(2*X+1)/5)/av_pool1_div+1)+conv4_feat_size-1+1)\n",
    "                              -int(conv4_feat_size*(1-1/av_pool2_div)) -1+1)**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc, out_features=out_fc_1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc_1, out_features=10, bias=True)\n",
    "        self.fc3 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.fc4 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.fc5 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.fc6 = nn.Linear(in_features=10, out_features=1)\n",
    "        \n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1, inplace=False)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=feats_2)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=feats_4)\n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x if len(x.shape)>=3 else x.unsqueeze(0)\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        \n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "\n",
    "        \n",
    "        x = self.fc6(self.relu(self.dropout1(self.fc5(self.relu(self.dropout1(self.fc4(self.relu(self.fc3(self.dropout1(self.relu(self.fc2( self.relu( self.fc1(x) ) )))))))))))) #[batch_size, 1]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def print_shapes(self, batch_size=10, X=302):\n",
    "        x = torch.ones((batch_size, 1, 2*X+1, 2*X+1)).to(device)\n",
    "        print(f\"Initial shape {x.shape}\")\n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        print(f\"Post Conv1+relu shape {x.shape}\")\n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "        print(f\"Post drop1+Conv2+relu+batchnorm shape {x.shape}\")\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "        print(f\"Post drop2+Conv3+relu shape {x.shape}\")\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        print(f\"Post Av Pool1 shape {x.shape}\")\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        print(f\"Post drop2+Conv4+batchnorm shape {x.shape}\")\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "        print(f\"Post Av. Pool2 shape {x.shape}\")\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "        print(f\"Post Pre-fc shape {x.shape}\")\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, 1]\n",
    "        print(f\"Post fc1+relu+fc2 shape {x.shape}\")\n",
    "        \n",
    "        x = self.fc4( self.relu( self.fc3(x) ) ) #[batch_size, 1]\n",
    "        print(f\"Post fc3+relu+fc4 shape {x.shape}\")\n",
    "        \n",
    "        x = self.fc6( self.relu( self.fc5(x) ) ) #[batch_size, 1]\n",
    "        print(f\"Post fc5+relu+fc6 shape {x.shape}\")\n",
    "\n",
    "    def load_my_state_dict(self, state_dict):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                print(f\"Params NOT in own state: {name}\")\n",
    "                continue\n",
    "            if isinstance(param, nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            print(f\"Params YES in own state: {name} shape on external {param.shape} shape on own {own_state[name].shape}\")\n",
    "            if param.shape==own_state[name].shape:\n",
    "                own_state[name].copy_(param)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (H) Histogram versión mejorada\n",
    "Encuentra el ángulo en el que la variancia intraclase mínima sea minima. Esto nos dará dos estimaciones de la phi CR. La resolución será igual a la delta theta empleada claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp_polar\n",
    "\n",
    "def run_histogram_intra_class_var(references, problems, image_pair_names, preprocess_fct, \n",
    "                            get_grav_fct, polar_hist_alg_kw_args):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "     \n",
    "    # preprocess the images the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "\n",
    "    references = images[:references.shape[0]]\n",
    "    problems = images[references.shape[0]:]\n",
    "    # Execute the Rotation Algorithm:\n",
    "\n",
    "    if polar_hist_alg_kw_args['use_exact_gravicenter']:\n",
    "        centers_pbs = get_grav_fct(problems) #[N_pbs, 2]\n",
    "        centers_refs = get_grav_fct(references)\n",
    "    else:\n",
    "        centers_pbs = np.repeat(np.array([[polar_hist_alg_kw_args['X'], \n",
    "                                          polar_hist_alg_kw_args['X']]]), \n",
    "                               len(problems), axis=0)\n",
    "        centers_refs = np.repeat(np.array([[polar_hist_alg_kw_args['X'], \n",
    "                                          polar_hist_alg_kw_args['X']]]), \n",
    "                               len(references), axis=0)\n",
    "    \n",
    "    if type(references)==torch.Tensor or type(problems)==torch.Tensor:\n",
    "        references = references.to('cpu').numpy()\n",
    "        problems = problems.to('cpu').numpy()\n",
    "\n",
    "    \n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    # run it\n",
    "    for ref_im, pb_im, cent_ref, cent_pb, imagep_n in zip(references, problems, centers_refs, centers_pbs, image_pair_names):\n",
    "        t0=time()\n",
    "        im_ref_polar = warp_polar(ref_im, center=cent_ref, \n",
    "                    output_shape=(polar_hist_alg_kw_args['theta_N'],\n",
    "                                  polar_hist_alg_kw_args['rad_N']), \n",
    "                    radius=polar_hist_alg_kw_args['max_rad'],\n",
    "                    scaling=polar_hist_alg_kw_args['rad_scaling'],\n",
    "                    order=polar_hist_alg_kw_args['interpolation_order'])\n",
    "        im_pb_polar = warp_polar(pb_im, center=cent_pb, \n",
    "                    output_shape=(polar_hist_alg_kw_args['theta_N'],\n",
    "                                  polar_hist_alg_kw_args['rad_N']), \n",
    "                    radius=polar_hist_alg_kw_args['max_rad'],\n",
    "                    scaling=polar_hist_alg_kw_args['rad_scaling'],\n",
    "                    order=polar_hist_alg_kw_args['interpolation_order'])\n",
    "        \n",
    "        \n",
    "        histR = im_ref_polar.sum(axis=1)\n",
    "        histR = histR/histR.sum()\n",
    "        \n",
    "        histP = im_pb_polar.sum(axis=1)\n",
    "        histP = histP/histP.sum()\n",
    "        \n",
    "        otsu_min_R = mild_brute_force_then_zoom_in(histR, every=len(histR)//100)\n",
    "        otsu_min_P = mild_brute_force_then_zoom_in(histP, every=len(histP)//100)\n",
    "        a_shift_is = 360.0/len(histR) # deg\n",
    "        found = (otsu_min_R-otsu_min_P)*a_shift_is/180*np.pi\n",
    "        \n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "        times[imagep_n] = time()-t0\n",
    "\n",
    "            \n",
    "    return predicted_deltaPhiCRs, times\n",
    "\n",
    "def mild_brute_force_then_zoom_in(hist, every=10):\n",
    "    filt_hist = hist[::every]\n",
    "    shift, _, _ = get_optimal_shift_and_otsu_for_that_shift(filt_hist, 0, len(filt_hist))\n",
    "    shift, otsu_min_angle_shifted, otsu_min = get_optimal_shift_and_otsu_for_that_shift(\n",
    "        filt_hist, shift*every-every*10, shift*every+every*10)\n",
    "    # this could either be the crest max direction or the minimum one\n",
    "    # we must convert all to the same, say to the crest max\n",
    "    if otsu_min < min(hist)+45 and otsu_min>min(hist)-45: # then its the min\n",
    "        otsu_min += 180\n",
    "        otsu_min -= 360*(otsu_min>=360)\n",
    "    return otsu_min # could also work with shift differences!\n",
    "\n",
    "\n",
    "def get_optimal_shift_and_otsu_for_that_shift(hist, min_shift, max_shift): # hist should be normalized in scale\n",
    "    otsu_var_per_shift = []\n",
    "    otsu_angle = []\n",
    "    bin_centers = list(range(0, len(hist)))\n",
    "    for shift in range(min_shift, max_shift):\n",
    "        hist_s = np.concatenate((hist[shift:], hist[:shift]))\n",
    "        weight1 = np.cumsum(hist_s)\n",
    "        weight2 = np.cumsum(hist_s[::-1])[::-1]\n",
    "        mean1 = np.cumsum(hist_s * bin_centers) / weight1\n",
    "        mean2 = (np.cumsum((hist_s * bin_centers)[::-1]) / weight2[::-1])[::-1]\n",
    "        variances = weight1[:-1] * weight2[1:] * (mean1[:-1] - mean2[1:]) ** 2\n",
    "        \n",
    "        minarg = np.nanargmax(variances)\n",
    "        otsu_angle.append( bin_centers[minarg] )\n",
    "        otsu_var_per_shift.append( variances[minarg] )\n",
    "    min_var_shift = np.nanargmin(otsu_var_per_shift)\n",
    "    opt_otsu_angle = otsu_angle[min_var_shift]\n",
    "    min_var_shift+=min_shift\n",
    "    in_shifted = opt_otsu_angle//(len(hist)-min_var_shift)>0\n",
    "    return min_var_shift, opt_otsu_angle, opt_otsu_angle + min_var_shift-len(hist)*in_shifted # the optimal shift, the opt_angle in the optimal shift and this angle but relative to the first image\n",
    "    # it should happen that the shift difference and the optimal angle relative to the unshifted, difference are the same phiCR difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (I) Usando regresión de una recta con los puntos recogidos en Gradient alg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient_resgression_alg_kw_args = {'gravicenter_alg': normalize_to_max_and_iX}\n",
    "\n",
    "# input images expected for all cases to be float64 and normalized to unity\n",
    "# also, at least in this case, expected to be numpy arrays!\n",
    "# Input expected to be alread [n, 2X+1, 2X+1] centered in gravicenter!\n",
    "def run_gradient_regression(references, problems, image_pair_names, preprocess_fct):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    \n",
    "    # preprocess the images the image loader:\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "\n",
    "    references = images[:references.shape[0]]\n",
    "    problems = images[references.shape[0]:]\n",
    "    \n",
    "    if type(references)==torch.Tensor or type(problems)==torch.Tensor:\n",
    "        references = references.to('cpu').numpy()\n",
    "        problems = problems.to('cpu').numpy()\n",
    "\n",
    "    \n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    rows_prec = np.broadcast_to( np.arange(references.shape[1]), (references.shape[1],references.shape[1])).swapaxes(0,1) #[h,w]\n",
    "    # run it\n",
    "    for ref_im, pb_im, imagep_n in zip(references, problems, image_pair_names):\n",
    "        t0=time()\n",
    "        \n",
    "        ref_ang = compute_gradient_regression_estimate(ref_im, rows_prec)\n",
    "        pb_ang = compute_gradient_regression_estimate(pb_im, rows_prec)\n",
    "\n",
    "        found = angle_to_pi_pi(ref_ang)-angle_to_pi_pi(pb_ang)\n",
    "        \n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "        times[imagep_n] = time()-t0\n",
    "\n",
    "            \n",
    "    return predicted_deltaPhiCRs, times\n",
    "\n",
    "\n",
    "def given_axis_angle_greater_minus_lower( angle, image, center, rows):\n",
    "    # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "    # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "    mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "    return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "def get_polarization_angle( angle, image, center, rows):\n",
    "    \"\"\"\n",
    "    All the mirror methods have the problem that we only get the\n",
    "    correct angle up to an angle pi. In order to know which is the\n",
    "    angle to the maximum of the ring (and not the minimum) a final\n",
    "    subtle check is required.\n",
    "    \"\"\"\n",
    "    #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "    if angle==0 or abs(angle)==np.pi:\n",
    "        angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "    diff=given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center, rows)\n",
    "\n",
    "    if diff<0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "        return angle+np.pi if angle<0 else angle\n",
    "    else:\n",
    "        return angle-np.pi if angle>0 else angle\n",
    "    \n",
    "    \n",
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_gradient_regression_estimate( im, rows_prec ):\n",
    "    #diag = np.sqrt( im.shape[0]**2+im.shape[1]**2 )\n",
    "    mask_radii = np.linspace(100, int(im.shape[1])/2, int(im.shape[1]/2))\n",
    "    found_gravs = np.zeros((mask_radii.shape[0], 2))\n",
    "    hs, ws = np.arange(im.shape[0]), np.arange(im.shape[1])\n",
    "    full_grav = compute_intensity_gravity_center(im)\n",
    "    radii_image =  np.sqrt((hs[:,np.newaxis]-full_grav[0])**2+(ws[np.newaxis,:]-full_grav[1])**2) # should be [H,W]\n",
    "    for j, radi in enumerate(mask_radii):\n",
    "        found_gravs[j,:] = compute_intensity_gravity_center(\n",
    "                np.where(radii_image<radi, im, 0).astype(np.float64))\n",
    "    betas = np.linalg.lstsq(\n",
    "                np.vstack((np.ones(len(found_gravs)), found_gravs[:,1])).T, \n",
    "                found_gravs[:, 0],rcond=None)[0]\n",
    "    #f, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "    #ax.imshow(im)\n",
    "    #ax.plot(found_gravs[:,1], found_gravs[:,0], 'or', markersize=3)\n",
    "    #ax.plot([0,604],[betas[0], betas[0]+betas[1]*604], '-w')\n",
    "    #ax.set_ylim((0,604))\n",
    "    #ax.set_xlim((0,604))\n",
    "    #plt.show()\n",
    "    return get_polarization_angle( np.arctan2(betas[1],1), im, full_grav, rows_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (J) Ajustar cos square al histograma radial+Carles\n",
    "Hacer una optimizacion de centro de histograma, hasta encontrar el ajuste cos square de menor error cuadratico medio.\n",
    "Que se podria optimizar en el full space? Desde luego, pero bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import skopt\n",
    "import sklearn.linear_model\n",
    "def get_least_square_error(center_h_w, im, ransac, theta_N, rad_N, max_rad, rad_scaling, interpol_order, ransac_opts=None): # get the least square error of a fit with a \n",
    "    # y=Acos**2(x/2-phi0)+B=b0+b1 cos(x)+b2 sin(x) if b0=A/2+B; b1=A/2 cos(2phi0); b2=A/2sin(2phi0)\n",
    "    im_polar = warp_polar(im, center=center_h_w, \n",
    "                    output_shape=(theta_N, rad_N), \n",
    "                    radius=max_rad,\n",
    "                    scaling=rad_scaling,\n",
    "                    order=interpol_order)\n",
    "    hist = im_polar.sum(axis=1)\n",
    "    #hist = hist/hist.sum()\n",
    "    supp_phis = np.linspace(0, np.pi*2, theta_N)\n",
    "    A = np.vstack((np.ones(len(hist)), np.cos(supp_phis), np.sin(supp_phis))).T\n",
    "    if not ransac:\n",
    "        betas, ls_res = np.linalg.lstsq( A, hist, rcond=None)[:2]\n",
    "    else:\n",
    "        betas = sk.linear_model.RANSACRegressor(base_estimator=sklearn.linear_model.LinearRegression(),\n",
    "                    min_samples=ransac_opts['min_samples'], max_trials=ransac_opts['max_trials'], \n",
    "                    residual_threshold=ransac_opts['residual_threshold'],\n",
    "                    #stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss='absolute_error',\n",
    "                    random_state=666)\n",
    "        betas = betas.fit(A[:,1:], hist)\n",
    "        ls_res = betas.score(A[:,1:], hist) \n",
    "    #print(f\"LS res {ls_res*(1-w)}\")\n",
    "    return np.sum(ls_res), betas, hist\n",
    "\n",
    "def rotate_image_by( image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "     \n",
    "        \n",
    "def get_Carles_metric(center_h_w, im,  interpolation_flag):\n",
    "    im_pi_im = rotate_image_by(im, np.pi, center_h_w,interpolation_flag)+im\n",
    "    #plt.imshow(im_pi_im)\n",
    "    #plt.show()\n",
    "    #plt.imshow(np.abs(im_pi_im-rotate_image_by(im_pi_im, np.pi/2, center_h_w,interpolation_flag)))\n",
    "    #plt.show()\n",
    "    #print(f\"Carles {bai*w}\")\n",
    "    return np.mean(np.abs(im_pi_im-rotate_image_by(im_pi_im, np.pi/2, center_h_w,interpolation_flag)))\n",
    "    \n",
    "\n",
    "\n",
    "def run_squared_cosine_fit_and_Carles(references, problems, image_pair_names, \n",
    "                                      preprocess_fct, get_grav_fct, squared_cosine_alg_kw_args):\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    if preprocess_fct is not None:\n",
    "        images = preprocess_fct( np.concatenate((references, problems), axis=0) )\n",
    "    else:\n",
    "        images = np.concatenate((references, problems), axis=0)\n",
    "\n",
    "    references = images[:references.shape[0]]\n",
    "    problems = images[references.shape[0]:]\n",
    "\n",
    "    if get_grav_fct:\n",
    "        centers_pbs = get_grav_fct(problems) #[N_pbs, 2]\n",
    "        centers_refs = get_grav_fct(references)\n",
    "    else:\n",
    "        centers_pbs = np.repeat(np.array([[polar_hist_alg_kw_args['X'], \n",
    "                                          polar_hist_alg_kw_args['X']]]), \n",
    "                               len(problems), axis=0)\n",
    "        centers_refs = np.repeat(np.array([[polar_hist_alg_kw_args['X'], \n",
    "                                          polar_hist_alg_kw_args['X']]]), \n",
    "                               len(references), axis=0)\n",
    "    \n",
    "    if type(references)==torch.Tensor or type(problems)==torch.Tensor:\n",
    "        references = references.to('cpu').numpy()\n",
    "        problems = problems.to('cpu').numpy()\n",
    "\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "    rows_prec = np.broadcast_to( np.arange(references.shape[1]), (references.shape[1],references.shape[1])).swapaxes(0,1) #[h,w]\n",
    "    # run it\n",
    "    get_fit = lambda c_h_w, im : get_least_square_error(c_h_w, im, ransac=squared_cosine_alg_kw_args['ransac'],\n",
    "                                            ransac_opts=squared_cosine_alg_kw_args['ransac_opts'],\n",
    "                                            theta_N=squared_cosine_alg_kw_args['theta_N'],\n",
    "                                            rad_N=squared_cosine_alg_kw_args['rad_N'],\n",
    "                                            max_rad=squared_cosine_alg_kw_args['max_rad'],\n",
    "                                            rad_scaling=squared_cosine_alg_kw_args['rad_scaling'], \n",
    "                                            interpol_order=squared_cosine_alg_kw_args['interpolation_order'])\n",
    "    w = squared_cosine_alg_kw_args['w']\n",
    "\n",
    "    if w==1:\n",
    "        get_metric = lambda c_h_w, im : get_Carles_metric(c_h_w, im, interpolation_flag=cv2.INTER_CUBIC)\n",
    "    elif w==0:\n",
    "        get_metric = lambda c_h_w, im : (1-w)*get_least_square_error(c_h_w, im, ransac=False,\n",
    "                                            theta_N=squared_cosine_alg_kw_args['theta_N'],\n",
    "                                            rad_N=squared_cosine_alg_kw_args['rad_N'],\n",
    "                                            max_rad=squared_cosine_alg_kw_args['max_rad'],\n",
    "                                            rad_scaling=squared_cosine_alg_kw_args['rad_scaling'], \n",
    "                                            interpol_order=squared_cosine_alg_kw_args['interpolation_order'])[0]\n",
    "    else:\n",
    "        get_metric = lambda c_h_w, im : (1-w)*get_least_square_error(c_h_w, im, ransac=False,\n",
    "                                            theta_N=squared_cosine_alg_kw_args['theta_N'],\n",
    "                                            rad_N=squared_cosine_alg_kw_args['rad_N'],\n",
    "                                            max_rad=squared_cosine_alg_kw_args['max_rad'],\n",
    "                                            rad_scaling=squared_cosine_alg_kw_args['rad_scaling'], \n",
    "                                            interpol_order=squared_cosine_alg_kw_args['interpolation_order'])[0]+\\\n",
    "                                    w*get_Carles_metric(c_h_w, im, interpolation_flag=cv2.INTER_CUBIC)\n",
    "    \n",
    "\n",
    "    if squared_cosine_alg_kw_args['method']!='Bayesian':\n",
    "        options={'maxiter':squared_cosine_alg_kw_args['max_it'],\n",
    "                'maxfev': squared_cosine_alg_kw_args['max_evals']}\n",
    "        \n",
    "        if squared_cosine_alg_kw_args['method']=='Nelder-Mead':\n",
    "            options['xatol']=squared_cosine_alg_kw_args['abs_tol']\n",
    "            options['fatol']=squared_cosine_alg_kw_args['rel_tol']\n",
    "        elif squared_cosine_alg_kw_args['method']=='Powell':\n",
    "            options['xtol']=squared_cosine_alg_kw_args['abs_tol']\n",
    "            options['ftol']=squared_cosine_alg_kw_args['rel_tol']\n",
    "\n",
    "        for ref_im, pb_im, cent_ref, cent_pb, imagep_n in zip(references, problems, centers_refs, centers_pbs, image_pair_names):\n",
    "            t0=time()\n",
    "            to_opt = lambda c_h_w : get_metric(c_h_w, im=ref_im)\n",
    "\n",
    "            res = scipy.optimize.minimize(to_opt, cent_ref, method=squared_cosine_alg_kw_args['method'],\n",
    "                                    bounds=((0,ref_im.shape[0]),(0, ref_im.shape[0])),\n",
    "                                    #constraints=(), \n",
    "                                    tol=None, options=options)\n",
    "            geom_center_ref = res.x\n",
    "\n",
    "            #check_results(ref_im, geom_center_ref, cent_ref, get_fit, np.linspace(0, 2*np.pi, squared_cosine_alg_kw_args['theta_N']), squared_cosine_alg_kw_args['ransac'])\n",
    "\n",
    "            \n",
    "            to_opt = lambda c_h_w : get_metric(c_h_w, im=pb_im)\n",
    "            res = scipy.optimize.minimize(to_opt, cent_pb, method=squared_cosine_alg_kw_args['method'],\n",
    "                                    bounds=((0,pb_im.shape[0]),(0, pb_im.shape[0])),\n",
    "                                    #constraints=(), \n",
    "                                    tol=None, options=options)\n",
    "            geom_center_pb = res.x\n",
    "            \n",
    "            #check_results(pb_im, geom_center_pb, cent_pb, get_fit, np.linspace(0, 2*np.pi, squared_cosine_alg_kw_args['theta_N']), squared_cosine_alg_kw_args['ransac'])\n",
    "            \n",
    "            if squared_cosine_alg_kw_args['get_delta_from_grav_geom_centers']:\n",
    "                ref_ang = np.arctan2(geom_center_ref[0]-cent_ref[0], geom_center_ref[1]-cent_ref[1] )\n",
    "                pb_ang = np.arctan2(geom_center_pb[0]-cent_pb[0], geom_center_pb[1]-cent_pb[1] )\n",
    "                \n",
    "                #no se si ambos, pero hace falta mirar si up or down, ze con gravcentros al menos es up to pi\n",
    "                ref_angle = get_polarization_angle( ref_ang, ref_im, cent_ref, rows_prec)\n",
    "                pb_angle = get_polarization_angle( pb_ang, pb_im, cent_pb, rows_prec)\n",
    "\n",
    "            else:\n",
    "                er, betas = get_fit(geom_center_ref, ref_im)[:2]\n",
    "                if squared_cosine_alg_kw_args['ransac']:\n",
    "                    betas = [np.nan,]+list(betas.estimator_.coef_)\n",
    "                ref_ang = np.arctan2(betas[2],betas[1])\n",
    "\n",
    "                er, betas = get_fit(geom_center_pb, pb_im)[:2]\n",
    "                if squared_cosine_alg_kw_args['ransac']:\n",
    "                    betas = [np.nan,]+list(betas.estimator_.coef_)\n",
    "                pb_ang = np.arctan2(betas[2],betas[1]) # probar si poniendo en y and x va bien, y si exige aun asi mirar si es up or down\n",
    "\n",
    "\n",
    "            found = angle_to_pi_pi(ref_ang)-angle_to_pi_pi(pb_ang)\n",
    "\n",
    "            predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "            times[imagep_n] = time()-t0\n",
    "    else:\n",
    "        for ref_im, pb_im, cent_ref, cent_pb, imagep_n in zip(references, problems, centers_refs, centers_pbs, image_pair_names):\n",
    "            t0=time()\n",
    "            to_opt = lambda c_h_w : get_metric(c_h_w, im=ref_im)\n",
    "\n",
    "            res = skopt.gp_minimize(to_opt, dimensions=((0.0,float(ref_im.shape[0])),(0.0, float(ref_im.shape[0]))),\n",
    "                                n_calls=squared_cosine_alg_kw_args['max_evals'],\n",
    "                                x0=[[cent_ref[0],cent_ref[1]]],\n",
    "                                n_initial_points=10, initial_point_generator='random',\n",
    "                                acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                random_state=666, \n",
    "                                n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                kappa=1.96, noise='gaussian', n_jobs=squared_cosine_alg_kw_args['n_jobs'])\n",
    "            geom_center_ref = res.x\n",
    "            check_results(ref_im, geom_center_ref, cent_ref, get_fit, np.linspace(0, 2*np.pi, squared_cosine_alg_kw_args['theta_N']), squared_cosine_NM_alg_kw_args['ransac'])\n",
    "\n",
    "            to_opt = lambda c_h_w : get_metric(c_h_w, im=pb_im)\n",
    "            res = skopt.gp_minimize(to_opt, dimensions=((0.0,float(pb_im.shape[0])),(0.0, float(pb_im.shape[0]))),\n",
    "                                n_calls=squared_cosine_alg_kw_args['max_evals'],\n",
    "                                x0=[[cent_pb[0],cent_pb[1]]],\n",
    "                                n_initial_points=10, initial_point_generator='random',\n",
    "                                acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                random_state=666, \n",
    "                                n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                kappa=1.96, noise='gaussian', n_jobs=squared_cosine_alg_kw_args['n_jobs'])\n",
    "            geom_center_pb = res.x\n",
    "            check_results(pb_im, geom_center_pb, cent_pb, get_fit, np.linspace(0, 2*np.pi, squared_cosine_alg_kw_args['theta_N']), squared_cosine_NM_alg_kw_args['ransac'])\n",
    "\n",
    "            if squared_cosine_alg_kw_args['get_delta_from_grav_geom_centers']:\n",
    "                ref_ang = np.arctan2(geom_center_ref[0]-cent_ref[0], geom_center_ref[1]-cent_ref[1] )\n",
    "                pb_ang = np.arctan2(geom_center_pb[0]-cent_pb[0], geom_center_pb[1]-cent_pb[1] )\n",
    "            else:\n",
    "                er, betas = get_fit(geom_center_ref, ref_im)[:2]\n",
    "                ref_ang = np.arctan2(betas[2]/betas[1],1)\n",
    "\n",
    "                er, betas = get_fit(geom_center_pb, pb_im)[:2]\n",
    "                pb_ang = np.arctan2(betas[2]/betas[1],1) # probar si poniendo en y and x va bien, y si exige aun asi mirar si es up or down\n",
    "\n",
    "            # no se si ambos, pero hace falta mirar si up or down, ze con gravcentros al menos es up to pi\n",
    "            ref_angle = get_polarization_angle( ref_ang, ref_im, cent_ref, rows_prec)\n",
    "            pb_angle = get_polarization_angle( pb_ang, pb_im, cent_pb, rows_prec)\n",
    "\n",
    "            found = angle_to_pi_pi(ref_ang)-angle_to_pi_pi(pb_ang)\n",
    "\n",
    "            predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "            times[imagep_n] = time()-t0\n",
    "\n",
    "            \n",
    "    return predicted_deltaPhiCRs, times\n",
    "\n",
    "def check_results(im, geom, grav, hist_and_fit_f, supp_phis, ransac):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "    ax[0].imshow(im)\n",
    "    ax[0].plot(geom[1],geom[0], 'or', label=\"Geometric Center\")\n",
    "    ax[0].plot(grav[1],grav[0], 'oy', label=\"Gravicenter\")\n",
    "    ax[0].plot([0,im.shape[0]-1],[-grav[1]*(geom[0]-grav[0])/(geom[1]-grav[1])+grav[0], (im.shape[0]-1-grav[1])*(geom[0]-grav[0])/(geom[1]-grav[1])+grav[0]], '-w')\n",
    "    ax[0].set_xlim((0,im.shape[1]))\n",
    "    ax[0].set_ylim((0, im.shape[0]))\n",
    "    \n",
    "    er, betas, hist = hist_and_fit_f(geom, im)\n",
    "    if ransac:\n",
    "        print(f\"n trials: {betas.n_trials_} inliers: {np.sum(betas.inlier_mask_)}\")\n",
    "        fit = betas.estimator_.predict(np.vstack(( np.cos(supp_phis), np.sin(supp_phis))).T)\n",
    "        ax[1].plot(supp_phis[betas.inlier_mask_], np.zeros(np.sum(betas.inlier_mask_)), 'o', markersize=1, label=\"Inliers\")\n",
    "    else:\n",
    "        fit = betas[0]+betas[1]*np.cos(supp_phis)+betas[2]*np.sin(supp_phis)\n",
    "        \n",
    "    ax[1].plot(supp_phis, hist, label=\"Histogram at optimal geometric center\")\n",
    "    ax[1].plot(supp_phis, fit, label=\"Least Squares Fit\")\n",
    "    ax[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "     \n",
    "def given_axis_angle_greater_minus_lower( angle, image, center, rows):\n",
    "    # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "    # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "    mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "    return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "def get_polarization_angle( angle, image, center, rows):\n",
    "    \"\"\"\n",
    "    All the mirror methods have the problem that we only get the\n",
    "    correct angle up to an angle pi. In order to know which is the\n",
    "    angle to the maximum of the ring (and not the minimum) a final\n",
    "    subtle check is required.\n",
    "    \"\"\"\n",
    "    #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "    if angle==0 or abs(angle)==np.pi:\n",
    "        angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "    diff=given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center, rows)\n",
    "\n",
    "    if diff<0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "        return angle+np.pi if angle<0 else angle\n",
    "    else:\n",
    "        return angle-np.pi if angle>0 else angle\n",
    "    \n",
    "\n",
    "    # comprobar si hace fata poner up-down\n",
    "    # mirar los plots de los resultados optimos, el histograma contra el ajuste que sale\n",
    "    # y tb la imagen con el gravicentro, el geometric center y la recta que los une! Esto en plan plot gure dot!\n",
    "    # Probar si bajas o subes el num de iteraciones y evaluaciones que pasa\n",
    "    # probar el Powel method!\n",
    "    \n",
    "    # Implementar ahora el Bayesian Optimizer y implementar ambos en simulation coordinate descent!\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Using the Experimental+Simulated Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bixek\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin_negat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin_posit\n"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_experimental\n",
    "# General pipeline settings\n",
    "#output_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}/\"\n",
    "output_path = F\"/home/melanie/Desktop/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}/\"\n",
    "output_units = 'deg'\n",
    "confidence = 90\n",
    "boots_samples = 10000\n",
    "\n",
    "dtype = np.float64\n",
    "dtype_torch = torch.float64\n",
    "\n",
    "\n",
    "\n",
    "if pipe_name==\"Proof_of_concept\":\n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/ProofOfConcept/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['ezer', 'bixek', 'sin_negat', 'sin_posit']\n",
    "    GT_abs = [ 0,  5.11, 16.10, -10.98]\n",
    "    repetitions = list(range(3))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    image_pair_names = []\n",
    "    indices = [(0,1),(0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "\n",
    "    show=[0,1,2,3]\n",
    "\n",
    "\n",
    "    references = np.zeros((len(indices), 2*X+1, 2*X+1), dtype=dtype)\n",
    "    problems = np.zeros((len(indices), 2*X+1, 2*X+1), dtype=dtype)\n",
    "    ground_truths = np.zeros(len(indices), dtype=np.float64)\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            j+=1\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[k] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[k] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[k])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[k] = GT_abs[ref]-GT_abs[pb]\n",
    "\n",
    "\n",
    "elif pipe_name==\"HeNe\":\n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Referencia_HeNe/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['sin_nada', 'con_todo', 'sin_negativo', 'sin_positivo']\n",
    "    #GT_abs = [ 0,  5.11, 16.10, -10.98]\n",
    "    GT_abs = [0, 4.40, 13.85, -9.45]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    image_pair_names = []\n",
    "    indices = [(0,1),(0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "\n",
    "    show=[0,1,2,3]\n",
    "\n",
    "\n",
    "    references = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    problems = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    ground_truths = np.zeros(len(indices)+1, dtype=np.float64)\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[k] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[k] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[k])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[k] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Ortogonal_HeNe/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['0_2', '90']\n",
    "    GT_abs = [0, 90]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    indices = [(0,1)]\n",
    "\n",
    "    show=[0,1]\n",
    "\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[-1] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[-1] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[-1])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[-1] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "elif pipe_name==\"LED_small_rho\":\n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Referencia/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['Sin_ninguno', 'Con_las_dos', 'Sin_negativo', 'Sin_positivo']\n",
    "    GT_abs = [ 0,  5.11, 16.10, -10.98]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    image_pair_names = []\n",
    "    indices = [(0,1),(0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "\n",
    "    show=[0,1,2,3]\n",
    "\n",
    "\n",
    "    references = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    problems = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    ground_truths = np.zeros(len(indices)+1, dtype=np.float64)\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[k] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[k] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[k])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[k] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Ortogonal/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['0', '90']\n",
    "    GT_abs = [0, 90]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    indices = [(0,1)]\n",
    "\n",
    "    show=[0,1]\n",
    "\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[-1] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[-1] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[-1])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[-1] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "else:\n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Referencia_Mayor_rho/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['sin_ninguno', 'Con_los_dos', 'sin_negativo', 'Sin_positivo']\n",
    "    GT_abs = [ 0,  5.11, 16.10, -10.98]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    image_pair_names = []\n",
    "    indices = [(0,1),(0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "\n",
    "    show=[0,1,2,3]\n",
    "\n",
    "\n",
    "    references = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    problems = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    ground_truths = np.zeros(len(indices)+1, dtype=np.float64)\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[k] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[k] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[k])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[k] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "   \n",
    "    \n",
    "        \n",
    "GT_units = 'deg'\n",
    "GT_nature = 'pol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rot_Kalkandjiev_Fibo_Cubic_Interp_Exper_Open_s11_toMean_iX', 'Rot_Kalkandjiev_Quad_Cubic_Interp_Exper_Open_s11_toMean_iX', 'Rot_Kalkandjiev_Fibo_Lanc_Interp_Exper_Open_s11_toMean_iX', 'Rot_Kalkandjiev_Quad_Lanc_Interp_Exper_Open_s11_toMean_iX', 'Mir_Fibo_Cubic_Interp_Exper_Open_s11_toMean_iX', 'Mir_Quad_Cubic_Interp_Exper_Open_s11_toMean_iX', 'Mir_Fibo_Lanc_Interp_Exper_Open_s11_toMean_iX', 'Mir_Quad_Lanc_Interp_Exper_Open_s11_toMean_iX', 'Rot_Naive_Fibo_Cubic_Interp_Exper_Open_s11_toMean_iX', 'Rot_Naive_Quad_Cubic_Interp_Exper_Open_s11_toMean_iX', 'Rot_Naive_Fibo_Lanc_Interp_Exper_Open_s11_toMean_iX', 'Rot_Naive_Quad_Lanc_Interp_Exper_Open_s11_toMean_iX', 'Rel_Rot_Fourier_Phase_Correlat_Exper_Open_s11_toMean_iX', 'Histo_Intra_Class_Var_Exper_Open_s11_toMean_iX', 'Grad_Regress_Exper_Open_s11_toMean_iX']\n",
      "> Passing Images from each Algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_7413/3089763176.py\", line 494, in <module>\n",
      "    output_path=output_path)\n",
      "  File \"/tmp/ipykernel_7413/2935119750.py\", line 99, in run_benchmark_output_result_histograms_and_result_table\n",
      "    image_pair_names[j:(j+batch_size)], dir_for_alg)\n",
      "  File \"/tmp/ipykernel_7413/3089763176.py\", line 144, in <lambda>\n",
      "    rotation_alg_kw_args=rotation_alg_kw_args_cub, out_plot_path=dir_alg, rotation_algorithm=None),\n",
      "  File \"/tmp/ipykernel_7413/2854177034.py\", line 40, in run_rotation_algorithm\n",
      "    search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])\n",
      "  File \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Polarization_Obtention_Algorithms.py\", line 975, in fibonacci_ratio_search\n",
      "    self.grav[im] if self.use_exact_gravicenter else self.grav))\n",
      "  File \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Ad_Hoc_Optimizer.py\", line 100, in fibonacci_ratio_search\n",
      "    active_points = self.initialize_correct_point_quad(image, args_for_cost, initial_guess)\n",
      "  File \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Ad_Hoc_Optimizer.py\", line 173, in initialize_correct_point_quad\n",
      "  File \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Polarization_Obtention_Algorithms.py\", line 886, in evaluate_image_rotation\n",
      "    return np.sum(np.abs(self.rotate_image_by(image_to_rotate, angle, center)-reference_image))\n",
      "  File \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Polarization_Obtention_Algorithms.py\", line 882, in rotate_image_by\n",
      "    return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=self.interpolation_flag).astype(image_array.dtype)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/melanie/anaconda3/envs/fbvars/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7413/3089763176.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mexperiment_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             output_path=output_path)\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0mfree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7413/2935119750.py\u001b[0m in \u001b[0;36mrun_benchmark_output_result_histograms_and_result_table\u001b[0;34m(algorithm_lambda_list, algorithm_name_list, references, problems, image_pair_names, generate_algorithm_plots, generate_histograms, boots_samples, confidence, output_units, ground_truths, GT_units, GT_nature, experiment_name, output_path, batch_size)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                     image_pair_names[j:(j+batch_size)], dir_for_alg)\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mpredicted_delta_phiCRs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malg_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_predicted_delta_phiCRs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7413/3089763176.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(refs, pbs, image_pair_names, dir_alg)\u001b[0m\n\u001b[1;32m    143\u001b[0m                         \u001b[0msearch_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fibonacci\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_alg_kw_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrotation_fibo_kw_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                         rotation_alg_kw_args=rotation_alg_kw_args_cub, out_plot_path=dir_alg, rotation_algorithm=None),\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7413/2854177034.py\u001b[0m in \u001b[0;36mrun_rotation_algorithm\u001b[0;34m(references, problems, image_pair_names, preprocess_fct, search_algorithm, search_alg_kw_args, rotation_alg_kw_args, out_plot_path, rotation_algorithm)\u001b[0m\n\u001b[1;32m     39\u001b[0m         rotation_algorithm.fibonacci_ratio_search(search_alg_kw_args['precision_fibonacci'],\n\u001b[0;32m---> 40\u001b[0;31m                     search_alg_kw_args['max_points_fibonacci'], search_alg_kw_args['cost_tolerance_fibonacci'])    \n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout_plot_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Polarization_Obtention_Algorithms.py\u001b[0m in \u001b[0;36mfibonacci_ratio_search\u001b[0;34m(self, precision, maximum_points, cost_tol)\u001b[0m\n\u001b[1;32m    974\u001b[0m                     self.original_images.centered_ring_images[im], (self.mirror_images_wrt_width_axis[im],\n\u001b[0;32m--> 975\u001b[0;31m                     self.grav[im] if self.use_exact_gravicenter else self.grav))\n\u001b[0m\u001b[1;32m    976\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_to_pi_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Ad_Hoc_Optimizer.py\u001b[0m in \u001b[0;36mfibonacci_ratio_search\u001b[0;34m(self, precision, maximum_points, cost_tol, image, args_for_cost, initial_guess)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# prepare the first point triad just like in quadratic fit search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mactive_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_correct_point_quad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_for_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_guess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Ad_Hoc_Optimizer.py\u001b[0m in \u001b[0;36minitialize_correct_point_quad\u001b[0;34m(self, image, args_for_cost, initial_guess)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mactive_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_for_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;31m# then at least two points have diff cost!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Polarization_Obtention_Algorithms.py\u001b[0m in \u001b[0;36mevaluate_image_rotation\u001b[0;34m(self, reference_image, angle, image_to_rotate, center)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_image_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_to_rotate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate_image_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_to_rotate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Conical_Refraction_Polarimeter/LAB/ANALYSIS_SCRIPTS/SOURCE/CLASS_CODE_Polarization_Obtention_Algorithms.py\u001b[0m in \u001b[0;36mrotate_image_by\u001b[0;34m(self, image_array, angle, center)\u001b[0m\n\u001b[1;32m    881\u001b[0m                              [-b, a, center[1]*b+center[0]*(1-a)]])\n\u001b[0;32m--> 882\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2067\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fbvars/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_experimental\n",
    "\n",
    "table_per_alg={}\n",
    "table_per_image={}\n",
    "\n",
    "\n",
    "algorithm_lambda_list=[]\n",
    "algorithm_name_list = []\n",
    "\n",
    "from skimage import morphology\n",
    "\n",
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "if current_block==1: # noisy dataset\n",
    "    #rot, mirror, grad and hist  \n",
    "\n",
    "    \n",
    "    # Sub_block specific stuff ########################\n",
    "    if current_sub_block==1: # ein in torch and not in torch bersioak, eta ein danak por batches procesetie!!!\n",
    "        # to max noisy and iX\n",
    "        def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                        ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                    X=X, device=device)).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        \n",
    "\n",
    "     \n",
    "        \n",
    "    elif current_sub_block==2:\n",
    "        # to max then to mean noisy and iX\n",
    "        def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                ims_t = ims_t/torch.mean(ims_t, axis=(-1,-2), keepdims=True)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=X, device=device)).to('cpu').numpy()\n",
    "                free() \n",
    "            return images\n",
    "        \n",
    "    \n",
    "    elif current_sub_block==3:\n",
    "        # to saturate at 0.05 noisy and iX\n",
    "        def preprocess_fct( images, saturation_threshold=0.05, batch_size=200, dtype=torch.float64 ):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                maxs = ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "                images[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch(\n",
    "                    (torch.where(\n",
    "                    ims_t<maxs*saturation_threshold, ims_t, 0.0)/maxs), X, device).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        \n",
    "    elif current_sub_block>=4 and current_sub_block<=8:\n",
    "        # sigmoid lut noisy\n",
    "\n",
    "        centers = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        ks = [35, 35, 35, 35, 35]\n",
    "        for j,k in enumerate(ks):\n",
    "            ks[j] = np.log(254)/centers[j] if k<np.log(254)/centers[j]  else k\n",
    "            ks[j] = np.log(254)/(1-centers[j]) if k<np.log(254)/(1-centers[j]) else k\n",
    "        \n",
    "        def preprocess_fct(images, center=centers[current_sub_block-4],\n",
    "                    slope_squeezeness=ks[current_sub_block-4], dtype=torch.float64, batch_size=200):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                ims_t = ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                images[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch(\n",
    "                        1.0/(1+torch.exp(-slope_squeezeness*(ims_t-center)))\n",
    "                                                      , X, device).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "    \n",
    "    elif current_sub_block>=9 and current_sub_block<=11:\n",
    "        # Opening to max to mean\n",
    "        structs = [7, 9, 11 ]#, 13]\n",
    "                                            \n",
    "        def to_max_to_mean(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                ims_t = ims_t/torch.mean(ims_t, axis=(-1,-2), keepdims=True)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=X, device=device)).to('cpu').numpy()\n",
    "                free() \n",
    "            return images\n",
    "        def get_struct(size, N):\n",
    "            foot = morphology.disk(size)\n",
    "            return np.repeat(foot[np.newaxis, :,:], N, axis=0)\n",
    "                                            \n",
    "        preprocess_fct = lambda ims : to_max_to_mean(\n",
    "            np.array([morphology.opening(im, morphology.disk(structs[current_sub_block-9]) ) for im in ims ]))\n",
    "    \n",
    "    elif current_sub_block>=12 and current_sub_block<=14:\n",
    "        # local binarization    \n",
    "        block_sizes=[21,27, 47 ]\n",
    "        def to_gravicenter(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                        ims_t, X=X, device=device)).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        local_threshold_binarization=lambda im: im < threshold_local(\n",
    "            im, block_size=block_sizes[current_sub_block-12], offset=10)\n",
    "        preprocess_fct= lambda ims: to_gravicenter(1.0*np.array([ local_threshold_binarization(im) for im in ims]))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Block General stuff ################3\n",
    "    # Add Rotation\n",
    "    rotation_alg_kw_args_cub = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                            'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC}\n",
    "    rotation_alg_kw_args_lanc = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                            'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_LANCZOS4}\n",
    "    rotation_quad_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "    rotation_fibo_kw_args = {'precision_fibonacci':1e-10, 'max_points_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "\n",
    "\n",
    "    algorithm_lambda_list += [\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_cub, out_plot_path=dir_alg, rotation_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_cub, out_plot_path=dir_alg, rotation_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_lanc, out_plot_path=dir_alg, rotation_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_lanc, out_plot_path=dir_alg, rotation_algorithm=None)\n",
    "        ]\n",
    "    algorithm_name_list+=[ \"Rot_Kalkandjiev_Fibo_Cubic_Interp\", \"Rot_Kalkandjiev_Quad_Cubic_Interp\",\n",
    "                         \"Rot_Kalkandjiev_Fibo_Lanc_Interp\", \"Rot_Kalkandjiev_Quad_Lanc_Interp\"]\n",
    "        \n",
    "    # Add Mirror\n",
    "    mirror_alg_kw_args_cub = {'theta_min_Mir':0, 'theta_max_Mir':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC}\n",
    "    mirror_alg_kw_args_lanc = {'theta_min_Mir':0, 'theta_max_Mir':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_LANCZOS4}\n",
    "    mirror_quad_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "    mirror_fibo_kw_args = {'precision_fibonacci':1e-10, 'max_points_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "    \n",
    "    \n",
    "    algorithm_lambda_list += [\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=mirror_fibo_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_cub, out_plot_path=dir_alg, mirror_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=mirror_quad_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_cub, out_plot_path=dir_alg, mirror_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=mirror_fibo_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_lanc, out_plot_path=dir_alg, mirror_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=mirror_quad_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_lanc, out_plot_path=dir_alg, mirror_algorithm=None)\n",
    "        ]\n",
    "    algorithm_name_list+=[ \"Mir_Fibo_Cubic_Interp\", \"Mir_Quad_Cubic_Interp\",\n",
    "                         \"Mir_Fibo_Lanc_Interp\", \"Mir_Quad_Lanc_Interp\"]\n",
    "    \n",
    "    # Relative Rotation Naive\n",
    "    naive_rotation_alg_kw_args_cub = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC, 'X':X}\n",
    "    naive_rotation_alg_kw_args_lanc = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                                       'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_LANCZOS4, 'X':X}\n",
    "    naive_rotation_quad_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "    naive_rotation_fibo_kw_args = {'precision_fibonacci':1e-10, 'max_points_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "    algorithm_lambda_list += [\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=naive_rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_cub, out_plot_path=dir_alg),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names,  dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=naive_rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_cub, out_plot_path=dir_alg),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=naive_rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_lanc, out_plot_path=dir_alg),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=naive_rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_lanc, out_plot_path=dir_alg)\n",
    "        ]\n",
    "    algorithm_name_list+=[ \"Rot_Naive_Fibo_Cubic_Interp\", \"Rot_Naive_Quad_Cubic_Interp\",\n",
    "                         \"Rot_Naive_Fibo_Lanc_Interp\", \"Rot_Naive_Quad_Lanc_Interp\"]\n",
    "    \n",
    "    # Relative Rotation Phase Correlation Polar Plot\n",
    "    X=X\n",
    "    polar_fourier_alg_kw_args = {'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \\\n",
    "                            'desired_theta_accur':36000, 'theta_N':800, 'rad_N':800, \\\n",
    "                            'use_exact_gravicenter':True, 'X':X}\n",
    "    algorithm_lambda_list.append(\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_polar_fourier_phase_correlation(\n",
    "                    refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                                polar_fourier_alg_kw_args)\n",
    "    )\n",
    "    algorithm_name_list.append(\"Rel_Rot_Fourier_Phase_Correlat\")\n",
    "    \n",
    "    #polar_fourier_preprocess_fct = lambda images : normalize_to_max_and_iX_torch(\n",
    "    #                                            torch.from_numpy(images), in_are_dev_float=False, device=device)\n",
    "    # biher deu preprocess en torch urtetie de output eitzeko gravicenter kalkuleu segiduen, abia bamos\n",
    "    # alzu ein numpyera pasetie baia gero berriro torchera edo.\n",
    "    \n",
    "    \n",
    "    # Histogram Intra-Class\n",
    "    X=X\n",
    "    polar_hist_alg_kw_args = {'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \\\n",
    "                            'theta_N':365*10**1, 'rad_N':50, \\\n",
    "                            'use_exact_gravicenter':True, 'X':X}\n",
    "    #polar_histogram_preprocess_fct = lambda images : normalize_to_max_and_iX_torch(\n",
    "    #                                            torch.from_numpy(images), in_are_dev_float=False, device=device)\n",
    "    # exactly the same, pbie da biher dabiela gravicentroa explicitly\n",
    "    algorithm_lambda_list.append(\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_histogram_intra_class_var(\n",
    "                    refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                                polar_hist_alg_kw_args)\n",
    "    )\n",
    "\n",
    "    algorithm_name_list.append(\"Histo_Intra_Class_Var\")\n",
    "\n",
    "    \n",
    "    # Gravicenter Regression honek ya ezteu biher preproc espetzixelik\n",
    "    algorithm_lambda_list.append(\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_gradient_regression(\n",
    "                    refs, pbs, image_pair_names, preprocess_fct)\n",
    "    )\n",
    "\n",
    "    algorithm_name_list.append(\"Grad_Regress\")\n",
    "  \n",
    "    # Include in the names the preprocessing and the dataset!\n",
    " \n",
    "    if current_sub_block==1:\n",
    "        algorithm_name_list = [f\"{name}_Exper_to_Max_iX\" for name in algorithm_name_list]\n",
    "    elif current_sub_block==2:\n",
    "        algorithm_name_list = [f\"{name}_Exper_to_Mean_iX\" for name in algorithm_name_list]\n",
    "    elif current_sub_block==3:\n",
    "        algorithm_name_list = [f\"{name}_Exper_Sat_5per_iX\" for name in algorithm_name_list]\n",
    "    elif current_sub_block>=4 and current_sub_block<=8:\n",
    "        algorithm_name_list = [f\"{name}_Exper_Sigm_k{ks[current_sub_block-4]}_c{centers[current_sub_block-4]}_iX\" for name in algorithm_name_list]            \n",
    "    elif current_sub_block>=9 and current_sub_block<=11:\n",
    "        algorithm_name_list = [f\"{name}_Exper_Open_s{structs[current_sub_block-9]}_toMean_iX\" for name in algorithm_name_list]            \n",
    "    elif current_sub_block>=12 and current_sub_block<=14:\n",
    "        algorithm_name_list = [f\"{name}_Exper_LocalBin_s{block_sizes[current_sub_block-12]}_iX\" for name in algorithm_name_list]            \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "elif current_block==2: # PREPROCESS FUNCTION!\n",
    "    # to max noisy and iX\n",
    "    def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "        images = images.astype(np.float64)\n",
    "        free()\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "            images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                X=X, device=device)).to('cpu').numpy()\n",
    "            free()\n",
    "        return images\n",
    "    \n",
    "    opts=[]\n",
    "    k=0\n",
    "\n",
    "    for ransac in [True, False]:\n",
    "        for get_delta_from_grav_geom_centers in [True, False]:\n",
    "            for w in [0,0, 0.999, 0.9999, 1]:\n",
    "                opts+=[{'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \n",
    "                            'theta_N':360*10**1, 'rad_N':50, \n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "                              'method':'Nelder-Mead',\n",
    "                             'max_it':45, 'max_evals':50, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'get_delta_from_grav_geom_centers':get_delta_from_grav_geom_centers, \n",
    "                                    'w':w, 'ransac':ransac, \n",
    "                        'ransac_opts':{'min_samples':0.7, 'max_trials':40, 'residual_threshold':0.3}},\n",
    "                    {'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \n",
    "                                'theta_N':360*10**1, 'rad_N':50, \n",
    "                                'use_exact_gravicenter':True, 'X':X,\n",
    "                                  'method':'Powell',\n",
    "                                 'max_it':45, 'max_evals':50, 'abs_tol':0, 'rel_tol':0,\n",
    "                                 'get_delta_from_grav_geom_centers':get_delta_from_grav_geom_centers,\n",
    "                                        'w':w, 'ransac':ransac,\n",
    "                                'ransac_opts':{'min_samples':0.7, 'max_trials':40, 'residual_threshold':0.3}}]\n",
    "                \n",
    "                algorithm_lambda_list+=[\n",
    "                    lambda refs, pbs, image_pair_names, dir_alg : run_squared_cosine_fit_and_Carles(\n",
    "                          refs, pbs, image_pair_names, preprocess_fct,get_gravicentrum_batched,\n",
    "                                opts[k]),\n",
    "                    lambda refs, pbs, image_pair_names, dir_alg : run_squared_cosine_fit_and_Carles(\n",
    "                          refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                        opts[k])  \n",
    "                    ]\n",
    "                algorithm_name_list+=[\n",
    "                        f\"Blazq_CosSq_w{w}_ransac{ransac}_deltaFromGrav{get_delta_from_grav_geom_centers}_NM_Exper_DS\",\n",
    "                        f\"Blazq_CosSq_w{w}_ransac{ransac}_deltaFromGrav{get_delta_from_grav_geom_centers}_P_Exper_DS\"]\n",
    "\n",
    "\n",
    "    for min_samples in [0.3,0.5, 0.7, 0.9]:\n",
    "        for residual_thresh in [0.1, 0.2, 0.3, 0.5, None]:\n",
    "            opts.append({'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \n",
    "                                'theta_N':360*10**1, 'rad_N':50, \n",
    "                                'use_exact_gravicenter':True, 'X':X,\n",
    "                                  'method':'Nelder-Mead',\n",
    "                                 'max_it':30, 'max_evals':50, 'abs_tol':0, 'rel_tol':0,\n",
    "                                 'get_delta_from_grav_geom_centers':False, \n",
    "                                        'w':1, 'ransac':True, \n",
    "                        'ransac_opts':{'min_samples':min_samples, 'max_trials':40, 'residual_threshold':residual_thresh}})\n",
    "            algorithm_lambda_list+=[\n",
    "                          lambda refs, pbs, image_pair_names, dir_alg : run_squared_cosine_fit_and_Carles(\n",
    "                              refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                                    opts[k])]\n",
    "            algorithm_name_list+=[\n",
    "                    f\"Blazq_CosSq_w{w}_NM_minSampl{min_samples}_resTh{residual_thresh}_Exper_DS\"]\n",
    "\n",
    "            \n",
    "\n",
    "elif current_block==3:\n",
    "\n",
    "    if current_sub_block==1:\n",
    "        # simple CNN\n",
    "        X=X\n",
    "        feats_1=20\n",
    "        feats_2=20\n",
    "        feats_3=20\n",
    "        feats_4=5\n",
    "        prop1=2.5\n",
    "        prop2=1.5\n",
    "        prop3=0.6\n",
    "        av_pool1_div=2\n",
    "        conv4_feat_size=8\n",
    "        av_pool2_div=10\n",
    "        out_fc_1=5\n",
    "        dropout_p1=0.2\n",
    "        dropout_p2=0.1\n",
    "\n",
    "        model_simple_encoder = Simple_Encoder( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                         prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                         av_pool2_div=av_pool2_div, \n",
    "                         out_fc_1=out_fc_1,\n",
    "                         dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "        # In case we wish to transfer the learned parameters of another run\n",
    "        input_path = '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "        #check_file = \"/NNs/BEST_Noisy_Model_and_Optimizer_2022-03-01 18:08:09.693062_Simple_Encoder.pt\"\n",
    "        check_file = '/NNs/BEST_Noisy_Model_and_Optimizer_2022-02-28 10:46:31.497654_Simple_Encoder.pt'\n",
    "        checkpoint = torch.load(input_path+f\"/{check_file}\")\n",
    "\n",
    "        # move model to gpu if available\n",
    "\n",
    "        model_simple_encoder.to(device)\n",
    "        model_simple_encoder.print_shapes()\n",
    "        model_simple_encoder.load_my_state_dict(checkpoint['model'])        \n",
    "        model_simple_encoder.eval()\n",
    "        \n",
    "        algorithm_lambda_list.append(lambda refs, pbs, image_pair_names, dir_alg : run_angle_predictor_model(model_simple_encoder, refs, pbs, image_pair_names))       \n",
    "    if current_sub_block==2:\n",
    "        '''\n",
    "        # CNN+fc\n",
    "        X=302\n",
    "        feats_1=20\n",
    "        feats_2=20\n",
    "        feats_3=20\n",
    "        feats_4=5\n",
    "        prop1=2.5\n",
    "        prop2=1.5\n",
    "        prop3=0.6\n",
    "        av_pool1_div=2\n",
    "        conv4_feat_size=8\n",
    "        av_pool2_div=10\n",
    "        out_fc_1=5\n",
    "        dropout_p1=0.2\n",
    "        dropout_p2=0.1\n",
    "\n",
    "        model_encoder_fc = Simple_Encoder_fc( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                         prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                         av_pool2_div=av_pool2_div, \n",
    "                         out_fc_1=out_fc_1,\n",
    "                         dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "        # In case we wish to transfer the learned parameters of another run\n",
    "        input_path='/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "        check_file = \"/BEST_Noisy_Model_and_Optimizer_2022-06-15 15:46:26.465402_Simple_Encoder.pt\"\n",
    "        checkpoint = torch.load(input_path+f\"/{check_file}\")\n",
    "\n",
    "        # move model to gpu if available\n",
    "        \n",
    "        model_encoder_fc.to(device)\n",
    "        model_encoder_fc.print_shapes()\n",
    "        model_encoder_fc.load_my_state_dict(checkpoint['model'])\n",
    "        model_encoder_fc.eval()\n",
    "        \n",
    "        algorithm_lambda_list.append( lambda refs, pbs, image_pair_names, dir_alg : run_angle_predictor_model(model_encoder_fc, refs, pbs, image_pair_names))\n",
    "        '''        \n",
    "        # simple CNN\n",
    "        X=X\n",
    "        feats_1=20\n",
    "        feats_2=20\n",
    "        feats_3=20\n",
    "        feats_4=5\n",
    "        prop1=2.5\n",
    "        prop2=1.5\n",
    "        prop3=0.6\n",
    "        av_pool1_div=2\n",
    "        conv4_feat_size=8\n",
    "        av_pool2_div=10\n",
    "        out_fc_1=5\n",
    "        dropout_p1=0.2\n",
    "        dropout_p2=0.1\n",
    "\n",
    "        model_simple_encoder = Simple_Encoder( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                         prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                         av_pool2_div=av_pool2_div, \n",
    "                         out_fc_1=out_fc_1,\n",
    "                         dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "        # In case we wish to transfer the learned parameters of another run\n",
    "        input_path = '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "        check_file = \"/NNs/BEST_Noisy_Model_and_Optimizer_2022-03-01 18:08:09.693062_Simple_Encoder.pt\"\n",
    "        #check_file = '/NNs/BEST_Noisy_Model_and_Optimizer_2022-02-28 10:46:31.497654_Simple_Encoder.pt'\n",
    "        checkpoint = torch.load(input_path+f\"/{check_file}\")\n",
    "\n",
    "        # move model to gpu if available\n",
    "\n",
    "        model_simple_encoder.to(device)\n",
    "        model_simple_encoder.print_shapes()\n",
    "        model_simple_encoder.load_my_state_dict(checkpoint['model'])        \n",
    "        model_simple_encoder.eval()\n",
    "        \n",
    "        algorithm_lambda_list.append(lambda refs, pbs, image_pair_names, dir_alg : run_angle_predictor_model(model_simple_encoder, refs, pbs, image_pair_names))       \n",
    "    \n",
    "    if current_sub_block==1:\n",
    "        algorithm_name_list.append(\"CNN_1_angle_predictor_Exper_Dataset\")\n",
    "    elif current_sub_block==2:\n",
    "        algorithm_name_list.append(\"CNN_2_angle_predictor_Exper_Dataset\")\n",
    "\n",
    "    \n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "    \n",
    "print(algorithm_name_list)\n",
    "\n",
    "# List the Algorithms to test\n",
    "for exp_name in exp_names:\n",
    "    table_per_image[exp_name], table_per_alg[exp_name] = run_benchmark_output_result_histograms_and_result_table( \\\n",
    "            algorithm_lambda_list=algorithm_lambda_list, algorithm_name_list=algorithm_name_list,\\\n",
    "            references=references, problems=problems, image_pair_names=image_pair_names,\\\n",
    "            generate_algorithm_plots=False,\\\n",
    "            generate_histograms=False, boots_samples=boots_samples, confidence=confidence,\\\n",
    "            output_units=output_units, ground_truths=ground_truths, GT_units=GT_units,\\\n",
    "            GT_nature = GT_nature,\\\n",
    "            experiment_name = exp_name, \\\n",
    "            output_path=output_path)\n",
    "    free()\n",
    "    \n",
    "# Benetan gordeta dauzelez df danak, al da exekuteu hau bukaeran tras hacerle un input a todos los df-s\n",
    "# Generate Excel files!\n",
    "# Excel for algorithms\n",
    "writer = StyleFrame.ExcelWriter(f'{output_path}/{exp_names[0]}/EXCEL_Results_per_Algorithm.xlsx')\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(pd.DataFrame({'Absolute Error':['Absolute_Error']})).to_excel(writer, sheet_name=exp_name, startcol=1)\n",
    "    StyleFrame(pd.DataFrame({'Times':['Times']})).to_excel(writer, sheet_name=exp_name, startcol=5)\n",
    "    sf = StyleFrame(pd.DataFrame(table_per_alg[exp_name].index.get_level_values(0)))\n",
    "    sf.set_column_width(columns=[1], width=55.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1)\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Absolute_Error'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.5)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1, startcol=1, float_format=\"%.5f\")\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Times'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name,  startrow=1, startcol=5, float_format=\"%.5f\")\n",
    "writer.save()\n",
    "\n",
    "free()\n",
    "# Excel for images\n",
    "writer = StyleFrame.ExcelWriter(f\"{output_path}/{exp_names[0]}/EXCEL_Results_per_Image.xlsx\")\n",
    "StyleFrame.A_FACTOR=10\n",
    "StyleFrame.P_FACTOR=0.9\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(table_per_image[exp_name]).set_row_height(1,50).to_excel(writer, best_fit=list(table_per_image[exp_name].columns), sheet_name=exp_name, index=False,  float_format=\"%.8f\")\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MetaBlock_1_Block_1_Sub_block_11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7413/3621682905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable_per_alg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# menos precision en fibo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'MetaBlock_1_Block_1_Sub_block_11'"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_experimental\n",
    "table_per_alg[exp_names[0]] # menos precision en fibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MetaBlock_1_Block_1_Sub_block_11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7413/1722275199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable_per_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'MetaBlock_1_Block_1_Sub_block_11'"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_experimental\n",
    "table_per_image[exp_names[0]][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale parece que si se decanta por el lado equivocado convergera en un minimo equivocado tanto el quadratic como el fibonacci, porke es multimodal la funcion de coste. Para evitarlo podriamos hace runa fase de exploración inicial probando no se, 10 diferentes angulos equidistantes en el rango y de ellos elegir los tres primeros para hacer la primera exploración eligiendo los más altos de frontera y en medio poner el que sea más bajo. Si no tmabién se podría probar con otras métricas de similitud, probar la mae, la similarity CNN etc.\n",
    "Y si no hacer BF directamente claro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Using a large simulated Noisy Image Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "# General pipeline settings\n",
    "output_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}\"\n",
    "output_units = 'deg'\n",
    "confidence = 90\n",
    "boots_samples = 10000\n",
    "X=302\n",
    "dtype = np.float64\n",
    "dtype_torch = torch.float64\n",
    "\n",
    "\n",
    "\n",
    "num_image_pairs_test = 800\n",
    "\n",
    "\n",
    "\n",
    "if current_meta_block==2:\n",
    "    use_noisy = True\n",
    "elif current_meta_block==3:\n",
    "    use_noisy=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label\n",
    "    \n",
    "# Noisy Test set!\n",
    "GT_file_path_test_noisy = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_noisy =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST\"\n",
    "\n",
    "# Non-Noisy Test set!\n",
    "GT_file_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST\"\n",
    "\n",
    "\n",
    "random_seed = 666\n",
    "\n",
    "if use_noisy:\n",
    "    test_data = ImageDataset(GT_file_path_test_noisy, images_dir_path_test_noisy)\n",
    "else:\n",
    "    test_data = ImageDataset(GT_file_path_test_non_noisy, images_dir_path_test_non_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "np.random.seed(random_seed)\n",
    "random_indices_refs = np.random.choice(range(len(test_data)), num_image_pairs_test, replace=False)\n",
    "\n",
    "X21 = test_data[0][0].shape[1]\n",
    "X_references = np.zeros( (num_image_pairs_test, X21, X21), dtype=np.float32)\n",
    "y_references = np.zeros( (num_image_pairs_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_refs):\n",
    "    im, lab = test_data[idx]\n",
    "    X_references[j, :,:] = im[0]\n",
    "    y_references[j] = lab\n",
    "\n",
    "random_indices_pbs = np.random.choice(range(len(test_data)), num_image_pairs_test, replace=False)\n",
    "\n",
    "X_problems = np.zeros( (num_image_pairs_test, X21, X21), dtype=np.float32)\n",
    "y_problems = np.zeros( (num_image_pairs_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_pbs):\n",
    "    im, lab = test_data[idx]\n",
    "    X_problems[j, :,:] = im[0]\n",
    "    y_problems[j] = lab\n",
    "    \n",
    "image_pair_names = [f'REF_{ref_idx}_PB_{pb_idx}' for ref_idx, pb_idx in zip(random_indices_refs, random_indices_pbs)]\n",
    "\n",
    "ground_truths = y_problems-y_references\n",
    "ground_truths = np.array([angle_to_pi_pi(phi) for phi in ground_truths])/2\n",
    "\n",
    "del y_problems\n",
    "del y_references\n",
    "free()\n",
    "\n",
    "GT_units = 'rad'\n",
    "GT_nature = 'pol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "\n",
    "table_per_alg={}\n",
    "table_per_image={}\n",
    "exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']# , 'Normalize_to_average', 'Sigmoid de parametros tal y cual']\n",
    "\n",
    "\n",
    "algorithm_lambda_list=[]\n",
    "algorithm_name_list = []\n",
    "\n",
    "from skimage import morphology\n",
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "    \n",
    "if current_block==1 and current_meta_block==2: # noisy dataset\n",
    "    #rot, mirror, grad and hist  \n",
    "    # Sub_block specific stuff ########################\n",
    "    if current_sub_block==1: # ein in torch and not in torch bersioak, eta ein danak por batches procesetie!!!\n",
    "        # to max noisy and iX\n",
    "        def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                        ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                              X=302, device=device)).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        \n",
    "\n",
    "     \n",
    "        \n",
    "    elif current_sub_block==2:\n",
    "        # to max then to mean noisy and iX\n",
    "        def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                ims_t = ims_t/torch.mean(ims_t, axis=(-1,-2), keepdims=True)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=302, device=device)).to('cpu').numpy()\n",
    "                free() \n",
    "            return images\n",
    "        \n",
    "    \n",
    "    elif current_sub_block==3:\n",
    "        # to saturate at 0.05 noisy and iX\n",
    "        def preprocess_fct( images, saturation_threshold=0.05, batch_size=200, dtype=torch.float64 ):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                maxs = ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "                images[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch(\n",
    "                    (torch.where(\n",
    "                    ims_t<maxs*saturation_threshold, ims_t, 0.0)/maxs), 302, device).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        \n",
    "    elif current_sub_block>=4 and current_sub_block<=8:\n",
    "        # sigmoid lut noisy\n",
    "\n",
    "        centers = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        ks = [35, 35, 35, 35, 35]\n",
    "        for j,k in enumerate(ks):\n",
    "            ks[j] = np.log(254)/centers[j] if k<np.log(254)/centers[j]  else k\n",
    "            ks[j] = np.log(254)/(1-centers[j]) if k<np.log(254)/(1-centers[j]) else k\n",
    "        \n",
    "        def preprocess_fct(images, center=centers[current_sub_block-4],\n",
    "                    slope_squeezeness=ks[current_sub_block-4], dtype=torch.float64, batch_size=200):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                ims_t = ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                images[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch(\n",
    "                        1.0/(1+torch.exp(-slope_squeezeness*(ims_t-center)))\n",
    "                                                      , 302, device).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "    \n",
    "    elif current_sub_block>=9 and current_sub_block<=11:\n",
    "        # Opening to max to mean\n",
    "        structs = [7, 9, 11 ]#, 13]\n",
    "                                            \n",
    "        def to_max_to_mean(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                ims_t = ims_t/torch.mean(ims_t, axis=(-1,-2), keepdims=True)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=302, device=device)).to('cpu').numpy()\n",
    "                free() \n",
    "            return images\n",
    "        def get_struct(size, N):\n",
    "            foot = morphology.disk(size)\n",
    "            return np.repeat(foot[np.newaxis, :,:], N, axis=0)\n",
    "                                            \n",
    "        preprocess_fct = lambda ims : to_max_to_mean(\n",
    "            np.array([morphology.opening(im, morphology.disk(structs[current_sub_block-9]) ) for im in ims ]) )\n",
    "    \n",
    "    elif current_sub_block>=12 and current_sub_block<=14:\n",
    "        # local binarization    \n",
    "        block_sizes=[21,27, 47 ]\n",
    "        def to_gravicenter(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                        ims_t, X=302, device=device)).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        local_threshold_binarization=lambda im: im < threshold_local(\n",
    "            im, block_size=block_sizes[current_sub_block-12], offset=10)\n",
    "        preprocess_fct= lambda ims: to_gravicenter(1.0*np.array([ local_threshold_binarization(im) for im in ims]))\n",
    "    \n",
    "    \n",
    "\n",
    "if current_block==1 and current_meta_block==3: # non-noisy dataset\n",
    "    #rot, mirror, grad and hist  \n",
    "    def get_gravicentrum_batched(images, batch_size=200):\n",
    "        gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "                torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "            free()\n",
    "        return gravicenters\n",
    "\n",
    "    \n",
    "    # to max noisy and iX\n",
    "    def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "        images = images.astype(np.float64)\n",
    "        free()\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "            images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "                          ), X=302, device=device)).to('cpu').numpy()\n",
    "            free()\n",
    "        return images\n",
    "        \n",
    "if current_block==1:\n",
    "    # Block General stuff ################3\n",
    "    # Add Rotation\n",
    "    rotation_alg_kw_args_cub = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                            'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC}\n",
    "    rotation_alg_kw_args_lanc = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                            'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_LANCZOS4}\n",
    "    rotation_quad_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "    rotation_fibo_kw_args = {'precision_fibonacci':1e-10, 'max_points_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "\n",
    "\n",
    "    algorithm_lambda_list += [\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_cub, out_plot_path=dir_alg, rotation_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_cub, out_plot_path=dir_alg, rotation_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_lanc, out_plot_path=dir_alg, rotation_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=rotation_alg_kw_args_lanc, out_plot_path=dir_alg, rotation_algorithm=None)\n",
    "        ]\n",
    "    algorithm_name_list+=[ \"Rot_Kalkandjiev_Fibo_Cubic_Interp\", \"Rot_Kalkandjiev_Quad_Cubic_Interp\",\n",
    "                         \"Rot_Kalkandjiev_Fibo_Lanc_Interp\", \"Rot_Kalkandjiev_Quad_Lanc_Interp\"]\n",
    "        \n",
    "    # Add Mirror\n",
    "    mirror_alg_kw_args_cub = {'theta_min_Mir':0, 'theta_max_Mir':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC}\n",
    "    mirror_alg_kw_args_lanc = {'theta_min_Mir':0, 'theta_max_Mir':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_LANCZOS4}\n",
    "    mirror_quad_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "    mirror_fibo_kw_args = {'precision_fibonacci':1e-10, 'max_points_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "    \n",
    "    \n",
    "    algorithm_lambda_list += [\n",
    "        lambda refs, pbs, image_pair_names,  dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=mirror_fibo_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_cub, out_plot_path=dir_alg, \n",
    "                                                              mirror_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=mirror_quad_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_cub, out_plot_path=dir_alg, mirror_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=mirror_fibo_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_lanc, out_plot_path=dir_alg, mirror_algorithm=None),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_mirror_flip_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=mirror_quad_kw_args,\n",
    "                        mirror_alg_kw_args=mirror_alg_kw_args_lanc, out_plot_path=dir_alg, mirror_algorithm=None)\n",
    "        ]\n",
    "    algorithm_name_list+=[ \"Mir_Fibo_Cubic_Interp\", \"Mir_Quad_Cubic_Interp\",\n",
    "                         \"Mir_Fibo_Lanc_Interp\", \"Mir_Quad_Lanc_Interp\"]\n",
    "    \n",
    "    # Relative Rotation Naive\n",
    "    naive_rotation_alg_kw_args_cub = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                        'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_CUBIC, 'X':302}\n",
    "    naive_rotation_alg_kw_args_lanc = {'theta_min_Rot':-np.pi, 'theta_max_Rot':np.pi, 'initial_guess_delta_rad':0.1, \\\n",
    "                                       'use_exact_gravicenter':True, 'interpolation_flag':cv2.INTER_LANCZOS4, 'X':302}\n",
    "    naive_rotation_quad_kw_args = {'precision_quadratic':1e-10, 'max_it_quadratic':100, 'cost_tolerance_quadratic':1e-14}\n",
    "    naive_rotation_fibo_kw_args = {'precision_fibonacci':1e-10, 'max_points_fibonacci':100, 'cost_tolerance_fibonacci':1e-14}\n",
    "    algorithm_lambda_list += [\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=naive_rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_cub, out_plot_path=dir_alg),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=naive_rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_cub, out_plot_path=dir_alg),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"fibonacci\", search_alg_kw_args=naive_rotation_fibo_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_lanc, out_plot_path=dir_alg),\n",
    "\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_naive_affine_rotation_algorithm(references=refs, problems=pbs, \n",
    "                        image_pair_names=image_pair_names, preprocess_fct=preprocess_fct,\n",
    "                        search_algorithm=\"quadratic\", search_alg_kw_args=naive_rotation_quad_kw_args,\n",
    "                        rotation_alg_kw_args=naive_rotation_alg_kw_args_lanc, out_plot_path=dir_alg)\n",
    "        ]\n",
    "    algorithm_name_list+=[ \"Rot_Naive_Fibo_Cubic_Interp\", \"Rot_Naive_Quad_Cubic_Interp\",\n",
    "                         \"Rot_Naive_Fibo_Lanc_Interp\", \"Rot_Naive_Quad_Lanc_Interp\"]\n",
    "    \n",
    "    # Relative Rotation Phase Correlation Polar Plot\n",
    "    X=302\n",
    "    polar_fourier_alg_kw_args = {'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \\\n",
    "                            'desired_theta_accur':36000, 'theta_N':800, 'rad_N':800, \\\n",
    "                            'use_exact_gravicenter':True, 'X':X}\n",
    "    algorithm_lambda_list.append(\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_polar_fourier_phase_correlation(\n",
    "                    refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                                polar_fourier_alg_kw_args)\n",
    "    )\n",
    "    algorithm_name_list.append(\"Rel_Rot_Fourier_Phase_Correlat\")\n",
    "    \n",
    "    #polar_fourier_preprocess_fct = lambda images : normalize_to_max_and_iX_torch(\n",
    "    #                                            torch.from_numpy(images), in_are_dev_float=False, device=device)\n",
    "    # biher deu preprocess en torch urtetie de output eitzeko gravicenter kalkuleu segiduen, abia bamos\n",
    "    # alzu ein numpyera pasetie baia gero berriro torchera edo.\n",
    "    \n",
    "    \n",
    "    # Histogram Intra-Class\n",
    "    X=302\n",
    "    polar_hist_alg_kw_args = {'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \\\n",
    "                            'theta_N':365*10**1, 'rad_N':50, \\\n",
    "                            'use_exact_gravicenter':True, 'X':X}\n",
    "    #polar_histogram_preprocess_fct = lambda images : normalize_to_max_and_iX_torch(\n",
    "    #                                            torch.from_numpy(images), in_are_dev_float=False, device=device)\n",
    "    # exactly the same, pbie da biher dabiela gravicentroa explicitly\n",
    "    algorithm_lambda_list.append(\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_histogram_intra_class_var(\n",
    "                    refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                                polar_hist_alg_kw_args)\n",
    "    )\n",
    "\n",
    "    algorithm_name_list.append(\"Histo_Intra_Class_Var\")\n",
    "\n",
    "    \n",
    "    # Gravicenter Regression honek ya ezteu biher preproc espetzixelik\n",
    "    algorithm_lambda_list.append(\n",
    "        lambda refs, pbs, image_pair_names, dir_alg : run_gradient_regression(\n",
    "                    refs, pbs, image_pair_names, preprocess_fct)\n",
    "    )\n",
    "\n",
    "    algorithm_name_list.append(\"Grad_Regress\")\n",
    "  \n",
    "    # Include in the names the preprocessing and the dataset!\n",
    "    if not use_noisy: # non-noisy\n",
    "        algorithm_name_list = [f\"{name}_NonNoisy_to_Max_and_iX\" for name in algorithm_name_list]\n",
    "    else:\n",
    "        if current_sub_block==1:\n",
    "            algorithm_name_list = [f\"{name}_Noisy_to_Max_iX\" for name in algorithm_name_list]\n",
    "        elif current_sub_block==2:\n",
    "            algorithm_name_list = [f\"{name}_Noisy_to_Mean_iX\" for name in algorithm_name_list]\n",
    "        elif current_sub_block==3:\n",
    "            algorithm_name_list = [f\"{name}_Noisy_Sat_5per_iX\" for name in algorithm_name_list]\n",
    "        elif current_sub_block>=4 and current_sub_block<=8:\n",
    "            algorithm_name_list = [f\"{name}_Noisy_Sigm_k{ks[current_sub_block-4]}_c{centers[current_sub_block-4]}_iX\" for name in algorithm_name_list]            \n",
    "        elif current_sub_block>=9 and current_sub_block<=11:\n",
    "            algorithm_name_list = [f\"{name}_Noisy_Open_s{structs[current_sub_block-9]}_toMean_iX\" for name in algorithm_name_list]            \n",
    "        elif current_sub_block>=12 and current_sub_block<=14:\n",
    "            algorithm_name_list = [f\"{name}_Noisy_LocalBin_s{block_sizes[current_sub_block-12]}_iX\" for name in algorithm_name_list]            \n",
    "                                            \n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "elif current_block==2: # PREPROCESS FUNCTION!\n",
    "    # to max noisy and iX\n",
    "    def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "        images = images.astype(np.float64)\n",
    "        free()\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "            images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                    ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "                          ), X=302, device=device)).to('cpu').numpy()\n",
    "            free()\n",
    "        return images\n",
    "\n",
    "    txt = \"Noisy\" if use_noisy else \"NonNoisy\"\n",
    "    opts=[]\n",
    "    k=0\n",
    "\n",
    "    for ransac in [True, False]:\n",
    "        for get_delta_from_grav_geom_centers in [True, False]:\n",
    "            for w in [0,0, 0.999, 0.9999, 1]:\n",
    "                opts+=[{'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \n",
    "                            'theta_N':360*10**1, 'rad_N':50, \n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "                              'method':'Nelder-Mead',\n",
    "                             'max_it':45, 'max_evals':50, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'get_delta_from_grav_geom_centers':get_delta_from_grav_geom_centers, \n",
    "                                    'w':w, 'ransac':ransac, \n",
    "                        'ransac_opts':{'min_samples':0.7, 'max_trials':40, 'residual_threshold':0.3}},\n",
    "                    {'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \n",
    "                                'theta_N':360*10**1, 'rad_N':50, \n",
    "                                'use_exact_gravicenter':True, 'X':X,\n",
    "                                  'method':'Powell',\n",
    "                                 'max_it':45, 'max_evals':50, 'abs_tol':0, 'rel_tol':0,\n",
    "                                 'get_delta_from_grav_geom_centers':get_delta_from_grav_geom_centers,\n",
    "                                        'w':w, 'ransac':ransac,\n",
    "                                'ransac_opts':{'min_samples':0.7, 'max_trials':40, 'residual_threshold':0.3}}]\n",
    "                \n",
    "                algorithm_lambda_list+=[\n",
    "                    lambda refs, pbs, image_pair_names, dir_alg : run_squared_cosine_fit_and_Carles(\n",
    "                          refs, pbs, image_pair_names, preprocess_fct,get_gravicentrum_batched,\n",
    "                                opts[k]),\n",
    "                    lambda refs, pbs, image_pair_names, dir_alg : run_squared_cosine_fit_and_Carles(\n",
    "                          refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                        opts[k])  \n",
    "                    ]\n",
    "                algorithm_name_list+=[\n",
    "                        f\"Blazq_CosSq_w{w}_ransac{ransac}_deltaFromGrav{get_delta_from_grav_geom_centers}_NM_{txt}_DS\",\n",
    "                        f\"Blazq_CosSq_w{w}_ransac{ransac}_deltaFromGrav{get_delta_from_grav_geom_centers}_P_{txt}_DS\"]\n",
    "\n",
    "\n",
    "    for min_samples in [0.3,0.5, 0.7, 0.9]:\n",
    "        for residual_thresh in [0.1, 0.2, 0.3, 0.5, None]:\n",
    "            opts.append({'rad_scaling':'linear', 'interpolation_order':3, 'max_rad':(2*X+1)*2//3, \n",
    "                                'theta_N':360*10**1, 'rad_N':50, \n",
    "                                'use_exact_gravicenter':True, 'X':X,\n",
    "                                  'method':'Nelder-Mead',\n",
    "                                 'max_it':30, 'max_evals':50, 'abs_tol':0, 'rel_tol':0,\n",
    "                                 'get_delta_from_grav_geom_centers':False, \n",
    "                                        'w':1, 'ransac':True, \n",
    "                        'ransac_opts':{'min_samples':min_samples, 'max_trials':40, 'residual_threshold':residual_thresh}})\n",
    "            algorithm_lambda_list+=[\n",
    "                          lambda refs, pbs, image_pair_names, dir_alg : run_squared_cosine_fit_and_Carles(\n",
    "                              refs, pbs, image_pair_names, preprocess_fct, get_gravicentrum_batched,\n",
    "                                    opts[k])]\n",
    "            algorithm_name_list+=[\n",
    "                    f\"Blazq_CosSq_w{w}_NM_minSampl{min_samples}_resTh{residual_thresh}_{txt}_DS\"]\n",
    "\n",
    "            \n",
    "\n",
    "elif current_block==3:\n",
    "\n",
    "    if current_sub_block==1:\n",
    "        # simple CNN\n",
    "        X=302\n",
    "        feats_1=20\n",
    "        feats_2=20\n",
    "        feats_3=20\n",
    "        feats_4=5\n",
    "        prop1=2.5\n",
    "        prop2=1.5\n",
    "        prop3=0.6\n",
    "        av_pool1_div=2\n",
    "        conv4_feat_size=8\n",
    "        av_pool2_div=10\n",
    "        out_fc_1=5\n",
    "        dropout_p1=0.2\n",
    "        dropout_p2=0.1\n",
    "\n",
    "        model_simple_encoder = Simple_Encoder( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                         prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                         av_pool2_div=av_pool2_div, \n",
    "                         out_fc_1=out_fc_1,\n",
    "                         dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "        # In case we wish to transfer the learned parameters of another run\n",
    "        input_path = '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "        #check_file = \"/NNs/BEST_Noisy_Model_and_Optimizer_2022-03-01 18:08:09.693062_Simple_Encoder.pt\"\n",
    "        check_file = '/NNs/BEST_Noisy_Model_and_Optimizer_2022-02-28 10:46:31.497654_Simple_Encoder.pt'\n",
    "        checkpoint = torch.load(input_path+f\"/{check_file}\")\n",
    "\n",
    "        # move model to gpu if available\n",
    "\n",
    "        model_simple_encoder.to(device)\n",
    "        model_simple_encoder.print_shapes()\n",
    "        model_simple_encoder.load_my_state_dict(checkpoint['model'])        \n",
    "        model_simple_encoder.eval()\n",
    "        \n",
    "        algorithm_lambda_list.append(lambda refs, pbs, image_pair_names, dir_alg : run_angle_predictor_model(model_simple_encoder, refs, pbs, image_pair_names))       \n",
    "    if current_sub_block==2:\n",
    "        '''\n",
    "        # CNN+fc\n",
    "        X=302\n",
    "        feats_1=20\n",
    "        feats_2=20\n",
    "        feats_3=20\n",
    "        feats_4=5\n",
    "        prop1=2.5\n",
    "        prop2=1.5\n",
    "        prop3=0.6\n",
    "        av_pool1_div=2\n",
    "        conv4_feat_size=8\n",
    "        av_pool2_div=10\n",
    "        out_fc_1=5\n",
    "        dropout_p1=0.2\n",
    "        dropout_p2=0.1\n",
    "\n",
    "        model_encoder_fc = Simple_Encoder_fc( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                         prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                         av_pool2_div=av_pool2_div, \n",
    "                         out_fc_1=out_fc_1,\n",
    "                         dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "        # In case we wish to transfer the learned parameters of another run\n",
    "        input_path='/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "        check_file = \"/BEST_Noisy_Model_and_Optimizer_2022-06-15 15:46:26.465402_Simple_Encoder.pt\"\n",
    "        checkpoint = torch.load(input_path+f\"/{check_file}\")\n",
    "\n",
    "        # move model to gpu if available\n",
    "        \n",
    "        model_encoder_fc.to(device)\n",
    "        model_encoder_fc.print_shapes()\n",
    "        model_encoder_fc.load_my_state_dict(checkpoint['model'])\n",
    "        model_encoder_fc.eval()\n",
    "        \n",
    "        algorithm_lambda_list.append( lambda refs, pbs, image_pair_names, dir_alg : run_angle_predictor_model(model_encoder_fc, refs, pbs, image_pair_names))\n",
    "        '''        \n",
    "        # simple CNN\n",
    "        X=302\n",
    "        feats_1=20\n",
    "        feats_2=20\n",
    "        feats_3=20\n",
    "        feats_4=5\n",
    "        prop1=2.5\n",
    "        prop2=1.5\n",
    "        prop3=0.6\n",
    "        av_pool1_div=2\n",
    "        conv4_feat_size=8\n",
    "        av_pool2_div=10\n",
    "        out_fc_1=5\n",
    "        dropout_p1=0.2\n",
    "        dropout_p2=0.1\n",
    "\n",
    "        model_simple_encoder = Simple_Encoder( X=X, feats_1=feats_1, feats_2=feats_2, feats_3=feats_3, feats_4=feats_4,\n",
    "                         prop1=prop1, prop2=prop2, prop3=prop3, av_pool1_div=av_pool1_div, conv4_feat_size=conv4_feat_size, \n",
    "                         av_pool2_div=av_pool2_div, \n",
    "                         out_fc_1=out_fc_1,\n",
    "                         dropout_p1=dropout_p1, dropout_p2=dropout_p2 ) \n",
    "\n",
    "        # In case we wish to transfer the learned parameters of another run\n",
    "        input_path = '/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Simple_Encoder/'\n",
    "        check_file = \"/NNs/BEST_Noisy_Model_and_Optimizer_2022-03-01 18:08:09.693062_Simple_Encoder.pt\"\n",
    "        #check_file = '/NNs/BEST_Noisy_Model_and_Optimizer_2022-02-28 10:46:31.497654_Simple_Encoder.pt'\n",
    "        checkpoint = torch.load(input_path+f\"/{check_file}\")\n",
    "\n",
    "        # move model to gpu if available\n",
    "\n",
    "        model_simple_encoder.to(device)\n",
    "        model_simple_encoder.print_shapes()\n",
    "        model_simple_encoder.load_my_state_dict(checkpoint['model'])        \n",
    "        model_simple_encoder.eval()\n",
    "        \n",
    "        algorithm_lambda_list.append(lambda refs, pbs, image_pair_names, dir_alg : run_angle_predictor_model(model_simple_encoder, refs, pbs, image_pair_names))       \n",
    "    \n",
    "                      \n",
    "    if current_sub_block==1 and use_noisy:\n",
    "        algorithm_name_list.append(\"CNN_1_angle_predictor_Noisy_Dataset\")\n",
    "    elif current_sub_block==1 and not use_noisy:\n",
    "        algorithm_name_list.append(\"CNN_1_angle_predictor_Non_Noisy_Dataset\")\n",
    "    elif current_sub_block==2 and use_noisy:\n",
    "        algorithm_name_list.append(\"CNN_2_angle_predictor_Noisy_Dataset\")\n",
    "    elif current_sub_block==2 and not use_noisy:\n",
    "        algorithm_name_list.append(\"CNN_2_angle_predictor_Non_Noisy_Dataset\")\n",
    "    \n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "\n",
    "\n",
    "# List the Algorithms to test\n",
    "for exp_name in exp_names:\n",
    "    table_per_image[exp_name], table_per_alg[exp_name] = run_benchmark_output_result_histograms_and_result_table(\\\n",
    "        algorithm_lambda_list=algorithm_lambda_list, algorithm_name_list=algorithm_name_list,\\\n",
    "         references=X_references, problems=X_problems, image_pair_names=image_pair_names,\\\n",
    "        generate_algorithm_plots=False,\\\n",
    "        generate_histograms=True, boots_samples=boots_samples, confidence=confidence,\\\n",
    "        output_units=output_units, ground_truths=ground_truths, GT_units=GT_units,\\\n",
    "        GT_nature = GT_nature,\\\n",
    "        experiment_name = exp_name, \\\n",
    "        output_path=output_path)\n",
    "    free()\n",
    "    \n",
    "# Generate Excel files!\n",
    "# Excel for algorithms\n",
    "writer = StyleFrame.ExcelWriter(f'{output_path}/{exp_names[0]}/EXCEL_Results_per_Algorithm.xlsx')\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(pd.DataFrame({'Absolute Error':['Absolute_Error']})).to_excel(writer, sheet_name=exp_name, startcol=1)\n",
    "    StyleFrame(pd.DataFrame({'Times':['Times']})).to_excel(writer, sheet_name=exp_name, startcol=5)\n",
    "    sf = StyleFrame(pd.DataFrame(table_per_alg[exp_name].index.get_level_values(0)))\n",
    "    sf.set_column_width(columns=[1], width=55.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1)\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Absolute_Error'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.5)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1, startcol=1, float_format=\"%.5f\")\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Times'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name,  startrow=1, startcol=5, float_format=\"%.5f\")\n",
    "writer.save()\n",
    "\n",
    "free()\n",
    "# Excel for images\n",
    "writer = StyleFrame.ExcelWriter(f\"{output_path}/{exp_names[0]}/EXCEL_Results_per_Image.xlsx\")\n",
    "StyleFrame.A_FACTOR=10\n",
    "StyleFrame.P_FACTOR=0.9\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(table_per_image[exp_name]).set_row_height(1,50).to_excel(writer, best_fit=list(table_per_image[exp_name].columns), sheet_name=exp_name, index=False,  float_format=\"%.8f\")\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "table_per_alg[exp_names[0]] # menos precision en fibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "table_per_image[exp_names[0]][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write down state update!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MetaBlock_1_Block_1_Sub_block_11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7413/2198443590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable_per_alg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"META_BLOCK_{pipe_name}.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_meta_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MetaBlock_1_Block_1_Sub_block_11'"
     ]
    }
   ],
   "source": [
    "table_per_alg[exp_names[0]]\n",
    "\n",
    "f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_meta_block))\n",
    "f.close()\n",
    "f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_block))\n",
    "f.close()\n",
    "f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_sub_block))\n",
    "f.close()\n",
    "\n",
    "import os\n",
    "if current_meta_block==1: # experimental\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<11: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block==1: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "\n",
    "if current_meta_block==2: # noisy\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<14: # hacer todas las métricas diferentes!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block==1: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            \n",
    "if current_meta_block==3: # non-noisy\n",
    "    \n",
    "    if current_block==1: # only one subblock\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block==1: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"4\")\n",
    "            f.close()\n",
    "\n",
    "            \n",
    "restart_run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent=0.9\n",
    "k=35\n",
    "\n",
    "k= np.log(254)/cent if k<np.log(254)/cent  else k\n",
    "k= np.log(254)/(1-cent) if k<np.log(254)/(1-cent) else k\n",
    "print(k)\n",
    "#k=5.413/cent\n",
    "\n",
    "lut = 1/(1+np.exp(-k*(np.linspace(0,1,256)-cent)))\n",
    "plt.plot(np.linspace(0,1,256), lut)\n",
    "plt.plot([0,1],[0,0])\n",
    "plt.xlabel(\"Input intensity\")\n",
    "plt.ylabel(\"Output intensity\")\n",
    "plt.title(\"Look up table for point transformation\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "'''\n",
    "k=0.085\n",
    "cent=255*0.5\n",
    "lut = 255/(1+np.exp(-k*(np.arange(256)-cent)))\n",
    "plt.plot(lut)\n",
    "plt.xlabel(\"Input intensity\")\n",
    "plt.ylabel(\"Output intensity\")\n",
    "plt.title(\"Look up table for point transformation\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ima = cv2.imread( \"../EXPERIMENTAL/TEST_IMAGES/Reference__100.png\", cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(ima)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb = cv2.imread( \"../EXPERIMENTAL/TEST_IMAGES/antes_de_la_estandar.png\", cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(imb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = np.stack((ima,imb),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "thresh = threshold_otsu(im)\n",
    "binary = im > thresh\n",
    "\n",
    "plt.imshow(binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, morphology\n",
    "footprint = morphology.disk(5)\n",
    "res = morphology.white_tophat(im, footprint)\n",
    "res2=im-res\n",
    "plt.imshow(im-res)\n",
    "plt.show()\n",
    "plt.imshow(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, morphology\n",
    "footprint = morphology.disk(7)\n",
    "res = morphology.white_tophat(im, footprint)\n",
    "res2=im-res\n",
    "plt.imshow(im-res)\n",
    "plt.show()\n",
    "plt.imshow(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(footprint[np.newaxis, :,:], 5, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = np.stack((im1, im2), 0)\n",
    "footprint = morphology.disk(7)\n",
    "foots = np.stack((footprint, footprint),0)\n",
    "imso = morphology.opening(ims, foots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imso[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(im2, imso[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = morphology.disk(7)\n",
    "\n",
    "im2=morphology.opening(im, footprint)\n",
    "plt.imshow(im2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, morphology\n",
    "footprint = morphology.disk(11)\n",
    "res = morphology.black_tophat(im, footprint)\n",
    "plt.imshow(im+res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, morphology\n",
    "footprint = morphology.disk(11)\n",
    "res = morphology.black_tophat(im, footprint)\n",
    "now=im+res\n",
    "res2 = morphology.white_tophat(now, footprint)\n",
    "plt.imshow(res2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"}, figsize=(10,10))\n",
    "every=1\n",
    "X = np.linspace(0, im.shape[0], int(np.round(im.shape[0]/every)))\n",
    "Y = np.linspace(0,im.shape[1],  int(np.round(im.shape[1]/every)))\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "print(X.shape, im[::every, ::every].shape)\n",
    "surf = ax.plot_surface(X, Y, im2[::every, ::every], cmap=cm.coolwarm,\n",
    "                       linewidth=3, antialiased=True, rstride=10, cstride=10)\n",
    "                       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ims[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = threshold_local(ims, 31, offset=10)\n",
    "b = ims[1]<ths[0]\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_threshold_binarization=lambda im: im < threshold_local(im, block_size=31, offset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=1.0*np.array([ local_threshold_binarization(im) for im in ims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bins[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu, threshold_local, threshold_sauvola\n",
    "block_size = 47\n",
    "local_thresh = threshold_local(ims[1], block_size, offset=10)\n",
    "#local_thresh = threshold_sauvola(im, block_size)\n",
    "binary_local = ims[1] < local_thresh\n",
    "plt.imshow(binary_local)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " elif current_sub_block>=12 and current_sub_block<=14:\n",
    "        # local binarization    \n",
    "        block_sizes=[ 21,27, 47 ]\n",
    "        def to_gravicenter(images, batch_size=200, dtype=torch.float64):\n",
    "            images = images.astype(np.float64)\n",
    "            free()\n",
    "            for j in range(0, images.shape[0], batch_size):\n",
    "                ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "                images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                        ims_t, X=302, device=device)).to('cpu').numpy()\n",
    "                free()\n",
    "            return images\n",
    "        local_threshold_binarization=lambda im: im < threshold_local(\n",
    "            im, block_size=block_sizes[current_sub_block-12], offset=10)\n",
    "        preprocess_fct= lambda ims: to_gravicenter(1.0*np.array([ local_threshold_binarization(im) for im in ims]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_pre = preprocess_fct(ims)\n",
    "plt.imshow(ims_pre[0])\n",
    "plt.show()\n",
    "plt.imshow(ims_pre[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu, threshold_local, threshold_sauvola\n",
    "block_size = 21\n",
    "local_thresh = threshold_local(im, block_size, offset=10)\n",
    "#local_thresh = threshold_sauvola(im, block_size)\n",
    "binary_local = im < local_thresh\n",
    "plt.imshow(binary_local)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(im):\n",
    "    h = np.zeros(256)\n",
    "    for i in im:\n",
    "        h[i]+=1\n",
    "    return h\n",
    "plt.plot(hist(im))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread( \"../EXPERIMENTAL/TEST_IMAGES/con_los_dos.png\", cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "def sigmoid_no_lut_normalize_and_iX( images, in_are_dev_float, device, center=0.7, \n",
    "                       slope_squeezeness=50, dtype=torch.float64, X=302 ):\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)    \n",
    "    images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "    images = 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "    return compute_raws_to_centered_iXs_torch(images, X, device) # we need not noramlize them again if center if sigmoid chosen with sense\n",
    "# Ojo! se usan los valores float del lut como valores de la imagen! (no los cuantizados!)\n",
    "\n",
    "\n",
    "out_im = sigmoid_no_lut_normalize_and_iX(torch.from_numpy(im).unsqueeze(0), in_are_dev_float=False, \n",
    "                                         center = cent, device=device,\n",
    "                                         slope_squeezeness=k)\n",
    "plt.imshow(out_im[0].to('cpu').numpy())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "out_im = sigmoid_lut_using_numpy_normalize_and_iX( torch.from_numpy(im).unsqueeze(0), in_are_dev=False, device=device, \n",
    "                                                  center=0.5, \n",
    "                       slope_squeezeness=k, max_val_lut_process=255, lut_process_dtype=torch.uint8,\n",
    "                       output_dtype=torch.float64, X=302 )\n",
    "plt.imshow(out_im[0].to('cpu').numpy())\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
