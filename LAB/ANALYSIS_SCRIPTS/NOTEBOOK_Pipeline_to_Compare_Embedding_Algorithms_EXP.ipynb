{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "def restart_run_all():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                IPython.notebook.kernel.restart();\n",
    "                setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 1000)\n",
    "                \n",
    "            </script>\n",
    "        '''\n",
    "    ))\n",
    "\n",
    "import ctypes\n",
    "import gc\n",
    "\n",
    "def free():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "    \n",
    "def skip(line, cell=None):\n",
    "    '''Skips execution of the current line/cell if line evaluates to True.'''\n",
    "    if eval(line):\n",
    "        return\n",
    "\n",
    "    get_ipython().run_cell(cell) \n",
    "\n",
    "def load_ipython_extension(shell):\n",
    "    '''Registers the skip magic when the extension loads.'''\n",
    "    shell.register_magic_function(skip, 'line_cell')\n",
    "\n",
    "def unload_ipython_extension(shell):\n",
    "    '''Unregisters the skip magic when the extension unloads.'''\n",
    "    del shell.magics_manager.magics['cell']['skip']\n",
    "    \n",
    "    \n",
    "load_ipython_extension(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 7\n"
     ]
    }
   ],
   "source": [
    "pipe=2\n",
    "if pipe==1:\n",
    "    pipe_name = \"Proof_of_concept2\"\n",
    "    X=150\n",
    "elif pipe==2:\n",
    "    pipe_name = \"HeNe2\"\n",
    "    X=302\n",
    "elif pipe==3:\n",
    "    pipe_name = \"LED_small_rho2\"\n",
    "    X=422\n",
    "elif pipe==4:\n",
    "    pipe_name = \"LED_big_rho2\"\n",
    "    X=402\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    f = open(f\"META_BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_meta_block = int(f.read())\n",
    "    f.close()\n",
    "    f = open(f\"BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_block = int(f.read())\n",
    "    f.close()\n",
    "    f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"r\")\n",
    "    current_sub_block = int(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "except:\n",
    "    current_block = 1\n",
    "    current_sub_block = 1\n",
    "    current_meta_block = 1\n",
    "\n",
    "if current_meta_block>1:\n",
    "    hey\n",
    "    raise ValueError\n",
    "    \n",
    "    \n",
    "print(current_meta_block, current_block, current_sub_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_meta_block==1: # use only experimental\n",
    "    dont_use_simulated = True\n",
    "    dont_use_experimental = False\n",
    "else: # use noisy or non noisy simulated! 2, 3 respectively\n",
    "    dont_use_simulated = False\n",
    "    dont_use_experimental = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import scipy\n",
    "import cv2\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm\n",
    "from SOURCE.CLASS_CODE_Image_Manager import Image_Manager\n",
    "from SOURCE.CLASS_CODE_Ad_Hoc_Optimizer import Ad_Hoc_Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from skimage.filters import threshold_local\n",
    "from styleframe import StyleFrame\n",
    "import sklearn as sk\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE TO COMPARE EMBEDDING AND SIMULATOR ALGORITHMS\n",
    "---\n",
    "---\n",
    "\n",
    "    def alg tal (image_refs, image_pbs, save_output_plots_path=None):\n",
    "        ...\n",
    "        return predicted_delta_phiCRs, times (de cada pairwise image pair ref pb -que están en los mismos indices claro)\n",
    "\n",
    "Ke guarde los plots ke se outputean si hace falta en ese path dado.\n",
    "\n",
    "Ta gero funkiño bat que coja algs, que coja image pairs y si acaso coja sus ground-truths como opctional argument, y que te outputee la tabla de imagen, algoritmos delta phicR, delta pol, times, GT, absolute errors.\n",
    "\n",
    "Ta gero bebai outputee pa cada algoritmo un histograma de los absolute errors y un histograma de tiempos, con las medias y percentiles indicados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from SOURCE.CLASS_CODE_Polarization_Obtention_Algorithms import Rotation_Algorithm, Mirror_Flip_Algorithm\n",
    "from SOURCE.CLASS_CODE_Image_Manager import Image_Manager\n",
    "from SOURCE.CLASS_CODE_Ad_Hoc_Optimizer import Ad_Hoc_Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "from styleframe import StyleFrame\n",
    "\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_to_pi_pi( angle): # convert any angle to range (-pi,pi]\\n\",\n",
    "    angle= angle%(2*np.pi) # take it to [-2pi, 2pi]\\n\",\n",
    "    return angle-np.sign(angle)*2*np.pi if abs(angle)>np.pi else angle\n",
    "\n",
    "\n",
    "def compute_expectation_CI(empirical_pdf, boots_samples, confidence):\n",
    "    resamplings=np.random.choice(empirical_pdf, size=( boots_samples, empirical_pdf.shape[0]))\n",
    "    boot_means=np.mean(resamplings, axis=1)\n",
    "    boot_stds=np.std(resamplings, axis=1)\n",
    "    observed_mean=empirical_pdf.mean()\n",
    "    observed_std=empirical_pdf.std()\n",
    "    boots_t=(observed_mean-boot_means)*np.sqrt(empirical_pdf.shape[0])/boot_stds\n",
    "    boots_t_percentiles = np.percentile(boots_t, q=((100-confidence)/2, confidence+(100-confidence)/2))\n",
    "    return observed_mean+boots_t_percentiles*observed_std/np.sqrt(empirical_pdf.shape[0])\n",
    "\n",
    "\n",
    "def plot_histograms_for(category, variable, final_results_df, statistic_df, conf, output_path, bins_log=True):\n",
    "    categories=len(final_results_df.groupby([category])) # category sería algorithm\n",
    "                            # variable serían time, absolute error etc.\n",
    "    columns=1 if categories==1 else 2 if (categories==2 or categories==4) else 3\n",
    "    rows=categories//3+(categories%3!=0)\n",
    "\n",
    "    fig=plt.figure(figsize=(7*columns, 5*rows))\n",
    "    if bins_log:\n",
    "        bins_main_exponents=np.linspace(-8.5, -3.5, 32 ).tolist()\n",
    "        bins_main_exponents=[1]+bins_main_exponents+[-1,0]\n",
    "        #bins_main_exponents=[1,-8.5, -8, -7.5, -7, -6.5,-6,-5.5,-5,-4.5,-4,-3.5,-1,0]\n",
    "        bins_main=10**np.array(bins_main_exponents)\n",
    "        bins_main[0]=0\n",
    "    else:\n",
    "        bins_main=13\n",
    "    axs=[]\n",
    "    maxy=0\n",
    "    for i, (group_var_val, group_df) in enumerate(final_results_df.groupby([category])):\n",
    "        axs.append(fig.add_subplot(rows,columns, i+1))\n",
    "        ns, b, p = axs[-1].hist(group_df[variable], bins=bins_main,\n",
    "                        label=f\"{category}={group_var_val}\", \n",
    "                        rwidth=1, align='mid', edgecolor=\"k\", alpha=0.6) # range=(0,0.4)\n",
    "        if bins_log:\n",
    "            axs[-1].set_xscale('log')\n",
    "        axs[-1].grid(True)\n",
    "        axs[-1].axvline(x=statistic_df[variable][f'CI_{conf}_low'][group_var_val], color='m',\n",
    "                        linestyle='--', label=f'mean {conf} CI', alpha=0.6)\n",
    "        axs[-1].axvline(x=statistic_df[variable][f'CI_{conf}_up'][group_var_val], color='m', \n",
    "                        linestyle='--', alpha=0.6)\n",
    "        quantiles=np.percentile(group_df[variable], q=((100-conf)/2, conf+(100-conf)/2))\n",
    "        axs[-1].axvline(x=quantiles[0], color='r', linestyle='--', label=f'{conf} quantiles')\n",
    "        axs[-1].axvline(x=quantiles[1], color='r', linestyle='--')\n",
    "        axs[-1].set_title(f\"mu {conf}% CI:\\n ({statistic_df[variable][f'CI_{conf}_low'][group_var_val]}, \\\n",
    "                          {statistic_df[variable][f'CI_{conf}_up'][group_var_val]})\")\n",
    "        axs[-1].legend()\n",
    "        maxy = np.max(ns) if np.max(ns)>maxy else maxy\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(0,maxy)\n",
    "    #fig.supylabel('common_y')\n",
    "    fig.suptitle(f\"Histograms for {variable}\")\n",
    "    #fig.suptitle(f\"Histogrms for {variable} \\n\\n Experiment: {experiment_name}\\n\\n\\n The x axes represent the smallest absolute difference between the theoretical\\n angle difference and the found angle difference, among the employed algorithms\")\n",
    "\n",
    "    os.makedirs(f\"{output_path}/HISTOGRAMS/\", exist_ok=True)\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig(f\"{output_path}/HISTOGRAMS/Histogram_for_{variable}.png\", bbox_inches='tight')\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "times = {}\n",
    "predicted_delta_phiCRs = {}\n",
    "\n",
    "def run_benchmark_output_result_histograms_and_result_table( algorithm_lambda_list, algorithm_name_list,\n",
    "                                            references, problems, image_pair_names, generate_algorithm_plots,\n",
    "                                            generate_histograms, boots_samples=10000, confidence=95,\n",
    "                                            output_units='rad', ground_truths=None, GT_units=None,\n",
    "                                            GT_nature = 'phiCR',\n",
    "                                            experiment_name = None, output_path=None, batch_size=20):\n",
    "    if experiment_name is not None:\n",
    "        output_path = f\"{output_path}/{experiment_name}/\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "    # GTs should be in [-pi, pi] or [-180, 180]\n",
    "    global times\n",
    "    global predicted_delta_phiCRs\n",
    "    \n",
    "    conv = 180/np.pi if output_units=='deg' else 1\n",
    "    convGT = 180/np.pi if (output_units=='deg' and GT_units=='rad') else \\\n",
    "        np.pi/180 if (output_units=='rad' and GT_units=='deg') else 1\n",
    "    print(\"> Passing Images from each Algorithm...\")\n",
    "    for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "        if output_path is not None and generate_algorithm_plots:\n",
    "            dir_for_alg = output_path+f\"/{alg_name}/\"\n",
    "            os.makedirs( dir_for_alg, exist_ok=True )\n",
    "        else:\n",
    "            dir_for_alg = None\n",
    "        \n",
    "        predicted_delta_phiCRs[alg_name]={}\n",
    "        times[alg_name]={}\n",
    "        #try: # por si por ejemplo ransac no encuentra ningun consenso y salta un error\n",
    "        for j in range(0, references.shape[0], batch_size):\n",
    "            \n",
    "            batch_predicted_delta_phiCRs, batch_times =  algorithm(\n",
    "                    references[j:(j+batch_size)], problems[j:(j+batch_size)], \n",
    "                    image_pair_names[j:(j+batch_size)], dir_for_alg)\n",
    "            predicted_delta_phiCRs[alg_name].update(batch_predicted_delta_phiCRs)\n",
    "            times[alg_name].update(batch_times)\n",
    "            free()\n",
    "            print(f\"Processed {j} Samples\")\n",
    "        '''\n",
    "        except:\n",
    "            for imn in image_pair_names:\n",
    "                predicted_delta_phiCRs[alg_name][imn]=0\n",
    "                times[alg_name][imn]=0\n",
    "        '''\n",
    "        \n",
    "        print(f\" - Algorithm {alg_name} done!\")\n",
    "        try: # for the Carles algorithm to receive different arguments with a lambda function, en fin\n",
    "            global k\n",
    "            k+=1\n",
    "        except:\n",
    "            pass\n",
    "        free()\n",
    "        \n",
    "    print(\"\\n> Rearranging results in Tables and outputting to Excels...\")\n",
    "    if output_path is not None:\n",
    "        json.dump({'image_pair_names':image_pair_names, 'predicted_delta_phiCRs':predicted_delta_phiCRs,\n",
    "              'times':times}, open( f\"{output_path}/RAW_results.json\", \"w\"))\n",
    "    # Rearrange the result to our desired Table and unit formats\n",
    "    image_ids = []\n",
    "    image_names = []\n",
    "    algorithm_names = []\n",
    "    delta_phiCRs = []\n",
    "    delta_pols = []\n",
    "    timess = []\n",
    "    GTs = []\n",
    "    abs_errors = []\n",
    "    free()\n",
    "    switch_dif = 90 if output_units=='deg' else np.pi/2\n",
    "    max_diff = 2*switch_dif\n",
    "    # if abs dif is bigger than 90 then the true error is 180-that number for its the smallest plane difference in angle!\n",
    "    for idx, image_pair_name in enumerate(image_pair_names):\n",
    "        for algorithm, alg_name in zip(algorithm_lambda_list, algorithm_name_list):\n",
    "            image_ids.append(idx)\n",
    "            algorithm_names.append(alg_name)\n",
    "            image_names.append(image_pair_name)\n",
    "            delta_phiCRs.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][image_pair_name]) ) \n",
    "            delta_pols.append( conv*angle_to_pi_pi(predicted_delta_phiCRs[alg_name][image_pair_name])/2.0 )\n",
    "            timess.append(times[alg_name][image_pair_name])\n",
    "            if ground_truths is not None:\n",
    "                GTs.append(convGT*ground_truths[idx])\n",
    "                if GT_nature=='phiCR':\n",
    "                    abs_errors.append( np.abs(delta_phiCRs[-1]-convGT*ground_truths[idx]) )\n",
    "                else: # then GT is of polarization\n",
    "                    abs_dif = np.abs(delta_pols[-1]-convGT*ground_truths[idx])\n",
    "                    if abs_dif>switch_dif:\n",
    "                        abs_er = max_diff - abs_dif\n",
    "                    else:\n",
    "                        abs_er = abs_dif\n",
    "                    abs_errors.append( abs_er )\n",
    "                #correct_decimals.append() # beittu HISTOGRAMAGAZ batera zelan eitten zendun hau!\n",
    "    table_per_image = pd.DataFrame.from_dict({'ID':image_ids, 'Image_Pair_Name':image_names, 'Algorithm':algorithm_names,\n",
    "                                   'Predicted_Delta_PhiCRs':delta_phiCRs, 'Pred_Delta_Polarizt':delta_pols,\n",
    "                                   'Times':timess, f'Ground_Truth_{GT_nature}':GTs, 'Absolute_Error':abs_errors})\n",
    "    if output_path is not None:\n",
    "        table_per_image.to_pickle( f\"{output_path}/Table_Per_Image_All.pkl\")\n",
    "    print(\" - Table per images done!\")    \n",
    "    free()\n",
    "\n",
    "    # Group by algorithm and generate statistics by analyte (times, absolute_errors etc.)\n",
    "    groups = table_per_image.groupby('Algorithm')\n",
    "    stdv = groups[['Absolute_Error', 'Times']].std().fillna(0.0)\n",
    "    means = groups[['Absolute_Error', 'Times']].mean()\n",
    "    # Compute confidence intervals using bootstrap\n",
    "    CIs_time = {}\n",
    "    CIs_abs_er = {}\n",
    "    for alg_name, df in table_per_image.groupby('Algorithm'):\n",
    "        CIs_time[alg_name] = compute_expectation_CI(df['Times'],boots_samples, confidence)\n",
    "        CIs_abs_er[alg_name] = compute_expectation_CI(df['Absolute_Error'], boots_samples, confidence)\n",
    "        free()\n",
    "    CIs_time_df = pd.DataFrame(index=CIs_time.keys(), data=CIs_time.values(), columns=[f'CI_{confidence}_l', f'CI_{confidence}_u'])\n",
    "    CIs_abs_er_df = pd.DataFrame(index=CIs_abs_er.keys(), data=CIs_abs_er.values(), columns=[f'CI_{confidence}_l', f'CI_{confidence}_u'])\n",
    "    \n",
    "    ae = pd.concat([means['Absolute_Error'], stdv['Absolute_Error'],\n",
    "                    CIs_abs_er_df[f'CI_{confidence}_l'], CIs_abs_er_df[f'CI_{confidence}_u']],\n",
    "                   keys=['Mean', 'Standard_Dev', f'CI_{confidence}_low', f'CI_{confidence}_up'],axis=1)\n",
    "    ts = pd.concat([means['Times'], stdv['Times'],\n",
    "                    CIs_time_df[f'CI_{confidence}_l'], CIs_time_df[f'CI_{confidence}_u']],                   \n",
    "                   keys=['Mean', 'Standard_Dev', f'CI_{confidence}_low', f'CI_{confidence}_up'],axis=1)\n",
    "    table_per_alg = pd.concat([ae, ts], keys=['Absolute_Error', 'Times'], axis=1)    \n",
    "    free()\n",
    "\n",
    "    if output_path is not None:\n",
    "        table_per_image.to_pickle( f\"{output_path}/Table_Per_Algorithm_Statistics.pkl\")\n",
    "        print(\" - Table per algorithm done!\")    \n",
    "        if generate_histograms:\n",
    "            print(\"\\n> Generating histograms...\")\n",
    "            plot_histograms_for('Algorithm', 'Absolute_Error', table_per_image, table_per_alg, confidence, output_path, bins_log=False)\n",
    "            plot_histograms_for('Algorithm', 'Times', table_per_image, table_per_alg, confidence, output_path, bins_log=False)\n",
    "            print(\"DONE!\")\n",
    "    return table_per_image, table_per_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity_gravity_center(image):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [h, w].\n",
    "        It will return an array of gravity centers [2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to numpy indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = np.sum(image, axis=0) # weights for x [raw_width]\n",
    "    intensity_in_h = np.sum(image, axis=1) # weights for y [raw_height]\n",
    "    total_intensity = intensity_in_h.sum()\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [2] (h_center,w_center)\n",
    "    return np.nan_to_num( np.stack(\n",
    "        (np.dot(intensity_in_h, np.arange(image.shape[0]))/total_intensity,\n",
    "         np.dot(intensity_in_w, np.arange(image.shape[1]))/total_intensity)\n",
    "        ) )\n",
    "\n",
    "def compute_raw_to_centered_iX(image, X):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_center(image)\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_image = np.zeros( (2*X+1, 2*X+1),  dtype = image.dtype )\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = np.rint(g_raw).astype(int) #[N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw[:]-X\n",
    "    unclipped_upper = g_index_raw[:]+X+1\n",
    "    # unclippde could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = np.clip( unclipped_lower, a_min=0, a_max=image.shape)\n",
    "    upper_bound = np.clip( unclipped_upper, a_min=0, a_max=image.shape)\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    centered_image[padding_lower[0]:padding_upper[0] or None,\n",
    "                                    padding_lower[1]:padding_upper[1] or None ] = \\\n",
    "                  image[lower_bound[0]:upper_bound[0],\n",
    "                                      lower_bound[1]:upper_bound[1]]\n",
    "    return centered_image\n",
    "\n",
    "\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                              iX_dev='cpu', out_dev='cpu', X=X): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                                     iX_dev='cpu', out_dev='cpu', X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    maxs = np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<maxs*saturation_threshold, images, 0.0)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX(images,  saturation_threshold, dtype=np.float64,\n",
    "                                      iX_dev='cpu', out_dev='cpu', X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)\n",
    "    means = np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_max_and_iX(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=X): # images expected to be [N_images, h, w]\n",
    "    images= images.astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def normalize_to_mean_and_iX(images, dtype=np.float64,\n",
    "                     iX_dev='cpu', out_dev='cpu', X=X): # images expected to be [N_images, h, w]\n",
    "    images = images.astype(dtype)/np.expand_dims( np.mean(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()\n",
    "\n",
    "def sigmoid_lut_and_iX( images, center=0.5, slope_squeezeness=0.085, max_val=255, dtype=np.float64, X=X ):\n",
    "    lut = max_val/(1+np.exp(-slope_squeezeness*(np.arange(max_val+1)-center*max_val)))\n",
    "    images = (lut[ images ]).astype(dtype)\n",
    "    return compute_raws_to_centered_iXs_torch( torch.from_numpy(images).to(device), X, device).to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch in out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_max_saturate_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=X): # threshold is in [0,1] of max\n",
    "                                                              # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.abmax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_mean_saturate_to_max_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    images = torch.where(images<maxs*saturation_threshold, images, 0.0)/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_saturate_to_mean_and_iX_torch(images,  in_are_dev_float, saturation_threshold, \n",
    "                                           device, dtype=torch.float32, X=X):  # threshold is in [0,1] of max\n",
    "                                                                # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    means=torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "    images = np.where(images<means*saturation_threshold, images, 0.0)/means\n",
    "    return compute_raws_to_centered_iXs_torch( images, X, device)\n",
    "\n",
    "def normalize_to_max_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=torch.float32, X=X): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "\n",
    "\n",
    "def normalize_to_mean_and_iX_torch(images, in_are_dev_float, \n",
    "                                device, dtype=torch.float32, X=X): # images expected to be [N_images, h, w]\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    return compute_raws_to_centered_iXs_torch(images/torch.mean(images, axis=(-1,-2), keepdims=True), X, device)\n",
    "\n",
    "\n",
    "def sigmoid_lut_using_numpy_normalize_and_iX( images, in_are_dev, device, center=0.5, \n",
    "                       slope_squeezeness=0.085, max_val_lut_process=255, lut_process_dtype=torch.uint8,\n",
    "                       output_dtype=torch.float64, X=X ):\n",
    "    if not in_are_dev:\n",
    "        images = images.to(device)\n",
    "    images = (max_val_lut_process*(images.type(torch.float64)/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)))\n",
    "                 ).type(lut_process_dtype)\n",
    "    \n",
    "    lut = (max_val_lut_process/(1+np.exp(-slope_squeezeness*(np.arange(max_val_lut_process+1)-\n",
    "                                                               center*max_val_lut_process))))\n",
    "    images = torch.from_numpy(lut[ images.to('cpu').numpy() ]).to(device).type(output_dtype)\n",
    "    return compute_raws_to_centered_iXs_torch(images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)), X, device)\n",
    "# Ojo! se usan los valores float del lut como valores de la imagen! (no los cuantizados!)\n",
    "\n",
    "def sigmoid_no_lut_normalize_and_iX( images, in_are_dev_float, device, center=0.7, \n",
    "                       slope_squeezeness=50, dtype=torch.float64, X=X ):\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)    \n",
    "    images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "    images = 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "    return compute_raws_to_centered_iXs_torch(images, X, device) # we need not noramlize them again if center if sigmoid chosen with sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (G) Metric/Embedding como look-up table (aka KNN) for SKLEARN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#args_sk_KNN = {'n_neighbors':3, 'weights':'distance', 'algorithm':'auto', 'leaf_size':50, 'p':2,\n",
    "#               'metric':'minkowski', 'n_jobs':n_jobs}\n",
    "\n",
    "class KNN_Regressor():\n",
    "    def __init__(self, embedder_func, args_sk_KNN):\n",
    "        # ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\n",
    "        # ‘uniform’, ‘distance’\n",
    "        self.embedder_func = embedder_func\n",
    "        self.KNN = sk.neighbors.KNeighborsRegressor(n_neighbors=args_sk_KNN['n_neighbors'],\n",
    "                    weights=args_sk_KNN['weights'], algorithm=args_sk_KNN['algorithm'],\n",
    "                    leaf_size=args_sk_KNN['leaf_size'], p=args_sk_KNN['p'], \n",
    "                    metric=args_sk_KNN['metric'], n_jobs=args_sk_KNN['n_jobs'])\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, X, y, already_embedded_X=False): # X [N_samples, dim_feats], y [N_samples] # y can be to regression floats!\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X) # [N_samples, dim_feats]\n",
    "        self.KNN = self.KNN.fit(X, y)\n",
    "        self.fitted = True\n",
    "    \n",
    "    def score(self, X, y, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.score(X,y)\n",
    "        \n",
    "    def predict(self, X, already_embedded_X=False):\n",
    "        if not already_embedded_X:\n",
    "            X = self.embedder_func(X)\n",
    "        return self.KNN.predict(X)\n",
    "    \n",
    "class Sklearn_embedder():\n",
    "    def __init__(self, embedder, preprocess_fct):\n",
    "        self.preprocess_fct = preprocess_fct\n",
    "        self.embedder = embedder\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.embedder.transform( self.preprocess_fct(X) )\n",
    "    \n",
    "pre_process_name = \"normalize_to_max_and_iX\"\n",
    "\n",
    "import torch\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def compute_intensity_gravity_centers_torch( images):\n",
    "    \"\"\"\n",
    "        Expects input image to be an array of dimensions [N_imgs, h, w].\n",
    "        It will return an array of gravity centers [N_imgs, 2(h,w)] in pixel coordinates\n",
    "        Remember that pixel coordinates are set equal to array indices\n",
    "\n",
    "    \"\"\"\n",
    "    # image wise total intensity and marginalized inensities for weighted sum\n",
    "    intensity_in_w = torch.sum(images, dim=1) # weights for x [N_images, raw_width]\n",
    "    intensity_in_h = torch.sum(images, dim=2) # weights for y [N_images, raw_height]\n",
    "    total_intensity = intensity_in_h.sum(dim=1) # [N_images]\n",
    "\n",
    "    # Compute mass center for intensity\n",
    "    # [N_images, 2] (h_center,w_center)\n",
    "    return torch.nan_to_num( torch.stack(\n",
    "        (torch.matmul(intensity_in_h.float(), torch.arange(images.shape[1], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity,\n",
    "         torch.matmul(intensity_in_w.float(), torch.arange(images.shape[2], \n",
    "                                    dtype=torch.float32, device=device))/total_intensity),\n",
    "        dim=1\n",
    "        ), nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "def compute_raws_to_centered_iXs_torch( images, X, device):\n",
    "\n",
    "    g_raw = compute_intensity_gravity_centers_torch(images) # [ N_images, 2]\n",
    "\n",
    "    # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "    # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "    # a 0 padding will be made.\n",
    "    centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                  device=device)\n",
    "\n",
    "    # we round the gravity centers to the nearest pixel indices\n",
    "    g_index_raw = torch.round(g_raw).int() #[ N_images, 2]\n",
    "\n",
    "    # obtain the slicing indices around the center of gravity\n",
    "    # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "    # a new axis!!\n",
    "    # [ N_images, 2 (h,w)]\n",
    "    unclipped_lower = g_index_raw-X\n",
    "    unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "    # unclipped could get out of bounds for the indices, so we clip them\n",
    "    lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                             max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "    # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "    # such that the center of gravity is left still in the center of the image\n",
    "    padding_lower = lower_bound-unclipped_lower\n",
    "    padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "    # crop the image\n",
    "    for im in range(g_raw.shape[0]):\n",
    "        centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                    padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                  images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                      lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "    return centered_images\n",
    "\n",
    "import gc\n",
    "def normalize_to_max_and_iX_input_output_flatten(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=X, batch_size=100): # images expected to be [N_images, h, w]\n",
    "    out = np.zeros((images.shape[0], (X*2+1)**2), dtype=np.float64)\n",
    "    images= images.astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "    images = images.reshape(-1, X*2+1, X*2+1)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        out[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch( torch.from_numpy(images[j:(j+batch_size)]).to(device), X, device).to('cpu').numpy().reshape(len(out[j:(j+batch_size)]), -1)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    return out\n",
    "\n",
    "\n",
    "preprocess_fct = normalize_to_max_and_iX_input_output_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sklearn as sk\n",
    "import sklearn.neighbors\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import umap\n",
    "import pickle\n",
    "from time import time\n",
    "#exp_emb='Noisy_Dataset_Embedders'\n",
    "#knn_embedder_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{exp_emb}/\"\n",
    "\n",
    "#f_name = f\"PCA_KNN_n_images_600_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_3_seed_666_date_14_06_2022_20h43m1655232227.sav\"\n",
    "#preprocess_and_embed =  Está dentro del knn_alg incluido!\n",
    "#trained_knn_alg = pickle.load((open(knn_embedder_stuff_path+f_name, 'rb')))\n",
    "\n",
    "def run_knn_on_embedding_space(references, problems, image_pair_names,   \n",
    "                       trained_knn_alg): # if as embedder one gives a pre_process_fct, it will work the same way\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "\n",
    "    t=time()\n",
    "    \n",
    "    ref = trained_knn_alg.predict( references.reshape(references.shape[0],-1), already_embedded_X=False )\n",
    "    pb = trained_knn_alg.predict( problems.reshape(problems.shape[0],-1), already_embedded_X=False )\n",
    "    angles = pb-ref\n",
    "    \n",
    "    t = time()-t\n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = t/len(references)\n",
    "        \n",
    "    return predicted_deltaPhiCRs, times    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (G.2) Metric/Embedding como look-up table (aka KNN) for Triplet loss embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #should be installed by default in any colab notebook\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "'''\n",
    "\n",
    "class Proximity_Metric_Based_On_Simple_Encoder(nn.Module):\n",
    "    def __init__(self, X=X, feats_1=15, feats_2=20, feats_3=20, feats_4=20,\n",
    "                 prop1=3, prop2=2, prop3=1, av_pool1_div=4, conv4_feat_size=15, av_pool2_div=10, \n",
    "                 out_fc_1=10, out_fc_2=10,\n",
    "                 dropout_p1=0.2, dropout_p2=0.1\n",
    "                ): \n",
    "        # propj is such that the_ image getting out from stage j is propj/prop_{j-1}-ths of the previous (with j=0 being 5)\n",
    "        # clearly, prop_{j-1}>prop_{j}>...\n",
    "        # 2X+1 will be assumed to be divisible by 5\n",
    "        assert((2*X+1)%5==0)\n",
    "        assert(prop1>prop2)\n",
    "        assert(prop2>prop3)\n",
    "        assert((int((prop3*(2*X+1)/5)/av_pool1_div)-conv4_feat_size)>0)\n",
    "        \n",
    "        \n",
    "        super(Proximity_Metric_Based_On_Simple_Encoder, self).__init__()\n",
    "        # in is [epoch_size, 1, 2X+1, 2X+1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=feats_1, \n",
    "                               kernel_size = int((2*X+1)/5*(5-prop1)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        self.conv2 = nn.Conv2d(in_channels=feats_1, out_channels=feats_2, \n",
    "                               kernel_size = int((2*X+1)/5*(prop1-prop2)+1), bias=True) \n",
    "        # out conv1 [epoch_size, feats_2, prop2*(prop1*(2X+1)/5)/prop1, prop2*(prop1*(2X+1)/5)/prop1]\n",
    "        # that is [epoch_size, feats_2, prop2*(2X+1)/5), prop2*(2X+1)/5)]\n",
    "        self.conv3 = nn.Conv2d(in_channels=feats_2, out_channels=feats_3, \n",
    "                               kernel_size = int((2*X+1)/5*(prop2-prop3)+1), bias=True)\n",
    "        # out conv3 is [epoch_size, feats_3, prop3*(2X+1)/5), prop3*(2X+1)/5)]\n",
    "\n",
    "        self.avPool1 = nn.AvgPool2d(kernel_size= int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=feats_3, out_channels=feats_4, \n",
    "                              kernel_size= int((prop3*(2*X+1)/5)/av_pool1_div+1)-conv4_feat_size+1, bias=True)\n",
    "        # [epoch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "        \n",
    "        self.avPool2 = nn.AvgPool2d(kernel_size= int(conv4_feat_size*(1-1/av_pool2_div)) +1, stride=1)\n",
    "        # out avpool1 is [epoch_size, feats_4, conv4_feat_size/av_pool2_div+1, conv4_feat_size/av_pool2_div+1]\n",
    "        \n",
    "        #self.in_fc = int(feats_4*(conv4_feat_size/av_pool2_div+1)**2)\n",
    "        self.in_fc = feats_4*((((((2*X+1-int((2*X+1)/5*(5-prop1)+1)+1)\n",
    "                                  -int((2*X+1)/5*(prop1-prop2)+1)+1)\n",
    "                                 -int((2*X+1)/5*(prop2-prop3)+1)+1)\n",
    "                                -int((prop3*(2*X+1)/5)*(1-1/av_pool1_div)) -1+1)\n",
    "                               -int((prop3*(2*X+1)/5)/av_pool1_div+1)+conv4_feat_size-1+1)\n",
    "                              -int(conv4_feat_size*(1-1/av_pool2_div)) -1+1)**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc, out_features=out_fc_1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc_1, out_features=out_fc_2, bias=True)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1, inplace=False)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=feats_2)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=feats_4)\n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        x = self.relu( self.conv1(x) ) # [batch_size, feats_1, prop1*(2X+1)/5, prop1*(2X+1)/5]\n",
    "        \n",
    "        x = self.batchNorm2( self.relu( self.conv2(self.dropout1(x)) )) # [batch_size, feats_2, prop2*(2X+1)/5, prop2*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.conv3(self.dropout2(x)) ) # [batch_size, feats_3, prop3*(2X+1)/5, prop3*(2X+1)/5]\n",
    "\n",
    "        \n",
    "        x = self.avPool1(x) # [batch_size, feats_3, prop3*(2X+1)/5)/av_pool1_div, prop3*(2X+1)/5)/av_pool1_div]\n",
    "\n",
    "        \n",
    "        x = self.batchNorm4(self.conv4(self.dropout2(x))) # [batch_size, feats_4, conv4_feat_size, conv4_feat_size]\n",
    "\n",
    "        \n",
    "        x = self.relu( self.avPool2(x) ) # [batch_size, feats_4, conv4_feat_size/av_pool2_div, conv4_feat_size/av_pool2_div]\n",
    "\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc) #[batch_size, feats_4*int(conv4_feat_size/av_pool2_div)**2]\n",
    "\n",
    "        \n",
    "        x = self.fc2( self.relu( self.fc1(x) ) ) #[batch_size, out_fc_2]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Proximity_Metric_Based_On_Corrector(nn.Module):\n",
    "    def __init__(self, S0=2*302+1, S1=2*290+1, S2=2*250+1, S3=2*200+1, S4 = 2*10+1,\n",
    "                 S5 = 2*1+1, S6 =2,\n",
    "                 feats_S1=10, feats_S2=10, feats_S3=20, feats_S4=20, feats_S5 = 20,\n",
    "                 out_fc1=100, out_fc2=10,\n",
    "                 feats_S6 = 25,\n",
    "                 dropout_p=0.1\n",
    "                ): \n",
    "       \n",
    "        super(Proximity_Metric_Based_On_Corrector, self).__init__()\n",
    "        self.Ss = [S0, S1, S2, S3, S4, S5, S6]\n",
    "        self.feats = [1, feats_S1, feats_S2, feats_S3, feats_S4, feats_S5, feats_S6]\n",
    "        self.out_fc1 = out_fc1\n",
    "        self.out_fc2 = out_fc2\n",
    "        # in is [batch_size, 1, S0, S0]\n",
    "        self.conv_S01 = nn.Conv2d(in_channels=1, out_channels=feats_S1, \n",
    "                               kernel_size = S0-S1+1, bias=True) \n",
    "        # out conv_S01 [batch_size, feats_S1, S1, S1]\n",
    "        self.conv_S12 = nn.Conv2d(in_channels=feats_S1, out_channels=feats_S2, \n",
    "                               kernel_size = S1-S2+1, bias=True) \n",
    "        # out conv_S12 [batch_size, feats_S2, S2, S2]\n",
    "        self.conv_S23 = nn.Conv2d(in_channels=feats_S2, out_channels=feats_S3, \n",
    "                               kernel_size = S2-S3+1, bias=True) \n",
    "        # out conv_S23 [batch_size, feats_S3, S3, S3]\n",
    "        \n",
    "        self.conv_S33 = nn.Conv2d(in_channels=feats_S3, out_channels=feats_S3, \n",
    "                               kernel_size = 1, bias=True) \n",
    "        # out conv_S33 [batch_size, feats_S3, S3, S3]\n",
    "        \n",
    "        self.conv_S34 = nn.Conv2d(in_channels=feats_S3, out_channels=feats_S4, \n",
    "                               kernel_size = S3-S4+1, bias=True) \n",
    "        # out conv_S34 [batch_size, feats_S4, S4, S4]\n",
    "        \n",
    "        self.conv_S45 = nn.Conv2d(in_channels=feats_S4, out_channels=feats_S5, \n",
    "                               kernel_size = S4-S5+1, bias=True) \n",
    "        # out conv_S45 [batch_size, feats_S5, S5, S5]\n",
    "        self.conv_S56 = nn.Conv2d(in_channels=feats_S5, out_channels=feats_S6, \n",
    "                               kernel_size = S5-S6+1, bias=True) \n",
    "        # out conv_S56 [batch_size, feats_S6, S6, S6]\n",
    "        \n",
    "        self.in_fc1 = S6*S6*feats_S6\n",
    "        self.fc1 = nn.Linear(in_features=self.in_fc1, out_features=out_fc1, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=out_fc1, out_features=out_fc2, bias=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_p, inplace=False)\n",
    "        self.relu = torch.nn.functional.leaky_relu\n",
    "\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=feats_S3)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(num_features=out_fc1)\n",
    "        \n",
    "\n",
    "    def forward(self, x): # [batch_size, 2X+1, 2X+1] or [batch_size, 1, 2X+1, 2X+1]\n",
    "        x = x.view(x.shape[0], 1, x.shape[-2], x.shape[-1]).float() # [batch_size, 1, 2X+1, 2X+1]\n",
    "        # Normalize to unity the float image\n",
    "        x = x/x.amax(dim=(2,3), keepdim=True)[0] # [batch_size, 1, 2X+1, 2X+1]\n",
    "        \n",
    "        # Conv layers\n",
    "        x = self.relu(self.conv_S01(x)) # [batch_size, feats_S1, S1, S1]\n",
    "        x = self.dropout( self.relu(self.conv_S12(x)) ) # [batch_size, feats_S2, S2, S2]\n",
    "        x = self.relu(self.conv_S23(x)) # [batch_size, feats_S3, S3, S3]\n",
    "        x = self.batchNorm1(self.relu(self.conv_S33(x)))\n",
    "        x = self.relu(self.conv_S34(x))\n",
    "        x = self.relu(self.conv_S45(x))\n",
    "        x = self.relu(self.conv_S56(x))\n",
    "        \n",
    "        x = x.view(x.shape[0], self.in_fc1)\n",
    "        x = self.dropout( self.relu(self.batchNorm2(self.fc1(self.dropout(x)))) )\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                    'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                    'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "'''\n",
    "class Triplet_NN_embedder(): # INPUT DATA IS ASSUMED TO BE NUMPY\n",
    "    def __init__(self, args_NN_embedder, checkpoint_path, device, batch_size=50,\n",
    "                 encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\"):\n",
    "        self.device = device\n",
    "        self.output_to = output_to\n",
    "        self.args_NN_embedder = args_NN_embedder\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.iX = args_NN_embedder['X']\n",
    "        self.out_dim = args_NN_embedder['out_fc2']\n",
    "        if encoder_or_denoiser_based==\"encoder\":\n",
    "            self.model = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_embedder['X'], \n",
    "                feats_1=args_NN_embedder['feats_1'], feats_2=args_NN_embedder['feats_2'], \n",
    "                feats_3=args_NN_embedder['feats_3'], feats_4=args_NN_embedder['feats_4'],\n",
    "                 prop1=args_NN_embedder['prop1'], prop2=args_NN_embedder['prop2'], prop3=args_NN_embedder['prop3'], \n",
    "                av_pool1_div=args_NN_embedder['av_pool1_div'], conv4_feat_size=args_NN_embedder['conv4_feat_size'], \n",
    "                av_pool2_div=args_NN_embedder['av_pool2_div'], \n",
    "                 out_fc_1=args_NN_embedder['out_fc_1'], out_fc_2=args_NN_embedder['out_fc2'],\n",
    "                 dropout_p1=args_NN_embedder['dropout_p1'], dropout_p2=args_NN_embedder['dropout_p2'] )\n",
    "        else:\n",
    "            self.model = Proximity_Metric_Based_On_Corrector(S0=S0, S1=S1, S2=S2, S3=S3, S4=S4, S5=S5, S6=S6,\n",
    "                 feats_S1=feats_S1, feats_S2=feats_S2, feats_S3=feats_S3, feats_S4=feats_S4,\n",
    "                 feats_S5=feats_S5, feats_S6=feats_S6,\n",
    "                 out_fc1=out_fc1, out_fc2=out_fc2,\n",
    "                 dropout_p=dropout_p ) \n",
    "        \n",
    "        self.preprocess = lambda X: (torch.tensor(X.reshape(X.shape[0],self.iX*2+1,self.iX*2+1)).to(device)) if len(X.shape)<3 else (torch.tensor(X).to(device))\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # move model to gpu if available\n",
    "        self.model.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.model.eval()\n",
    "    \n",
    "    @torch.no_grad() \n",
    "    def __call__(self, X):\n",
    "        self.model.eval()\n",
    "        if self.output_to==\"numpy\":\n",
    "            Xout = np.zeros((X.shape[0], self.out_dim), dtype=np.float64)\n",
    "            for j in range(0, X.shape[0], self.batch_size):\n",
    "                Xout[j:(j+self.batch_size)] = self.model(self.preprocess(X[j:(j+self.batch_size)])).detach().to('cpu').numpy()\n",
    "            return Xout\n",
    "        else:\n",
    "            return self.model(self.preprocess(X))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "\n",
    "exp_name_nn = \"Noisy_Dataset_Embedders\"\n",
    "\n",
    "triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=saved_NN_path+f\"/NNs/{check_file}\", \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")\n",
    "\n",
    "knn_embedder_stuff_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{exp_name_nn}/\"\n",
    "f_name_knn = f'Triplet_CNN_KNN_n_images_600_emb_dims_10_seed_666_date_14_06_2022_20h38m15s.sav'\n",
    "'''\n",
    "#trained_knn_alg_triplet = pickle.load((open(knn_embedder_stuff_path+f_name_knn, 'rb')))\n",
    "\n",
    "#trained_knn_alg_triplet.embedder_func = triplet_embedder\n",
    "\n",
    "def run_knn_on_embedding_space(references, problems, image_pair_names,   \n",
    "                       trained_knn_alg): # if as embedder one gives a pre_process_fct, it will work the same way\n",
    "    predicted_deltaPhiCRs={}\n",
    "    times={}\n",
    "\n",
    "    t=time()\n",
    "    \n",
    "    ref = trained_knn_alg.predict( references, already_embedded_X=False )\n",
    "    pb = trained_knn_alg.predict( problems, already_embedded_X=False )\n",
    "    angles = pb-ref\n",
    "    \n",
    "    t = time()-t\n",
    "    for i, imagep_n in enumerate(image_pair_names):\n",
    "        predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(angles[i]) # pb - ref\n",
    "        times[imagep_n] = t/len(references)\n",
    "        \n",
    "    return predicted_deltaPhiCRs, times    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (K.1) Simulation Fit using h5f library of D matrices gravicenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_by( image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "def given_axis_angle_greater_minus_lower( angle, image, center, rows):\n",
    "    # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "    # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "    mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "    return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un embedder aqui solo tiene sentido si ha estado fed con ground truth poarization angles\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(references, problems, image_pair_names, \n",
    "                                            preprocess_fct, simulation_fit_kw_args, embedder=None):\n",
    "    s = Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR( preprocess_fct, simulation_fit_kw_args, embedder=embedder)\n",
    "    return s.get_angles_times(references, problems, image_pair_names)\n",
    "\n",
    "class Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR():\n",
    "    \n",
    "    def rotate_image_by(  self, image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "\n",
    "    def get_Carles_metric( self, center_h_w, im,  interpolation_flag):\n",
    "        im_pi_im = self.rotate_image_by(im, np.pi, center_h_w,interpolation_flag)+im\n",
    "        return np.mean(np.abs(im_pi_im-rotate_image_by(im_pi_im, np.pi/2, center_h_w,interpolation_flag)))\n",
    "\n",
    "\n",
    "    def initial_Blazquez_estimation( self,  im, center, options_Blaz, rows_prec ):\n",
    "        get_metric = lambda c_h_w : self.get_Carles_metric(c_h_w, im=im, interpolation_flag=cv2.INTER_CUBIC)\n",
    "        res = scipy.optimize.minimize(get_metric, center, method='Nelder-Mead',\n",
    "                                            bounds=((0,im.shape[0]),(0, im.shape[0])),\n",
    "                                            tol=None, options=options_Blaz)\n",
    "        geom_center = res.x\n",
    "        angle = np.arctan2(geom_center[0]-center[0], geom_center[1]-center[1] )\n",
    "        angle = self.get_polarization_angle( angle, im, center, rows_prec)\n",
    "        max_pix_in_prof = np.argmax(im[ int(geom_center[0]),:])\n",
    "        R0 = np.abs(max_pix_in_prof-geom_center[1])-3\n",
    "\n",
    "        try:\n",
    "            if max_pix_in_prof>geom_center[1]:\n",
    "                tol = im[ int(geom_center[0]),::-1]>0.4\n",
    "            else:\n",
    "                tol = im[ int(geom_center[0]),:]>0.4\n",
    "            init = np.argwhere(tol)[0,0]\n",
    "        except:\n",
    "            try:\n",
    "                if max_pix_in_prof>geom_center[1]:\n",
    "                    tol = im[ int(geom_center[0]),::-1]>0.3\n",
    "                else:\n",
    "                    tol = im[ int(geom_center[0]),:]>0.3\n",
    "                init = np.argwhere(tol)[0,0]\n",
    "            except:\n",
    "                try:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.2\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.2\n",
    "                    init = np.argwhere(tol)[0,0]\n",
    "                except:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.1\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.1\n",
    "                    if np.sum(tol)!=0:\n",
    "                        init = np.argwhere(tol)[0,0]\n",
    "                    else:\n",
    "                        return -angle, R0, 22\n",
    "                    \n",
    "        w0 = np.argwhere(np.logical_not(tol[init:]))[0,0]\n",
    "        #print(f\"phi{-angle} R0{R0} w0{w0}\")\n",
    "        return -angle, R0, w0\n",
    "\n",
    "    def get_simulated_image( self, R0, w0, Z, phiCR):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phiCR)]).to(device) #[num_phiCR, 1, 1]\n",
    "        images = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        return self.preprocess_fct(images, in_are_dev_float=True)[0] # only one image\n",
    "    \n",
    "    def closest_in_ar_periodic(  self, value, list_array, delta):\n",
    "        idxs = (np.round((value-min(list_array))/delta)%len(list_array)).astype(int)\n",
    "        return list_array[ idxs ]\n",
    "    \n",
    "    def plot_found_and_ref( self, im_exp, R0, w0, Z, phi):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phi)]).to(device) #[num_phiCR, 1, 1]\n",
    "        im_sim = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        im_sim = self.process(im_sim, in_are_dev_float=True)[0].to('cpu').numpy()\n",
    "        fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "        ax[0].imshow(im_exp)\n",
    "        ax[0].set_title(\"Experimental Image\")\n",
    "        ax[1].imshow(im_sim)\n",
    "        ax[1].set_title(f\"Found optimal\\nR0={R0} w0={w0} Z={Z}\\n phi={phi}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def compute_metric(self, R0_w0_Z_phi, exp_image):\n",
    "        #self.plot_found_and_ref(exp_image.to('cpu').numpy(),R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3])\n",
    "        return self.similarity_func( exp_image, \n",
    "                        self.get_simulated_image(R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3]) )\n",
    "    \n",
    "    def closest_idx_in_ar(self, value, list_array): # hay que meterle una periodicidad como con los angulos porke los algs de optimizacion están pensados para que así sea\n",
    "        return (np.abs(list_array-value)).argmin()\n",
    "\n",
    "    def plot(self, guess, pb):\n",
    "        im = torch.cat((guess, pb))\n",
    "        plt.imshow(im.to('cpu').numpy())\n",
    "        plt.show()\n",
    "\n",
    "    def given_axis_angle_greater_minus_lower(self, angle, image, center, rows):\n",
    "        # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "        # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "        mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "        return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "    def get_polarization_angle(self, angle, image, center, rows):\n",
    "        \"\"\"\n",
    "        All the mirror methods have the problem that we only get the\n",
    "        correct angle up to an angle pi. In order to know which is the\n",
    "        angle to the maximum of the ring (and not the minimum) a final\n",
    "        subtle check is required.\n",
    "        \"\"\"\n",
    "        #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "        if angle==0 or abs(angle)==np.pi:\n",
    "            angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "        diff=given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center, rows)\n",
    "\n",
    "        if diff<0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "            return angle+np.pi if angle<0 else angle\n",
    "        else:\n",
    "            return angle-np.pi if angle>0 else angle\n",
    "\n",
    "    \n",
    "    def __init__(self, preprocess_fct, simulation_fit_kw_args, embedder=None):\n",
    "    \n",
    "        if embedder is None:\n",
    "            self.process = preprocess_fct\n",
    "            self.preprocess_fct = preprocess_fct\n",
    "        else:\n",
    "            self.process = preprocess_fct\n",
    "            self.preprocess_fct = lambda im, in_are_dev_float : self.embedder(self.process( im, in_are_dev_float ))\n",
    "        self.simulation_fit_kw_args = simulation_fit_kw_args\n",
    "        self.embedder = embedder\n",
    "\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(simulation_fit_kw_args['ID_file_path'])))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.R0s_ar = np.array(self.R0s, dtype=np.float64) # Convert them to float arrays\n",
    "        self.w0s_ar = np.array(self.w0s, dtype=np.float64)\n",
    "        self.Zs_ar = np.array(self.Zs, dtype=np.float64)\n",
    "\n",
    "        self.h5f_D_matrices = h5py.File( simulation_fit_kw_args['D_matrix_file_path'], 'r')\n",
    "        self.phis = torch.from_numpy( self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(device) #[1,Nx,Ny]\n",
    "\n",
    "        self.min_Z=min(self.Zs_ar)\n",
    "        self.max_Z=max(self.Zs_ar)\n",
    "        self.min_phi=-np.pi\n",
    "        self.max_phi=np.pi\n",
    "        self.min_radi=min(self.R0s_ar)\n",
    "        self.max_radi=max(self.R0s_ar)\n",
    "        self.min_w0=min(self.w0s_ar)\n",
    "        self.max_w0=max(self.w0s_ar)\n",
    "        #print((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi))\n",
    "\n",
    "        self.last_R0=None\n",
    "        self.last_w0=None\n",
    "        self.last_Z=None\n",
    "        self.R0_precision=abs(self.R0s_ar[1]-self.R0s_ar[0])\n",
    "        self.w0_precision=abs(self.w0s_ar[1]-self.w0s_ar[0])\n",
    "        if len(self.Zs_ar)>1:\n",
    "            self.Z_precision=abs(self.Zs_ar[1]-self.Zs_ar[0])\n",
    "        else:\n",
    "            self.Z_precision=0.00001        \n",
    "        self.similarity_func=simulation_fit_kw_args['similarity_alg']\n",
    "\n",
    "\n",
    "    \n",
    "    def get_angles_times(self, references, problems, image_pair_names):\n",
    "        predicted_deltaPhiCRs={}\n",
    "        times={}\n",
    "\n",
    "        if self.preprocess_fct is not None:\n",
    "            images_t = self.preprocess_fct( torch.from_numpy(np.concatenate((references, problems), axis=0)), in_are_dev_float=False )\n",
    "        else:\n",
    "            images_t = torch.from_numpy( np.concatenate((references, problems), axis=0) )\n",
    "\n",
    "        references_t = images_t[:references.shape[0]]\n",
    "        problems_t = images_t[references.shape[0]:]\n",
    "\n",
    "        if self.simulation_fit_kw_args['use_exact_gravicenter']:\n",
    "            centers_pbs = self.simulation_fit_kw_args['gravicenter_alg'](torch.tensor(problems).to(device)) #[N_pbs, 2] in numpy but input in torch\n",
    "            centers_refs = self.simulation_fit_kw_args['gravicenter_alg'](torch.tensor(references).to(device))\n",
    "        else:\n",
    "            centers_pbs = np.repeat(np.array([[self.simulation_fit_kw_args['X'], \n",
    "                                              self.simulation_fit_kw_args['X']]]), \n",
    "                                   len(problems), axis=0)\n",
    "            centers_refs = np.repeat(np.array([[self.simulation_fit_kw_args['X'], \n",
    "                                              self.simulation_fit_kw_args['X']]]), \n",
    "                                   len(references), axis=0)\n",
    "\n",
    "        rows_prec = np.broadcast_to( np.arange(references.shape[1]), (references.shape[1],references.shape[1])).swapaxes(0,1) #[h,w]\n",
    "        \n",
    "        if self.embedder is None:\n",
    "            references = references_t.to('cpu').numpy()\n",
    "            problems = problems_t.to('cpu').numpy()\n",
    "        else:\n",
    "            references = self.process( torch.from_numpy(references), in_are_dev_float=False).to('cpu').numpy()\n",
    "            problems = self.process( torch.from_numpy(problems), in_are_dev_float=False).to('cpu').numpy()\n",
    "        \n",
    "        # Blazquez algorithm estimation of phiCR, R0 (and even w0)\n",
    "        options_Blaz={'maxiter':self.simulation_fit_kw_args['max_it_Blaz'],\n",
    "                 'maxfev': self.simulation_fit_kw_args['max_evals_Blaz'], \n",
    "                 'xatol':self.simulation_fit_kw_args['abs_tol_Blaz'],\n",
    "                 'fatol':self.simulation_fit_kw_args['rel_tol_Blaz']}\n",
    "\n",
    "        for ref_im, pb_im, ref_im_t, pb_im_t, cent_ref, cent_pb, imagep_n in zip(references, problems, references_t, problems_t, centers_refs, centers_pbs, image_pair_names):\n",
    "            t0=time()\n",
    "            \n",
    "            Z_guess = 0\n",
    "            phi_guess, R0_guess, w0_guess = self.initial_Blazquez_estimation( ref_im, cent_ref, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_ref = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "            \n",
    "            phi_guess, R0_guess, w0_guess = self.initial_Blazquez_estimation( pb_im, cent_pb, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_pb = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "\n",
    "            to_opt_ref = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=ref_im_t )\n",
    "            to_opt_pb = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=pb_im_t)\n",
    "\n",
    "            if self.simulation_fit_kw_args['method']=='Bayesian':\n",
    "                res = skopt.gp_minimize(to_opt_ref, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_ref],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "                res = skopt.gp_minimize(to_opt_pb, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_pb],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            else:\n",
    "                options={'maxiter':self.simulation_fit_kw_args['max_it'],\n",
    "                    'maxfev': self.simulation_fit_kw_args['max_evals']}\n",
    "\n",
    "                if self.simulation_fit_kw_args['method']=='Nelder-Mead':\n",
    "                    options['xatol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['fatol']=self.simulation_fit_kw_args['rel_tol']\n",
    "                elif self.simulation_fit_kw_args['method']=='Powell':\n",
    "                    options['xtol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['ftol']=self.simulation_fit_kw_args['rel_tol']\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_ref, init_guess_ref, method=self.simulation_fit_kw_args['method'],\n",
    "                         bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_pb, init_guess_pb, method=self.simulation_fit_kw_args['method'],\n",
    "                                bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            found = angle_to_pi_pi(opt_R0w0ZphiCR_pb[-1])-angle_to_pi_pi(opt_R0w0ZphiCR_ref[-1])\n",
    "\n",
    "            predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "            times[imagep_n] = time()-t0\n",
    "\n",
    "        self.h5f_D_matrices.close()      \n",
    "        return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (K.2) Simulation Fit using h5f library of D matrices geometric center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "\n",
    "# to max noisy and iX\n",
    "def preprocess_fct(images, batch_size=200, dtype=torch.float64):\n",
    "    images = images.astype(np.float64)\n",
    "    free()\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        ims_t = torch.from_numpy(images[j:(j+batch_size)]).type(dtype).to(device)\n",
    "        images[j:(j+batch_size)] = (compute_raws_to_centered_iXs_torch(\n",
    "                ims_t/(ims_t.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "                      ), X=X, device=device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_geom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64, saturation_threshold=1):\n",
    "    if not in_are_dev_float:\n",
    "        images = images.type(dtype).to(device)\n",
    "    maxs = images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)\n",
    "    return torch.where(images<maxs*saturation_threshold, images, 0.0)/maxs\n",
    "\n",
    "\n",
    "# Un embedder aqui solo tiene sentido si ha estado fed con ground truth poarization angles\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(references, problems, image_pair_names, \n",
    "                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args, embedder=None, \n",
    "                                ):\n",
    "    s = Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center( \n",
    "        pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args, embedder=embedder)\n",
    "    return s.get_angles_times(references, problems, image_pair_names)\n",
    "\n",
    "class Simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center():\n",
    "    \n",
    "    def center_in_center_torch(self, images, centers): # For a piling of images and centers\n",
    "        # crop the iamges with size (X+1+X)^2 leaving the gravity center in\n",
    "        # the central pixel of the image. In case the image is not big enough for the cropping,\n",
    "        # a 0 padding will be made.\n",
    "        centered_images = torch.zeros( ( images.shape[0], 2*X+1, 2*X+1),  dtype = images.dtype, \n",
    "                                      device=device)\n",
    "\n",
    "        # we round the gravity centers to the nearest pixel indices\n",
    "        g_index_raw = torch.round(centers).int() #[ N_images, 2]\n",
    "\n",
    "        # obtain the slicing indices around the center of gravity\n",
    "        # TODO -> make all this with a single array operation by stacking the lower and upper in\n",
    "        # a new axis!!\n",
    "        # [ N_images, 2 (h,w)]\n",
    "        unclipped_lower = g_index_raw-X\n",
    "        unclipped_upper = g_index_raw+X+1\n",
    "\n",
    "        # unclipped could get out of bounds for the indices, so we clip them\n",
    "        lower_bound = torch.clip( unclipped_lower.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        upper_bound = torch.clip( unclipped_upper.float(), min=torch.Tensor([[0,0]]).to(device),\n",
    "                                 max=torch.Tensor(list(images.shape[1:])).unsqueeze(0).to(device)).int()\n",
    "        # we use the difference between the clipped and unclipped to get the necessary padding\n",
    "        # such that the center of gravity is left still in the center of the image\n",
    "        padding_lower = lower_bound-unclipped_lower\n",
    "        padding_upper = upper_bound-unclipped_upper\n",
    "\n",
    "        # crop the image\n",
    "        for im in range(centers.shape[0]):\n",
    "            centered_images[im, padding_lower[ im, 0]:padding_upper[ im, 0] or None,\n",
    "                                        padding_lower[ im, 1]:padding_upper[ im, 1] or None] = \\\n",
    "                      images[im, lower_bound[ im, 0]:upper_bound[ im, 0],\n",
    "                                          lower_bound[ im, 1]:upper_bound[ im, 1]]\n",
    "\n",
    "        return centered_images\n",
    "    \n",
    "    def rotate_image_by(  self, image_array, angle, center,interpolation_flag):\n",
    "        \"\"\"\n",
    "        Center is expected to be a point [h,w]\n",
    "        \"\"\"\n",
    "        a=np.cos(angle)\n",
    "        b=np.sin(angle)\n",
    "        rot_mat=np.float64([[a, b, center[1]*(1-a)-center[0]*b],\n",
    "                             [-b, a, center[1]*b+center[0]*(1-a)]])\n",
    "        return cv2.warpAffine(image_array, rot_mat, image_array.shape, flags=interpolation_flag).astype(image_array.dtype)\n",
    "\n",
    "\n",
    "    def get_Carles_metric( self, center_h_w, im,  interpolation_flag):\n",
    "        im_pi_im = self.rotate_image_by(im, np.pi, center_h_w,interpolation_flag)+im\n",
    "        return np.mean(np.abs(im_pi_im-rotate_image_by(im_pi_im, np.pi/2, center_h_w,interpolation_flag)))\n",
    "\n",
    "\n",
    "    def initial_Blazquez_estimation( self,  im, center, options_Blaz, rows_prec ):\n",
    "        get_metric = lambda c_h_w : self.get_Carles_metric(c_h_w, im=im, interpolation_flag=cv2.INTER_CUBIC)\n",
    "        res = scipy.optimize.minimize(get_metric, center, method='Nelder-Mead',\n",
    "                                            bounds=((0,im.shape[0]),(0, im.shape[0])),\n",
    "                                            tol=None, options=options_Blaz)\n",
    "        geom_center = res.x\n",
    "        angle = np.arctan2(geom_center[0]-center[0], geom_center[1]-center[1] )\n",
    "        angle = self.get_polarization_angle( angle, im, center, rows_prec)\n",
    "        max_pix_in_prof = np.argmax(im[ int(geom_center[0]),:])\n",
    "        R0 = np.abs(max_pix_in_prof-geom_center[1])-3\n",
    "        try:\n",
    "            if max_pix_in_prof>geom_center[1]:\n",
    "                tol = im[ int(geom_center[0]),::-1]>0.4\n",
    "            else:\n",
    "                tol = im[ int(geom_center[0]),:]>0.4\n",
    "            init = np.argwhere(tol)[0,0]\n",
    "        except:\n",
    "            try:\n",
    "                if max_pix_in_prof>geom_center[1]:\n",
    "                    tol = im[ int(geom_center[0]),::-1]>0.3\n",
    "                else:\n",
    "                    tol = im[ int(geom_center[0]),:]>0.3\n",
    "                init = np.argwhere(tol)[0,0]\n",
    "            except:\n",
    "                try:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.2\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.2\n",
    "                    init = np.argwhere(tol)[0,0]\n",
    "                except:\n",
    "                    if max_pix_in_prof>geom_center[1]:\n",
    "                        tol = im[ int(geom_center[0]),::-1]>0.1\n",
    "                    else:\n",
    "                        tol = im[ int(geom_center[0]),:]>0.1\n",
    "                    if np.sum(tol)!=0:\n",
    "                        init = np.argwhere(tol)[0,0]\n",
    "                    else:\n",
    "                        return -angle, R0, 22, geom_center       \n",
    "        w0 = np.argwhere(np.logical_not(tol[init:]))[0,0]\n",
    "        #print(f\"phi{-angle} R0{R0} w0{w0}\")\n",
    "        return -angle, R0, w0, geom_center\n",
    "\n",
    "    def get_simulated_image( self, R0, w0, Z, phiCR):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phiCR)]).to(device) #[num_phiCR, 1, 1]\n",
    "        images = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        images = self.postgeom_preprocess_fct(images, in_are_dev_float=True)[0] # only one image\n",
    "        if self.dif_not_cal:\n",
    "            self.dif = self.X-images.shape[-1]//2\n",
    "            self.dif_not_cal=False\n",
    "        return torch.nn.functional.pad(images, (self.dif,self.dif,self.dif,self.dif), mode='constant', value=0)\n",
    "    \n",
    "    def closest_in_ar_periodic(  self, value, list_array, delta):\n",
    "        idxs = (np.round((value-min(list_array))/delta)%len(list_array)).astype(int)\n",
    "        return list_array[ idxs ]\n",
    "    \n",
    "    def plot_found_and_ref( self, im_exp, R0, w0, Z, phi):\n",
    "        if self.last_R0!=R0 or self.last_w0!=w0 or self.last_Z!=Z:\n",
    "            name = f\"R0_{self.closest_in_ar_periodic(R0,self.R0s_ar, self.R0_precision)}_w0_{self.closest_in_ar_periodic(w0, self.w0s_ar, self.w0_precision)}_Z_{self.closest_in_ar_periodic(Z, self.Zs_ar, self.Z_precision)}\"\n",
    "            self.D_mats = torch.from_numpy(self.h5f_D_matrices[name][:]\n",
    "                    ).unsqueeze(1).to(device) #[2, 1, h, w]            \n",
    "            self.last_R0 = R0\n",
    "            self.last_w0 = w0\n",
    "            self.last_Z = Z\n",
    "        phiCRs = torch.tensor([angle_to_pi_pi(phi)]).to(device) #[num_phiCR, 1, 1]\n",
    "        im_sim = self.D_mats[0]+self.D_mats[1]*torch.cos(phiCRs-self.phis) #[num_phiCR, Nx,Ny]\n",
    "        im_sim = torch.nn.functional.pad(\n",
    "            self.postgeom_preprocess_fct(im_sim, in_are_dev_float=True)[0],\n",
    "            (self.dif,self.dif,self.dif,self.dif), mode='constant', value=0).to('cpu').numpy()\n",
    "        fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "        ax[0].imshow(im_exp)\n",
    "        ax[0].set_title(\"Experimental Image\")\n",
    "        ax[1].imshow(im_sim)\n",
    "        ax[1].set_title(f\"Found optimal\\nR0={R0} w0={w0} Z={Z}\\n phi={phi}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def compute_metric(self, R0_w0_Z_phi, exp_image):\n",
    "        #self.plot_found_and_ref(exp_image.to('cpu').numpy(),R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3])\n",
    "        return self.similarity_func( exp_image, \n",
    "                        self.get_simulated_image(R0_w0_Z_phi[0], R0_w0_Z_phi[1], R0_w0_Z_phi[2], R0_w0_Z_phi[3]) )\n",
    "    \n",
    "    def closest_idx_in_ar(self, value, list_array): # hay que meterle una periodicidad como con los angulos porke los algs de optimizacion están pensados para que así sea\n",
    "        return (np.abs(list_array-value)).argmin()\n",
    "\n",
    "    def plot(self, guess, pb):\n",
    "        im = torch.cat((guess, pb))\n",
    "        plt.imshow(im.to('cpu').numpy())\n",
    "        plt.show()\n",
    "\n",
    "    def given_axis_angle_greater_minus_lower(self, angle, image, center, rows):\n",
    "        # such that if the output is positive, then R has more intensity and you know immediately that the good angle is the bigger one?\n",
    "        # de fet esto sugiere un algoritmo con el polano ortogonal que directamente te encuentra el angulo que toca, pero bueno con los que buscan el eje simetrico el truco no parece que funcionara\n",
    "        mask=np.less(rows, np.tan(angle)*(rows.swapaxes(0,1)-center[1])+center[0]) #[h,w] We set -angle, because the coordinates we are thinking of are a mirror flip in w\n",
    "        # also, we use less instead of greater because we are really thinking on the mirror fliped axes on w\n",
    "        return np.sum(image[mask])-np.sum(image[np.logical_not(mask)])\n",
    "\n",
    "    def get_polarization_angle(self, angle, image, center, rows):\n",
    "        \"\"\"\n",
    "        All the mirror methods have the problem that we only get the\n",
    "        correct angle up to an angle pi. In order to know which is the\n",
    "        angle to the maximum of the ring (and not the minimum) a final\n",
    "        subtle check is required.\n",
    "        \"\"\"\n",
    "        #if angle==np.pi or 0: In this case the correct one is not defined by this alg!!!\n",
    "        if angle==0 or abs(angle)==np.pi:\n",
    "            angle+=1e-12 # this solution is not ideal, but it works, since we will never get such a good precision\n",
    "        diff=given_axis_angle_greater_minus_lower(angle+np.pi/2, image, center, rows)\n",
    "\n",
    "        if diff<0: # then Upper>Lower -> then good one is the one in (0,pi)\n",
    "            return angle+np.pi if angle<0 else angle\n",
    "        else:\n",
    "            return angle-np.pi if angle>0 else angle\n",
    "\n",
    "    \n",
    "    def __init__(self, pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args, embedder=None, preprocess_simulated=None):\n",
    "        \n",
    "        if embedder is None:\n",
    "            self.process = preprocess_fct\n",
    "            self.pregeom_preprocess_fct = pregeom_preprocess_fct\n",
    "            self.postgeom_preprocess_fct = postgeom_preprocess_fct\n",
    "        else:\n",
    "            self.process = postgeom_preprocess_fct\n",
    "            self.postgeom_preprocess_fct = lambda im, in_are_dev_float : self.embedder(self.process( im, in_are_dev_float ))\n",
    "            self.pregeom_preprocess_fct = pregeom_preprocess_fct\n",
    "        self.simulation_fit_kw_args = simulation_fit_kw_args\n",
    "        self.embedder = embedder\n",
    "        \n",
    "        self.X = simulation_fit_kw_args['X']\n",
    "        self.dif_not_cal = True\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(simulation_fit_kw_args['ID_file_path'])))       \n",
    "        self.R0s = list(self.df_GTs['R0s'].drop_duplicates()) # Note they are lists of strings!\n",
    "        self.w0s = list(self.df_GTs['w0s'].drop_duplicates())\n",
    "        self.Zs = list(self.df_GTs['Zs'].drop_duplicates())\n",
    "        self.R0s_ar = np.array(self.R0s, dtype=np.float64) # Convert them to float arrays\n",
    "        self.w0s_ar = np.array(self.w0s, dtype=np.float64)\n",
    "        self.Zs_ar = np.array(self.Zs, dtype=np.float64)\n",
    "\n",
    "        self.h5f_D_matrices = h5py.File( simulation_fit_kw_args['D_matrix_file_path'], 'r')\n",
    "        self.phis = torch.from_numpy( self.h5f_D_matrices['phis'][:]).unsqueeze(0).to(device) #[1,Nx,Ny]\n",
    "\n",
    "        self.min_Z=min(self.Zs_ar)\n",
    "        self.max_Z=max(self.Zs_ar)\n",
    "        self.min_phi=-np.pi\n",
    "        self.max_phi=np.pi\n",
    "        self.min_radi=min(self.R0s_ar)\n",
    "        self.max_radi=max(self.R0s_ar)\n",
    "        self.min_w0=min(self.w0s_ar)\n",
    "        self.max_w0=max(self.w0s_ar)\n",
    "        #print((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi))\n",
    "\n",
    "        self.last_R0=None\n",
    "        self.last_w0=None\n",
    "        self.last_Z=None\n",
    "        self.R0_precision=abs(self.R0s_ar[1]-self.R0s_ar[0])\n",
    "        self.w0_precision=abs(self.w0s_ar[1]-self.w0s_ar[0])\n",
    "        if len(self.Zs_ar)>1:\n",
    "            self.Z_precision=abs(self.Zs_ar[1]-self.Zs_ar[0])\n",
    "        else:\n",
    "            self.Z_precision=0.00001\n",
    "        self.similarity_func=simulation_fit_kw_args['similarity_alg']\n",
    "\n",
    "\n",
    "    \n",
    "    def get_angles_times(self, references, problems, image_pair_names):\n",
    "        predicted_deltaPhiCRs={}\n",
    "        times={}\n",
    "\n",
    "        if self.pregeom_preprocess_fct is not None:\n",
    "            images_t = self.pregeom_preprocess_fct( torch.from_numpy(np.concatenate((references, problems), axis=0)), \n",
    "                                           in_are_dev_float=False )\n",
    "        else:\n",
    "            images_t = torch.from_numpy( np.concatenate((references, problems), axis=0) ).to(device)\n",
    "\n",
    "        gcenters_t = compute_intensity_gravity_centers_torch( images_t) #[N_pbs, 2] in numpy but input in torch\n",
    "        images_t = self.center_in_center_torch(images_t, gcenters_t) # center in gravicentrum!\n",
    "\n",
    "        references_t = images_t[:references.shape[0]]\n",
    "        problems_t = images_t[references.shape[0]:]\n",
    "        centers_refs = gcenters_t[:references.shape[0]].to('cpu').numpy()\n",
    "        centers_pbs = gcenters_t[references.shape[0]:].to('cpu').numpy()\n",
    "\n",
    "        rows_prec = np.broadcast_to( np.arange(references.shape[-1]), (references.shape[-1],references.shape[-1])).swapaxes(0,1) #[h,w]\n",
    "        \n",
    "        if self.embedder is None:\n",
    "            references = references_t.to('cpu').numpy()\n",
    "            problems = problems_t.to('cpu').numpy()\n",
    "        else:\n",
    "            references = self.process( torch.from_numpy(references), in_are_dev_float=False).to('cpu').numpy()\n",
    "            problems = self.process( torch.from_numpy(problems), in_are_dev_float=False).to('cpu').numpy()\n",
    "        \n",
    "        # Blazquez algorithm estimation of phiCR, R0 (and even w0)\n",
    "        options_Blaz={'maxiter':self.simulation_fit_kw_args['max_it_Blaz'],\n",
    "                 'maxfev': self.simulation_fit_kw_args['max_evals_Blaz'], \n",
    "                 'xatol':self.simulation_fit_kw_args['abs_tol_Blaz'],\n",
    "                 'fatol':self.simulation_fit_kw_args['rel_tol_Blaz']}\n",
    "\n",
    "        for ref_im, pb_im, ref_im_t, pb_im_t, cent_ref, cent_pb, imagep_n in zip(references, problems, references_t, problems_t, centers_refs, centers_pbs, image_pair_names):\n",
    "            t0=time()\n",
    "            \n",
    "            Z_guess = 0\n",
    "            phi_guess, R0_guess, w0_guess, geom_center_ref = self.initial_Blazquez_estimation( ref_im, cent_ref, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_ref = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "            \n",
    "            \n",
    "            phi_guess, R0_guess, w0_guess, geom_center_pb = self.initial_Blazquez_estimation( pb_im, cent_pb, options_Blaz, rows_prec )\n",
    "            R0_guess = self.min_radi if R0_guess<self.min_radi else self.max_radi if R0_guess>self.max_radi else R0_guess\n",
    "            w0_guess = self.min_w0 if w0_guess<self.min_w0 else self.max_w0 if w0_guess>self.max_w0 else w0_guess\n",
    "            init_guess_pb = [ R0_guess, w0_guess, Z_guess, phi_guess ]\n",
    "\n",
    "            #ref_im = self.center_in_center(ref_im, geom_center_ref)\n",
    "            #pb_im = self.center_in_center(pb_im, geom_center_pb)\n",
    "            ref_im_t, pb_im_t = self.center_in_center_torch(torch.stack((ref_im_t, pb_im_t), dim=0),\n",
    "                                        torch.tensor([[geom_center_ref[0],geom_center_ref[1]],\n",
    "                                                    [geom_center_pb[0],geom_center_pb[1]]], device=device))\n",
    "\n",
    "            ref_im_t = self.postgeom_preprocess_fct(ref_im_t, True)\n",
    "            pb_im_t = self.postgeom_preprocess_fct(pb_im_t, True)\n",
    "            \n",
    "            ref_im = ref_im_t.to('cpu').numpy()\n",
    "            pb_im = pb_im_t.to('cpu').numpy()\n",
    "            \n",
    "            to_opt_ref = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=ref_im_t )\n",
    "            to_opt_pb = lambda R0_w0_Z_phi : self.compute_metric(R0_w0_Z_phi, exp_image=pb_im_t)\n",
    "\n",
    "            if self.simulation_fit_kw_args['method']=='Bayesian':\n",
    "                res = skopt.gp_minimize(to_opt_ref, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_ref],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "                res = skopt.gp_minimize(to_opt_pb, dimensions=(\n",
    "                    (self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                    n_calls=self.simulation_fit_kw_args['max_evals'],\n",
    "                                    x0=[init_guess_pb],\n",
    "                                    n_initial_points=10, initial_point_generator='random',\n",
    "                                    acq_func='gp_hedge', acq_optimizer='auto', \n",
    "                                    random_state=666, \n",
    "                                    n_points=10000, n_restarts_optimizer=5, xi=0.01, \n",
    "                                    kappa=1.96, noise='gaussian', n_jobs=self.simulation_fit_kw_args['n_jobs'])\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            else:\n",
    "                options={'maxiter':self.simulation_fit_kw_args['max_it'],\n",
    "                    'maxfev': self.simulation_fit_kw_args['max_evals']}\n",
    "\n",
    "                if self.simulation_fit_kw_args['method']=='Nelder-Mead':\n",
    "                    options['xatol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['fatol']=self.simulation_fit_kw_args['rel_tol']\n",
    "                elif self.simulation_fit_kw_args['method']=='Powell':\n",
    "                    options['xtol']=self.simulation_fit_kw_args['abs_tol']\n",
    "                    options['ftol']=self.simulation_fit_kw_args['rel_tol']\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_ref, init_guess_ref, method=self.simulation_fit_kw_args['method'],\n",
    "                         bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_ref = res.x\n",
    "                self.plot_found_and_ref(ref_im, opt_R0w0ZphiCR_ref[0],opt_R0w0ZphiCR_ref[1],opt_R0w0ZphiCR_ref[2],opt_R0w0ZphiCR_ref[3])            \n",
    "\n",
    "\n",
    "                res = scipy.optimize.minimize(to_opt_pb, init_guess_pb, method=self.simulation_fit_kw_args['method'],\n",
    "                                bounds=((self.min_radi,self.max_radi),(self.min_w0,self.max_w0), (self.min_Z, self.max_Z), (self.min_phi, self.max_phi)),\n",
    "                                        #constraints=(), \n",
    "                                        tol=None, options=options)\n",
    "                opt_R0w0ZphiCR_pb = res.x\n",
    "                self.plot_found_and_ref(pb_im, opt_R0w0ZphiCR_pb[0],opt_R0w0ZphiCR_pb[1],opt_R0w0ZphiCR_pb[2],opt_R0w0ZphiCR_pb[3])            \n",
    "\n",
    "            found = angle_to_pi_pi(opt_R0w0ZphiCR_pb[-1])-angle_to_pi_pi(opt_R0w0ZphiCR_ref[-1])\n",
    "\n",
    "            predicted_deltaPhiCRs[imagep_n] = angle_to_pi_pi(found)\n",
    "            times[imagep_n] = time()-t0\n",
    "\n",
    "        self.h5f_D_matrices.close()      \n",
    "        return predicted_deltaPhiCRs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Using the Experimental+Simulated Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con_todo\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin_negativo\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin_positivo\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_experimental\n",
    "# General pipeline settings\n",
    "output_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}/\"\n",
    "#output_path = F\"/home/melanie/Desktop/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}/\"\n",
    "output_units = 'deg'\n",
    "confidence = 90\n",
    "boots_samples = 10000\n",
    "\n",
    "dtype = np.float64\n",
    "dtype_torch = torch.float64\n",
    "\n",
    "n_jobs=10\n",
    "\n",
    "GT_units = 'deg'\n",
    "GT_nature = 'pol'\n",
    "\n",
    "if pipe_name==\"Proof_of_concept2\":\n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/ProofOfConcept/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['ezer', 'bixek', 'sin_negat', 'sin_posit']\n",
    "    GT_abs = [ 0,  5.11, 16.10, -10.98]\n",
    "    repetitions = list(range(3))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    image_pair_names = []\n",
    "    indices = [(0,1),(0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "\n",
    "    show=[0,1,2,3]\n",
    "\n",
    "\n",
    "    references = np.zeros((len(indices), 2*X+1, 2*X+1), dtype=dtype)\n",
    "    problems = np.zeros((len(indices), 2*X+1, 2*X+1), dtype=dtype)\n",
    "    ground_truths = np.zeros(len(indices), dtype=np.float64)\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            j+=1\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[k] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[k] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[k])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[k] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "elif pipe_name==\"HeNe2\":\n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Referencia_HeNe/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['sin_nada', 'con_todo', 'sin_negativo', 'sin_positivo']\n",
    "    #GT_abs = [ 0,  5.11, 16.10, -10.98]\n",
    "    GT_abs = [0, 4.40, 13.85, -9.45]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    image_pair_names = []\n",
    "    indices = [(0,1),(0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "\n",
    "    show=[0,1,2,3]\n",
    "\n",
    "\n",
    "    references = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    problems = np.zeros((len(indices)+1, 2*X+1, 2*X+1), dtype=dtype)\n",
    "    ground_truths = np.zeros(len(indices)+1, dtype=np.float64)\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[k] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[k] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[k])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[k] = GT_abs[ref]-GT_abs[pb]\n",
    "        \n",
    "    # Get the Images to Test\n",
    "    images_path = \"../EXPERIMENTAL/Fotos_Turpin/New_Day/Experimento_Ortogonal_HeNe/\"\n",
    "    #images_path = \"/home/melanie/Desktop/Conical_Refraction_Polarimeter/LAB/EXPERIMENTAL/TEST_IMAGES/\"\n",
    "    exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']\n",
    "    names = ['0_2', '90']\n",
    "    GT_abs = [0, 90]\n",
    "    repetitions = list(range(20))\n",
    "    h=540\n",
    "    w=720\n",
    "\n",
    "    indices = [(0,1)]\n",
    "\n",
    "    show=[0,1]\n",
    "\n",
    "\n",
    "    for k, (ref, pb) in enumerate(indices):\n",
    "        image_pair_names.append(f\"REF_{names[ref]}_PB_{names[pb]}\")\n",
    "\n",
    "        imgR = np.zeros((h, w), dtype=np.float64)\n",
    "        imgP = np.zeros((h, w), dtype=np.float64)\n",
    "        for j in repetitions:\n",
    "            imgR += cv2.imread(f\"{images_path}/{names[ref]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "            imgP += cv2.imread(f\"{images_path}/{names[pb]}_{j}.png\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "        # iX center\n",
    "        references[-1] = compute_raw_to_centered_iX(imgR/len(repetitions), X)\n",
    "        problems[-1] = compute_raw_to_centered_iX(imgP/len(repetitions), X)\n",
    "        if pb in show:\n",
    "            plt.imshow(references[-1])\n",
    "            plt.show()\n",
    "            print(names[pb])\n",
    "            show.remove(pb)\n",
    "\n",
    "        ground_truths[-1] = GT_abs[ref]-GT_abs[pb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simulation_Grav_Prepr_ISOMAP_Trained_wnoisy_DS_Exper_Searc_NM', 'Simulation_Grav_Prepr_ISOMAP_Trained_wnoisy_DS_Exper_Searc_P']\n",
      "> Passing Images from each Algorithm...\n"
     ]
    }
   ],
   "source": [
    "%%skip $dont_use_experimental\n",
    "\n",
    "table_per_alg={}\n",
    "table_per_image={}\n",
    "exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']# , 'Normalize_to_average', 'Sigmoid de parametros tal y cual']\n",
    "\n",
    "\n",
    "algorithm_lambda_list=[]\n",
    "algorithm_name_list = []\n",
    "\n",
    "from skimage import morphology\n",
    "\n",
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "emb_dims=10\n",
    "random_seed=666\n",
    "\n",
    "if current_block==1: # Experimental Embedder+KNN Regressor\n",
    "    \n",
    "    def normalize_to_max_and_iX_input_output_flatten_knn(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=X, batch_size=100): # images expected to be [N_images, h, w]\n",
    "        out = np.zeros((images.shape[0], (2*X+1)**2), dtype=np.float64)\n",
    "        images= images.reshape(-1, X*2+1, X*2+1).astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            out[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch( torch.from_numpy(images[j:(j+batch_size)]).to(device), X, device).to('cpu').numpy().reshape(len(out[j:(j+batch_size)]), -1)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        return out\n",
    "    \n",
    "    if current_sub_block<9: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "    elif current_sub_block>8:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        \n",
    "\n",
    "    if current_sub_block==1 or current_sub_block==9:\n",
    "        # PCA -> Existe la incremental PCA por si es massa grande el dataset!\n",
    "        args = {'exp':'PCA','emb_dims':emb_dims, \"whiten\":True}\n",
    "        embedder = sk.decomposition.PCA(n_components=args['emb_dims'], whiten=args['whiten'], random_state=random_seed)\n",
    "        \n",
    "        if current_sub_block==1: # noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "\n",
    "    elif current_sub_block==2 or current_sub_block==10:\n",
    "        # KPCA\n",
    "        args = {'exp':'KPCA_rbf', 'emb_dims':emb_dims, 'kernel':'rbf', 'fit_inverse':True, 'max_iter':100}\n",
    "        # kernels: linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘cosine’, ‘precomputed’\n",
    "        embedder = sk.decomposition.KernelPCA(n_components=args['emb_dims'], kernel=args['kernel'], \n",
    "                        fit_inverse_transform=args['fit_inverse'], max_iter=args['max_iter'], \n",
    "                                random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==2: # noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_19h47m1657907266.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_19h47m1657907266.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_14h39m1657888747.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_14h39m1657888747.sav\"\n",
    "           \n",
    "    elif current_sub_block==3 or current_sub_block==11:\n",
    "        # LLE \n",
    "        args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 200, \"emb_dims\": emb_dims, 'max_iter':100}\n",
    "        # Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "        embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "                      n_components=args['emb_dims'], max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==3: # noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "        elif current_sub_block==11: # non-noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==4 or current_sub_block==12:\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==4: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==12: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "        \n",
    "    elif current_sub_block==5 or current_sub_block==13:\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==13: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==14:\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==14: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "\n",
    "    elif current_sub_block==7 or current_sub_block==15:\n",
    "        args = {'exp':'RAW'}\n",
    "        embedder = lambda X : X\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "        elif current_sub_block==15: # non-noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "        \n",
    "\n",
    "    \n",
    "    text = \"noisy\" if current_sub_block<9 else \"non_noisy\"\n",
    "    if current_sub_block<8 or (current_sub_block>8 and current_sub_block<16): # scikit learn embedders\n",
    "        #preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_name_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "        if args['exp']=='RAW':\n",
    "            trained_knn_alg.embedder_func.embedder.transform=trained_knn_alg.embedder_func.embedder\n",
    "            \n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_KNN_{args['exp']}_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "    \n",
    "    if current_sub_block==8 or current_sub_block==16:\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "        args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                            'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                            'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "        checkpoint = torch.load(saved_NN_path+f\"/NNs/{check_file}\")\n",
    "        triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=saved_NN_path+'/NNs/'+check_file, \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")\n",
    "        \n",
    "        if current_sub_block==8:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_08_07_2022_10h31m45s.sav\"\n",
    "        elif current_sub_block==16:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_07_07_2022_16h49m21s.sav\"\n",
    "        \n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_path_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func = triplet_embedder\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "\n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_Triplet_CNN_KNN_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "        free()\n",
    "     \n",
    "    \n",
    "elif current_block==2 or current_block==3: # Simulation Gravicenter or Geometric center\n",
    "    ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/STRUCTURE_Grid_R0_115_w0_115_Z_3.json\"\n",
    "    D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/SIMULATIONS/Dataset_R0_115_w0_115_Z_3.h5\"\n",
    "\n",
    "    #ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "    #D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "\n",
    "    #ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_Proof_of_Concept/STRUCTURE_Grid_R0_115_w0_115_Z_1.json\"\n",
    "    #D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_Proof_of_Concept/SIMULATIONS/Dataset_R0_115_w0_115_Z_1.h5\"\n",
    "\n",
    "    simulation_fit_kw_args_NM = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Nelder-Mead',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "\n",
    "    simulation_fit_kw_args_P = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Powell',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "    \n",
    "    #text_DS = \"Noisy\" if current_block==2 else \"Non_Noisy\"\n",
    "    geomgrav = \"Grav\" if current_block==2 else \"Geom\"\n",
    "    run_alg = run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR if current_block==2 else run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center\n",
    "    if current_sub_block==1: # to max\n",
    "        # to max noisy and iX\n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                                  X=X, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "                ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        if current_meta_block<3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Exper_Searc_P\",\n",
    "            ]\n",
    "        elif current_meta_block==3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_P\",\n",
    "            ]\n",
    "        \n",
    "          \n",
    "    elif current_sub_block==2: # to mean\n",
    "        # to max then to mean noisy and iX\n",
    "                               \n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                    images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=X, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "\n",
    "    elif current_sub_block==3: # sigmoid luts\n",
    "        \n",
    "        if current_block==2:\n",
    "            def preprocess_fct(images, in_are_dev_float, center,\n",
    "                    slope_squeezeness, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "                                                          , X, device)\n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35), \n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35),\n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, center=0.1,\n",
    "                    slope_squeezeness=35, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block>3:\n",
    "        # to max noisy and iX\n",
    "        def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "            if not in_are_dev_float:\n",
    "                images = images.type(dtype).to(device)\n",
    "                free()\n",
    "            return compute_raws_to_centered_iXs_torch(\n",
    "                        images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                              X=X, device=device)\n",
    "        \n",
    "    if current_sub_block==4: # Triplet embedder\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "\n",
    "        checkpoint_path=saved_NN_path+f\"/NNs/{check_file}\"\n",
    "\n",
    "\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                          'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                          'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "\n",
    "        triplet_embedder_simulator = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_encoder['X'], \n",
    "                        feats_1=args_NN_encoder['feats_1'], feats_2=args_NN_encoder['feats_2'], \n",
    "                        feats_3=args_NN_encoder['feats_3'], feats_4=args_NN_encoder['feats_4'],\n",
    "                         prop1=args_NN_encoder['prop1'], prop2=args_NN_encoder['prop2'], prop3=args_NN_encoder['prop3'], \n",
    "                        av_pool1_div=args_NN_encoder['av_pool1_div'], conv4_feat_size=args_NN_encoder['conv4_feat_size'], \n",
    "                        av_pool2_div=args_NN_encoder['av_pool2_div'], \n",
    "                         out_fc_1=args_NN_encoder['out_fc_1'], out_fc_2=args_NN_encoder['out_fc2'],\n",
    "                         dropout_p1=args_NN_encoder['dropout_p1'], dropout_p2=args_NN_encoder['dropout_p2'] )\n",
    "        triplet_embedder_simulator.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        triplet_embedder_simulator.load_state_dict(checkpoint['model'])\n",
    "        triplet_embedder_simulator.eval()\n",
    "        \n",
    "\n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=triplet_embedder_simulator),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=triplet_embedder_simulator)\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block<8: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"noisy\"\n",
    "        \n",
    "    elif current_sub_block>7:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"non_noisy\"\n",
    "       \n",
    "    if current_sub_block==5 or current_sub_block==8: # NCA embedder\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==8: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==9: # UMAP embedder\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "                \n",
    "    elif current_sub_block==7 or current_sub_block==10: # ISOMAP embedder\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "    \n",
    "    if current_sub_block>4:\n",
    "        preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        \n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) ),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) )\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Exper_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Exper_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "else:\n",
    "    raise ValueError\n",
    "   \n",
    "   \n",
    "\n",
    "print(algorithm_name_list)\n",
    "\n",
    "# List the Algorithms to test\n",
    "for exp_name in exp_names:\n",
    "    table_per_image[exp_name], table_per_alg[exp_name] = run_benchmark_output_result_histograms_and_result_table( \\\n",
    "            algorithm_lambda_list=algorithm_lambda_list, algorithm_name_list=algorithm_name_list,\\\n",
    "            references=references, problems=problems, image_pair_names=image_pair_names,\\\n",
    "            generate_algorithm_plots=False,\\\n",
    "            generate_histograms=False, boots_samples=boots_samples, confidence=confidence,\\\n",
    "            output_units=output_units, ground_truths=ground_truths, GT_units=GT_units,\\\n",
    "            GT_nature = GT_nature,\\\n",
    "            experiment_name = exp_name, \\\n",
    "            output_path=output_path)\n",
    "    free()\n",
    "    \n",
    "# Benetan gordeta dauzelez df danak, al da exekuteu hau bukaeran tras hacerle un input a todos los df-s\n",
    "# Generate Excel files!\n",
    "# Excel for algorithms\n",
    "writer = StyleFrame.ExcelWriter(f'{output_path}/{exp_names[0]}/EXCEL_Results_per_Algorithm.xlsx')\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(pd.DataFrame({'Absolute Error':['Absolute_Error']})).to_excel(writer, sheet_name=exp_name, startcol=1)\n",
    "    StyleFrame(pd.DataFrame({'Times':['Times']})).to_excel(writer, sheet_name=exp_name, startcol=5)\n",
    "    sf = StyleFrame(pd.DataFrame(table_per_alg[exp_name].index.get_level_values(0)))\n",
    "    sf.set_column_width(columns=[1], width=55.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1)\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Absolute_Error'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.5)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1, startcol=1, float_format=\"%.5f\")\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Times'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name,  startrow=1, startcol=5, float_format=\"%.5f\")\n",
    "writer.save()\n",
    "\n",
    "free()\n",
    "# Excel for images\n",
    "writer = StyleFrame.ExcelWriter(f\"{output_path}/{exp_names[0]}/EXCEL_Results_per_Image.xlsx\")\n",
    "StyleFrame.A_FACTOR=10\n",
    "StyleFrame.P_FACTOR=0.9\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(table_per_image[exp_name]).set_row_height(1,50).to_excel(writer, best_fit=list(table_per_image[exp_name].columns), sheet_name=exp_name, index=False,  float_format=\"%.8f\")\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip $dont_use_experimental\n",
    "table_per_alg[exp_names[0]] # menos precision en fibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_experimental\n",
    "table_per_image[exp_names[0]][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Using a large simulated Noisy Image Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "# General pipeline settings\n",
    "output_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/Pipeline/{pipe_name}\"\n",
    "output_units = 'deg'\n",
    "confidence = 90\n",
    "boots_samples = 10000\n",
    "X=X\n",
    "dtype = np.float64\n",
    "dtype_torch = torch.float64\n",
    "n_jobs=10\n",
    "\n",
    "\n",
    "num_image_pairs_test = 500\n",
    "\n",
    "\n",
    "\n",
    "if current_meta_block==2:\n",
    "    use_noisy = True\n",
    "elif current_meta_block==3:\n",
    "    use_noisy=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, GT_file_path, images_dir_path):\n",
    "        self.df_GTs = pd.DataFrame.from_dict(json.load(open(GT_file_path)))\n",
    "        self.images_dir_path = images_dir_path\n",
    "        self.len_data = len(self.df_GTs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.images_dir_path}/IM_{self.df_GTs.iloc[idx,0]}_phiCR_{self.df_GTs.iloc[idx,1]}.png\"\n",
    "        image = read_image(img_path) #[1, 2X+1, 2X+1] torch tensor\n",
    "        label = torch.Tensor([float(self.df_GTs.iloc[idx, 1])]).type(torch.float32) #[1] torch tensor of float32\n",
    "        return image, label\n",
    "    \n",
    "# Noisy Test set!\n",
    "GT_file_path_test_noisy = f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_noisy =f\"/home/oiangu/Desktop/Conical_Refraction_Polarimeter/OUTPUT/NOISY/TEST\"\n",
    "\n",
    "# Non-Noisy Test set!\n",
    "GT_file_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST/GROUND_TRUTHS.json\"\n",
    "images_dir_path_test_non_noisy = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/IMAGE_LIBRARY/NON_NOISY/TEST\"\n",
    "\n",
    "\n",
    "random_seed = 666\n",
    "\n",
    "if use_noisy:\n",
    "    test_data = ImageDataset(GT_file_path_test_noisy, images_dir_path_test_noisy)\n",
    "else:\n",
    "    test_data = ImageDataset(GT_file_path_test_non_noisy, images_dir_path_test_non_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "np.random.seed(random_seed)\n",
    "random_indices_refs = np.random.choice(range(len(test_data)), num_image_pairs_test, replace=False)\n",
    "\n",
    "X21 = test_data[0][0].shape[1]\n",
    "X_references = np.zeros( (num_image_pairs_test, X21, X21), dtype=np.float32)\n",
    "y_references = np.zeros( (num_image_pairs_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_refs):\n",
    "    im, lab = test_data[idx]\n",
    "    X_references[j, :,:] = im[0]\n",
    "    y_references[j] = lab\n",
    "\n",
    "random_indices_pbs = np.random.choice(range(len(test_data)), num_image_pairs_test, replace=False)\n",
    "\n",
    "X_problems = np.zeros( (num_image_pairs_test, X21, X21), dtype=np.float32)\n",
    "y_problems = np.zeros( (num_image_pairs_test), dtype=np.float64)\n",
    "\n",
    "for j,idx in enumerate(random_indices_pbs):\n",
    "    im, lab = test_data[idx]\n",
    "    X_problems[j, :,:] = im[0]\n",
    "    y_problems[j] = lab\n",
    "    \n",
    "image_pair_names = [f'REF_{ref_idx}_PB_{pb_idx}' for ref_idx, pb_idx in zip(random_indices_refs, random_indices_pbs)]\n",
    "\n",
    "ground_truths = y_problems-y_references\n",
    "ground_truths = np.array([angle_to_pi_pi(phi) for phi in ground_truths])/2\n",
    "\n",
    "del y_problems\n",
    "del y_references\n",
    "free()\n",
    "\n",
    "GT_units = 'rad'\n",
    "GT_nature = 'pol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "\n",
    "table_per_alg={}\n",
    "table_per_image={}\n",
    "exp_names=[f'MetaBlock_{current_meta_block}_Block_{current_block}_Sub_block_{current_sub_block}']# , 'Normalize_to_average', 'Sigmoid de parametros tal y cual']\n",
    "\n",
    "\n",
    "algorithm_lambda_list=[]\n",
    "algorithm_name_list = []\n",
    "\n",
    "from skimage import morphology\n",
    "\n",
    "def get_gravicentrum_batched(images, batch_size=200):\n",
    "    gravicenters = np.zeros((images.shape[0], 2), dtype=np.float64)\n",
    "    for j in range(0, images.shape[0], batch_size):\n",
    "        gravicenters[j:(j+batch_size)] = compute_intensity_gravity_centers_torch(\n",
    "            torch.from_numpy(images[j:(j+batch_size)]).to(device)).to('cpu').numpy()\n",
    "        free()\n",
    "    return gravicenters\n",
    "\n",
    "emb_dims=10\n",
    "\n",
    "\n",
    "if current_block==1: # Experimental Embedder+KNN Regressor\n",
    "    def normalize_to_max_and_iX_input_output_flatten_knn(images, dtype=np.float64,\n",
    "                    iX_dev='cpu', out_dev='cpu', X=X, batch_size=100): # images expected to be [N_images, h, w]\n",
    "        out = np.zeros((images.shape[0], (2*X+1)**2), dtype=np.float64)\n",
    "        images= images.reshape(-1, X*2+1, X*2+1).astype(dtype)/np.expand_dims( np.amax(images, axis=(-2,-1) ), (-2,-1) )\n",
    "        for j in range(0, images.shape[0], batch_size):\n",
    "            out[j:(j+batch_size)] = compute_raws_to_centered_iXs_torch( torch.from_numpy(images[j:(j+batch_size)]).to(device), X, device).to('cpu').numpy().reshape(len(out[j:(j+batch_size)]), -1)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        return out\n",
    "    \n",
    "    if current_sub_block<9: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "    elif current_sub_block>8:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        \n",
    "\n",
    "    if current_sub_block==1 or current_sub_block==9:\n",
    "        # PCA -> Existe la incremental PCA por si es massa grande el dataset!\n",
    "        args = {'exp':'PCA','emb_dims':emb_dims, \"whiten\":True}\n",
    "        embedder = sk.decomposition.PCA(n_components=args['emb_dims'], whiten=args['whiten'], random_state=random_seed)\n",
    "        \n",
    "        if current_sub_block==1: # noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h21m1656930066.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"PCA_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "            f_name_knn = \"PCA_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_23h10m1657055407.sav\"\n",
    "    elif current_sub_block==2 or current_sub_block==10:\n",
    "        # KPCA\n",
    "        args = {'exp':'KPCA_rbf', 'emb_dims':emb_dims, 'kernel':'rbf', 'fit_inverse':True, 'max_iter':100}\n",
    "        # kernels: linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "        embedder = sk.decomposition.KernelPCA(n_components=args['emb_dims'], kernel=args['kernel'], \n",
    "                        fit_inverse_transform=args['fit_inverse'], max_iter=args['max_iter'], \n",
    "                                random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==2: # noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_19h47m1657907266.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_19h47m1657907266.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"KPCA_rbf_EMBEDDER_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_14h39m1657888747.sav\"\n",
    "            f_name_knn = \"KPCA_rbf_KNN_n_images_3000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_14h39m1657888747.sav\"\n",
    "            \n",
    "    elif current_sub_block==3 or current_sub_block==11:\n",
    "        # LLE \n",
    "        args = {'exp':'LLE_standard',\"method\":\"standard\", \"n_neighbors\": 200, \"emb_dims\": emb_dims, 'max_iter':100}\n",
    "        # Methods: standard, hessian, ltsa, modified (modified_tol) \n",
    "        embedder = sk.manifold.LocallyLinearEmbedding(method=args['method'], n_neighbors=args['n_neighbors'],\n",
    "                      n_components=args['emb_dims'], max_iter=args['max_iter'], random_state=random_seed, n_jobs=n_jobs)\n",
    "        if current_sub_block==3: # noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_20h00m1657044055.sav\"\n",
    "        elif current_sub_block==11: # non-noisy trained\n",
    "            f_name_emb = \"LLE_standard_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "            f_name_knn = \"LLE_standard_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h23m1657102984.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==4 or current_sub_block==12:\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==4: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==12: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "        \n",
    "    elif current_sub_block==5 or current_sub_block==13:\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==13: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "                \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==14:\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==14: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "\n",
    "    elif current_sub_block==7 or current_sub_block==15:\n",
    "        args = {'exp':'RAW'}\n",
    "        embedder = lambda X : X\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_05_07_2022_19h58m1657043897.sav\"\n",
    "        elif current_sub_block==15: # non-noisy trained\n",
    "            f_name_emb = \"RAW_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "            f_name_knn = \"RAW_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_12h20m1657102825.sav\"\n",
    "        \n",
    "    \n",
    "    text = \"noisy\" if current_sub_block<9 else \"non_noisy\"\n",
    "    if current_sub_block<8 or (current_sub_block>8 and current_sub_block<16): # scikit learn embedders\n",
    "        preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_name_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "        if args['exp']=='RAW':\n",
    "            trained_knn_alg.embedder_func.embedder.transform=trained_knn_alg.embedder_func.embedder\n",
    "            \n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_KNN_{args['exp']}_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "    \n",
    "    if current_sub_block==8 or current_sub_block==16:\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                  'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                  'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "        args_NN_denoiser = {'X':302, 'S0':2*302+1, 'S1':2*250+1, 'S2':2*200+1, 'S3':2*150+1, 'S4':2*10+1,\n",
    "                            'S5':2*1+1, 'S6':2, 'feats_S1':5, 'feats_S2':5, 'feats_S3':10, 'feats_S4':20,\n",
    "                            'feats_S5':20, 'feats_S6':25, 'out_fc1':100, 'dropout_p':0.1, 'out_fc_2':10}\n",
    "\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "        checkpoint = torch.load(saved_NN_path+f\"/NNs/{check_file}\")\n",
    "        triplet_embedder = Triplet_NN_embedder( args_NN_encoder, \n",
    "                checkpoint_path=saved_NN_path+'/NNs/'+check_file, \n",
    "                device=device, encoder_or_denoiser_based=\"encoder\", output_to=\"numpy\")\n",
    "        \n",
    "        if current_sub_block==8:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_08_07_2022_10h31m45s.sav\"\n",
    "        elif current_sub_block==16:\n",
    "            f_path_knn=\"Triplet_CNN_KNN_n_images_5000_emb_dims_10_seed_666_date_07_07_2022_16h49m21s.sav\"\n",
    "        \n",
    "        trained_knn_alg = dill.load((open(emb_knn_path+f_path_knn, 'rb')))\n",
    "        trained_knn_alg.embedder_func = triplet_embedder\n",
    "        trained_knn_alg.embedder_func.preprocess_fct = normalize_to_max_and_iX_input_output_flatten_knn\n",
    "\n",
    "        algorithm_lambda_list.append(\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_knn_on_embedding_space(refs, pbs,\n",
    "                                                                    image_pair_names, trained_knn_alg)\n",
    "            )\n",
    "        algorithm_name_list.append(\n",
    "                f\"Embedder_Triplet_CNN_KNN_Trained_w{text}_DS_Exper\"\n",
    "            )\n",
    "        free()\n",
    "     \n",
    "    \n",
    "elif current_block==2 or current_block==3: # Simulation Gravicenter or Geometric center\n",
    "    #ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/STRUCTURE_Grid_R0_115_w0_115_Z_3.json\"\n",
    "    #D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_115x_w0_115x_Z_3x_64bit/SIMULATIONS/Dataset_R0_115_w0_115_Z_3.h5\"\n",
    "    \n",
    "    ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "    D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "\n",
    "    #ID_file_path=  \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/STRUCTURE_Grid_R0_70_w0_70_Z_4.json\"\n",
    "    #D_matrix_file_path= \"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Dataset_R0_70_w0_70_Z_4.h5\"\n",
    "\n",
    "    simulation_fit_kw_args_NM = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Nelder-Mead',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "\n",
    "    simulation_fit_kw_args_P = {'ID_file_path':ID_file_path , 'D_matrix_file_path':D_matrix_file_path, 'device':device,\n",
    "                             'similarity_alg':lambda im1, im2: torch.sum(torch.abs(im1-im2)).item(),\n",
    "                            'use_exact_gravicenter':True, 'X':X,\n",
    "            'gravicenter_alg': lambda ims: compute_intensity_gravity_centers_torch( ims ).to('cpu').numpy(),\n",
    "                              'method':'Powell',\n",
    "                             'max_it':70, 'max_evals':100, 'abs_tol':0, 'rel_tol':0,\n",
    "                             'max_it_Blaz':40, 'max_evals_Blaz':40, 'abs_tol_Blaz':0, 'rel_tol_Blaz':0}\n",
    "    \n",
    "    #text_DS = \"Noisy\" if current_block==2 else \"Non_Noisy\"\n",
    "    geomgrav = \"Grav\" if current_block==2 else \"Geom\"\n",
    "    run_alg = run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR if current_block==2 else run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center\n",
    "    if current_sub_block==1: # to max\n",
    "        # to max noisy and iX\n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                                  X=X, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "                ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        if current_meta_block<3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Noisy_Searc_P\",\n",
    "            ]\n",
    "        elif current_meta_block==3:\n",
    "            algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Max_DS_Non_Noisy_Searc_P\",\n",
    "            ]\n",
    "        \n",
    "          \n",
    "    elif current_sub_block==2: # to mean\n",
    "        # to max then to mean noisy and iX\n",
    "                               \n",
    "        if current_block==2:\n",
    "            def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                    images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                         X=X, device=device)\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/torch.mean(images, axis=(-1,-2), keepdims=True)\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Mean_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "\n",
    "    elif current_sub_block==3: # sigmoid luts\n",
    "        \n",
    "        if current_block==2:\n",
    "            def preprocess_fct(images, in_are_dev_float, center,\n",
    "                    slope_squeezeness, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return compute_raws_to_centered_iXs_torch(\n",
    "                            1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "                                                          , X, device)\n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35), \n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                    preprocess_fct=lambda images, in_are_dev_float: preprocess_fct(images, in_are_dev_float,\n",
    "                                                                                center=0.1, slope_squeezeness=35),\n",
    "                    simulation_fit_kw_args=simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        else:\n",
    "            def pregeom_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                return images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))\n",
    "            \n",
    "            def postgeom_preprocess_fct(images, in_are_dev_float, center=0.1,\n",
    "                    slope_squeezeness=35, dtype=torch.float64):\n",
    "                if not in_are_dev_float:\n",
    "                    images = images.type(dtype).to(device)\n",
    "                    free()\n",
    "                images = images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1))   # normalize\n",
    "                return 1.0/(1+torch.exp(-slope_squeezeness*(images-center)))\n",
    "        \n",
    "        \n",
    "            algorithm_lambda_list+=[\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_NM, embedder=None),\n",
    "                lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR_geometric_center(\n",
    "                                                refs, pbs, image_pair_names, \n",
    "                                                pregeom_preprocess_fct, postgeom_preprocess_fct, simulation_fit_kw_args_P, embedder=None),\n",
    "            ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_{geomgrav}_Prepr_Sigm_cent_{0.1}_slp_{35}_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block>3:\n",
    "        # to max noisy and iX\n",
    "        def simulation_preprocess_fct(images, in_are_dev_float, dtype=torch.float64):\n",
    "            if not in_are_dev_float:\n",
    "                images = images.type(dtype).to(device)\n",
    "                free()\n",
    "            return compute_raws_to_centered_iXs_torch(\n",
    "                        images/(images.amax(dim=(-2,-1), keepdim=True)[0].unsqueeze(1)),\n",
    "                              X=X, device=device)\n",
    "        \n",
    "    if current_sub_block==4: # Triplet embedder\n",
    "        saved_NN_path=f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/OUTPUT/LIBRARIES_OF_THEORETICAL_D/Basler_like_R0_300x_w0_300x_Z_50x_64bit/SIMULATIONS/Proximity_Metric/\"\n",
    "        check_file=\"BEEEST1_BEST_Model_and_Optimizer_2022-05-03 17:24:03.205978_Proximity_Metric_from_Simple_Encoder_Batch_Hard_Soft_Margin.pt\"\n",
    "\n",
    "        checkpoint_path=saved_NN_path+f\"/NNs/{check_file}\"\n",
    "\n",
    "\n",
    "        args_NN_encoder = {'X':302, 'feats_1':20, 'feats_2':20, 'feats_3':20, 'feats_4':5, 'prop1':2.5, 'prop2':1.5,\n",
    "                          'prop3':0.6, 'av_pool1_div':2, 'conv4_feat_size':8, 'av_pool2_div':10, 'out_fc_1':5,\n",
    "                          'dropout_p1':0.2, 'dropout_p2':0.1, 'out_fc2':10} # out_fc_2 is the output dim of the embedding space\n",
    "\n",
    "        triplet_embedder_simulator = Proximity_Metric_Based_On_Simple_Encoder( X=args_NN_encoder['X'], \n",
    "                        feats_1=args_NN_encoder['feats_1'], feats_2=args_NN_encoder['feats_2'], \n",
    "                        feats_3=args_NN_encoder['feats_3'], feats_4=args_NN_encoder['feats_4'],\n",
    "                         prop1=args_NN_encoder['prop1'], prop2=args_NN_encoder['prop2'], prop3=args_NN_encoder['prop3'], \n",
    "                        av_pool1_div=args_NN_encoder['av_pool1_div'], conv4_feat_size=args_NN_encoder['conv4_feat_size'], \n",
    "                        av_pool2_div=args_NN_encoder['av_pool2_div'], \n",
    "                         out_fc_1=args_NN_encoder['out_fc_1'], out_fc_2=args_NN_encoder['out_fc2'],\n",
    "                         dropout_p1=args_NN_encoder['dropout_p1'], dropout_p2=args_NN_encoder['dropout_p2'] )\n",
    "        triplet_embedder_simulator.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        triplet_embedder_simulator.load_state_dict(checkpoint['model'])\n",
    "        triplet_embedder_simulator.eval()\n",
    "        \n",
    "\n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, embedder=triplet_embedder_simulator),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, embedder=triplet_embedder_simulator)\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_Triplet_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "    if current_sub_block<8: # embedder knns trained with noisy dataset\n",
    "        embedder_exp_name=\"Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"noisy\"\n",
    "        \n",
    "    elif current_sub_block>7:\n",
    "        embedder_exp_name=\"Non_Noisy_Dataset_Embedders\"\n",
    "        emb_knn_path = f\"/home/oiangu/Hippocampus/Conical_Refraction_Polarimeter/Embedders/Embedders_and_KNN/{embedder_exp_name}/\"\n",
    "        text_sk = \"non_noisy\"\n",
    "       \n",
    "    if current_sub_block==5 or current_sub_block==8: # NCA embedder\n",
    "        # NCA -> uses y categorical Ezin 5000\n",
    "        args = {'exp':'NCA', 'emb_dims':emb_dims, 'init':'auto', 'max_iter':100 }\n",
    "        # init ‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’\n",
    "        embedder = sk.neighbors.NeighborhoodComponentsAnalysis(n_components=args['emb_dims'], init=args['init'],\n",
    "                                        max_iter=args['max_iter'], random_state=random_seed)\n",
    "        if current_sub_block==5: # noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_23h17m1657228679.sav\"\n",
    "        elif current_sub_block==8: # non-noisy trained\n",
    "            f_name_emb = \"NCA_EMBEDDER_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "            f_name_knn = \"NCA_KNN_n_images_2000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_07_07_2022_14h43m1657197822.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==6 or current_sub_block==9: # UMAP embedder\n",
    "        # UMAP -> uses y continous\n",
    "        args = {'exp':'UMAP', 'emb_dims':emb_dims, 'min_dist':0.1, 'n_neighbors':300, 'metric':'hamming', 'n_epochs':None,\n",
    "               'target_metric':'l2'}\n",
    "        # Metrics: euclidean, canberra, cosine, manhattan, braycurtis, mahalanobis, hamming\n",
    "        embedder = umap.UMAP(n_components=args['emb_dims'], min_dist=args['min_dist'], n_epochs=args['n_epochs'],\n",
    "                    n_neighbors=args['n_neighbors'], metric=args['metric'], random_state=random_seed, n_jobs=n_jobs,\n",
    "                            target_metric=args['target_metric']) \n",
    "        if current_sub_block==6: # noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_14_07_2022_22h33m1657830789.sav\"\n",
    "        elif current_sub_block==9: # non-noisy trained\n",
    "            f_name_emb = \"UMAP_EMBEDDER_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "            f_name_knn = \"UMAP_KNN_n_images_4000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_15_07_2022_04h21m1657851668.sav\"\n",
    "        \n",
    "        \n",
    "    elif current_sub_block==7 or current_sub_block==10: # ISOMAP embedder\n",
    "        # ISOMAP\n",
    "        args = {'exp':'ISOMAP', 'n_neighbors':200, 'emb_dims':emb_dims, 'max_iter':100, 'neighbors_algorithm':'auto', 'metric':'minkowski' }\n",
    "        embedder = sk.manifold.Isomap( n_neighbors=args['n_neighbors'],n_components=args['emb_dims'],\n",
    "                            max_iter=args['max_iter'], neighbors_algorithm=args['neighbors_algorithm'], n_jobs=n_jobs,\n",
    "                            metric=args['metric'], p=2)\n",
    "        if current_sub_block==7: # noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_04_07_2022_12h24m1656930242.sav\"\n",
    "        elif current_sub_block==10: # non-noisy trained\n",
    "            f_name_emb = \"ISOMAP_EMBEDDER_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "            f_name_knn = \"ISOMAP_KNN_n_images_5000_emb_dims_10_pre_process_normalize_to_max_and_iX_n_decimals_2_seed_666_date_06_07_2022_14h08m1657109335.sav\"\n",
    "    \n",
    "    if current_sub_block>4:\n",
    "        preprocess_and_embed = dill.load((open(emb_knn_path+f_name_emb, 'rb')))\n",
    "        algorithm_lambda_list+=[\n",
    "            lambda refs, pbs, image_pair_names, dir_alg : run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(\n",
    "                                        refs, pbs, image_pair_names, \n",
    "                        simulation_preprocess_fct, simulation_fit_kw_args_NM, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) ),\n",
    "        \n",
    "            lambda refs, pbs, image_pair_names, dir_alg :run_simulation_fit_R0_w0_Z_Dmatrices_optimize_phiCR(refs, pbs, image_pair_names, \n",
    "                                     simulation_preprocess_fct, simulation_fit_kw_args_P, \n",
    "                embedder = lambda x: torch.from_numpy(preprocess_and_embed.transform(x.to('cpu').numpy().reshape(x.shape[0],-1))).to(device) ),\n",
    "       \n",
    "        ]\n",
    "        algorithm_name_list+=[\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Noisy_Searc_NM\",\n",
    "                f\"Simulation_Grav_Prepr_{args['exp']}_Trained_w{text_sk}_DS_Noisy_Searc_P\",\n",
    "        ]\n",
    "        free()\n",
    "        \n",
    "else:\n",
    "    raise ValueError\n",
    "   \n",
    "   \n",
    "\n",
    "print(algorithm_name_list)\n",
    "\n",
    "# List the Algorithms to test\n",
    "for exp_name in exp_names:\n",
    "    table_per_image[exp_name], table_per_alg[exp_name] = run_benchmark_output_result_histograms_and_result_table(\\\n",
    "        algorithm_lambda_list=algorithm_lambda_list, algorithm_name_list=algorithm_name_list,\\\n",
    "         references=X_references, problems=X_problems, image_pair_names=image_pair_names,\\\n",
    "        generate_algorithm_plots=False,\\\n",
    "        generate_histograms=True, boots_samples=boots_samples, confidence=confidence,\\\n",
    "        output_units=output_units, ground_truths=ground_truths, GT_units=GT_units,\\\n",
    "        GT_nature = GT_nature,\\\n",
    "        experiment_name = exp_name, \\\n",
    "        output_path=output_path)\n",
    "    free()\n",
    "    \n",
    "    \n",
    "# Benetan gordeta dauzelez df danak, al da exekuteu hau bukaeran tras hacerle un input a todos los df-s\n",
    "# Generate Excel files!\n",
    "# Excel for algorithms\n",
    "writer = StyleFrame.ExcelWriter(f'{output_path}/{exp_names[0]}/EXCEL_Results_per_Algorithm.xlsx')\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(pd.DataFrame({'Absolute Error':['Absolute_Error']})).to_excel(writer, sheet_name=exp_name, startcol=1)\n",
    "    StyleFrame(pd.DataFrame({'Times':['Times']})).to_excel(writer, sheet_name=exp_name, startcol=5)\n",
    "    sf = StyleFrame(pd.DataFrame(table_per_alg[exp_name].index.get_level_values(0)))\n",
    "    sf.set_column_width(columns=[1], width=55.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1)\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Absolute_Error'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.5)\n",
    "    sf.to_excel(writer, sheet_name=exp_name, startrow=1, startcol=1, float_format=\"%.5f\")\n",
    "    sf = StyleFrame(table_per_alg[exp_name]['Times'])\n",
    "    sf.set_column_width(columns=[ 1,2,3,4], width=15.0)\n",
    "    sf.to_excel(writer, sheet_name=exp_name,  startrow=1, startcol=5, float_format=\"%.5f\")\n",
    "writer.save()\n",
    "\n",
    "free()\n",
    "# Excel for images\n",
    "writer = StyleFrame.ExcelWriter(f\"{output_path}/{exp_names[0]}/EXCEL_Results_per_Image.xlsx\")\n",
    "StyleFrame.A_FACTOR=10\n",
    "StyleFrame.P_FACTOR=0.9\n",
    "for exp_name in exp_names:\n",
    "    StyleFrame(table_per_image[exp_name]).set_row_height(1,50).to_excel(writer, best_fit=list(table_per_image[exp_name].columns), sheet_name=exp_name, index=False,  float_format=\"%.8f\")\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "table_per_alg[exp_names[0]] # menos precision en fibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $dont_use_simulated\n",
    "table_per_image[exp_names[0]][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update State Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_per_alg[exp_names[0]]\n",
    "\n",
    "f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_meta_block))\n",
    "f.close()\n",
    "f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_block))\n",
    "f.close()\n",
    "f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "f.write(str(current_sub_block))\n",
    "f.close()\n",
    "\n",
    "import os\n",
    "if current_meta_block==1: # experimental\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<16: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "        if current_sub_block<10: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block<10: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "\n",
    "elif current_meta_block==2: # noisy simulated\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<16: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "        if current_sub_block<10: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "\n",
    "    if current_block==3:\n",
    "        if current_sub_block<10: # CNN eindeu ein CNN+fc\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else: # ein deuz ya danak next meta block\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()    \n",
    "            f = open(f\"META_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"3\")\n",
    "            f.close()\n",
    "            \n",
    "elif current_meta_block==3: # experimental\n",
    "    \n",
    "    if current_block==1:\n",
    "        if current_sub_block<16: # hacer todas las métricas diferentes! PONER 14 SI REALMENTE QUIERES HACERLOS TODOS!\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(str(current_sub_block+1))\n",
    "            f.close()        \n",
    "        else:\n",
    "            f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"2\")\n",
    "            f.close()\n",
    "            f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "            f.write(\"1\")\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "    if current_block==2: # solo hay un subblock bien grodo eso si\n",
    "        f = open(f\"BLOCK_{pipe_name}.txt\", \"w\")\n",
    "        f.write(\"3\")\n",
    "        f.close()\n",
    "        f = open(f\"SUB_BLOCK_{pipe_name}.txt\", \"w\")\n",
    "        f.write(\"1\")\n",
    "        f.close()\n",
    "\n",
    "    if current_block==3: # solo un subblock tb\n",
    "        raise ValueError\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "            \n",
    "restart_run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
